{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c772e8c-6e8e-4676-b4e5-1326f085ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "#os.chdir(os.path.expanduser(\"D:\\\\intr_timescales\\\\isttc\\\\scripts\"))\n",
    "os.chdir(os.path.expanduser(\"C:\\\\Users\\\\ipoch\\\\Documents\\\\repos\\\\isttc\\\\scripts\"))\n",
    "from calculate_acf import acf_pearsonr_trial_avg, acf_sttc_trial_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e632b-f5a0-4ee7-8a58-12740c3154ee",
   "metadata": {},
   "source": [
    "### Get and prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c623b-b349-496d-8a19-32155ce4bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' # pfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7edf15-b4d3-4cbc-aab7-96ae7c71d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned data\n",
    "results_folder = 'D:\\\\projects_q_30_10_2024\\\\isttc\\\\results\\\\monkey\\\\'\n",
    "save_folder_binned = results_folder + 'fixation_period_1000ms\\\\binned\\\\' + area + '\\\\acf\\\\'\n",
    "\n",
    "csv_data_file = results_folder + 'data_' + area + '_fixon_1500ms_fixation_with_empty_binned_50ms.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_binned_list = list(reader)\n",
    "    \n",
    "n_binned_spike_trains = len(sua_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_binned_spike_trains))\n",
    "\n",
    "# transform list to an array and to a dataframe \n",
    "sua_binned_array = np.array(sua_binned_list)\n",
    "sua_binned_array = sua_binned_array[:, :-1-9] # for 1000 calc\n",
    "\n",
    "bin_cols = ['bin_' + str(i) for i in range(sua_binned_array.shape[1]-3)]\n",
    "sua_binned_df = pd.DataFrame(sua_binned_array, columns=['unit_id', 'trial_id','condition_id'] + bin_cols)\n",
    "sua_binned_df = sua_binned_df.astype('int')\n",
    "\n",
    "n_binned_units = len(sua_binned_df['unit_id'].unique())\n",
    "print('n units {}'.format(n_binned_units))\n",
    "\n",
    "sua_binned_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf246f12-fc79-45c3-a5f0-179ccb5d7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-binned data\n",
    "results_folder = 'D:\\\\projects_q_30_10_2024\\\\isttc\\\\results\\\\monkey\\\\'\n",
    "save_folder_non_binned = results_folder + 'fixation_period_1000ms\\\\non_binned\\\\' + area + '\\\\acf\\\\'\n",
    "\n",
    "csv_data_file = results_folder + 'data_' + area + '_fixon_1500ms_with_empty_fixation.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_non_binned_list = list(reader)\n",
    "    \n",
    "n_non_binned_spike_trains = len(sua_non_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_non_binned_spike_trains))\n",
    "\n",
    "# transform data to a dict, key is unit_id, values is a list of spike trains (one spike train per trial)\n",
    "units_dict = {}\n",
    "for spike_train in sua_non_binned_list:\n",
    "    spike_train_ = np.asarray(spike_train[3:]).astype(int)\n",
    "    spike_train_1000 = spike_train_[spike_train_ <= 1000]\n",
    "    if int(spike_train[0]) in units_dict:\n",
    "        units_dict[int(spike_train[0])].append(spike_train_1000)\n",
    "    else:\n",
    "        units_dict[int(spike_train[0])] = []\n",
    "        units_dict[int(spike_train[0])].append(spike_train_1000)\n",
    "\n",
    "n_non_binned_units = len(units_dict)\n",
    "print('n units {}'.format(n_non_binned_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ce9e8-388a-483a-95b0-15285186924d",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edd5da-3409-49fa-8855-7d2ba5253fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 20\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a1f52-078c-48e5-b47b-ef700dc2e46f",
   "metadata": {},
   "source": [
    "#### Using Pearson (as in papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95d069-f78d-458f-89de-c5dd4eb4c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "\n",
    "for i in range(n_runs):\n",
    "    print('######### RUNNING {}'.format(i))\n",
    "    acf_average_trial_pearsonr_l = []\n",
    "    acf_matrix_pearsonr_l = []\n",
    "    \n",
    "    unit_id_l = sua_binned_df['unit_id'].unique()\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for unit in unit_id_l:\n",
    "        print('Processing unit {}'.format(unit))\n",
    "        sua_binned_unit_df = sua_binned_df.query('unit_id == @unit')\n",
    "        print('N trials {}'.format(len(sua_binned_unit_df)))\n",
    "    \n",
    "        sua_binned_unit_df = sua_binned_unit_df.sample(n=10, replace=True) # for cases when less then 20 trials\n",
    "        print('N trials {}'.format(len(sua_binned_unit_df)))\n",
    "        \n",
    "        if len(sua_binned_unit_df) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_pearsonr_trial_avg(sua_binned_unit_df[bin_cols].values, n_lags, verbose_=False)\n",
    "            acf_average_trial_pearsonr_l.append(acf_average)\n",
    "            acf_matrix_pearsonr_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(unit)\n",
    "    \n",
    "    acf_average_trial_pearsonr_df = pd.DataFrame(np.array(acf_average_trial_pearsonr_l), columns=acf_cols)\n",
    "    acf_average_trial_pearsonr_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_average_trial_pearsonr_df.isnull().any().any()))\n",
    "    acf_average_trial_pearsonr_df.head(3)\n",
    "\n",
    "    acf_average_trial_pearsonr_df.to_pickle(save_folder_binned + 'trials10\\\\acf_average_trial_pearsonr_with_empty_50ms_20lags_df' + str(i) + '.pkl')\n",
    "    np.save(save_folder_binned + 'trials10\\\\acf_matrix_pearsonr_l_with_empty_50ms_20lags_df' + str(i) + '.npy', acf_matrix_pearsonr_l)\n",
    "\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f23dd-bc6a-4e79-b030-e2e5803cca93",
   "metadata": {},
   "source": [
    "#### Using STTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ddbfc-ab38-4ed0-9aab-ec536311035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "\n",
    "for i in range(n_runs):\n",
    "    print('######### RUNNING {}'.format(i))\n",
    "\n",
    "    acf_average_trial_sttc_l = []\n",
    "    acf_matrix_sttc_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "\n",
    "        v_subsample = random.choices(v, k=10)\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v_subsample)))\n",
    "        \n",
    "        if len(v_subsample) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_sttc_trial_avg(v_subsample, zero_padding_len_=51)\n",
    "            acf_average_trial_sttc_l.append(acf_average)\n",
    "            acf_matrix_sttc_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_average_trial_sttc_df = pd.DataFrame(np.array(acf_average_trial_sttc_l), columns=acf_cols)\n",
    "    acf_average_trial_sttc_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_average_trial_sttc_df.isnull().any().any()))\n",
    "    acf_average_trial_sttc_df.head(3)\n",
    "\n",
    "    acf_average_trial_sttc_df.to_pickle(save_folder_non_binned + 'trials10\\\\acf_average_trial_sttc_with_empty_50ms_20lags_51padding_df' + str(i) + '.pkl')\n",
    "    np.save(save_folder_non_binned + 'trials10\\\\acf_matrix_sttc_l_with_empty_50ms_20lags_51padding_df' + str(i) + '.npy', acf_matrix_sttc_l)\n",
    "\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
