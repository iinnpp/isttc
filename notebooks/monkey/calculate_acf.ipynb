{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765fb181-e45a-4541-8970-2c76c0c644fb",
   "metadata": {},
   "source": [
    "Calculate ACFs:\n",
    "\n",
    "on unit level:\n",
    "1. Pearsonr trial average\n",
    "2. STTC trial average\n",
    "3. STTC trial concat\n",
    "4. STTC trial concat with global normalisation\n",
    "   \n",
    "on trial level:\n",
    "1. ACF proper per trial\n",
    "2. iSTTC per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c772e8c-6e8e-4676-b4e5-1326f085ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "from isttc.scripts.cfg_global import project_folder_path\n",
    "from isttc.acfunc import acf_pearsonr_trial_avg, acf_sttc_trial_concat, acf_sttc_trial_avg, acf_sttc\n",
    "\n",
    "#from calculate_acf import acf_sttc_trial_concat_global this is now in tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e632b-f5a0-4ee7-8a58-12740c3154ee",
   "metadata": {},
   "source": [
    "### Get and prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682dfa3-86b6-4e87-84ee-ff6c44d74c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_suffix = 'with'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d1b61-22e1-4227-8a33-220b22d9a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = project_folder_path + 'results\\\\monkey\\\\'\n",
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms_' + empty_suffix + '_empty\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c623b-b349-496d-8a19-32155ce4bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' # pfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7edf15-b4d3-4cbc-aab7-96ae7c71d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned data\n",
    "csv_data_file = data_folder + 'data_' + area + '_fixon_1000ms_' + empty_suffix + '_empty_fixation_binned_50ms.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_binned_list = list(reader)\n",
    "    \n",
    "n_binned_spike_trains = len(sua_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_binned_spike_trains))\n",
    "\n",
    "# transform list to an array and to a dataframe \n",
    "sua_binned_array = np.array(sua_binned_list)\n",
    "\n",
    "bin_cols = ['bin_' + str(i) for i in range(sua_binned_array.shape[1]-5)]\n",
    "sua_binned_df = pd.DataFrame(sua_binned_array, columns=['unit_id', 'trial_id','condition_id','spike_count','fr_hz'] + bin_cols)\n",
    "for col_name in ['unit_id', 'trial_id','condition_id','spike_count'] + bin_cols:\n",
    "    sua_binned_df[col_name] = sua_binned_df[col_name].astype(int)\n",
    "sua_binned_df['fr_hz'] = sua_binned_df['fr_hz'].astype(float)\n",
    "\n",
    "n_binned_units = len(sua_binned_df['unit_id'].unique())\n",
    "print('n units {}'.format(n_binned_units))\n",
    "\n",
    "sua_binned_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf246f12-fc79-45c3-a5f0-179ccb5d7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-binned data\n",
    "csv_data_file = data_folder + 'data_' + area + '_fixon_1000ms_' + empty_suffix + '_empty_fixation.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_non_binned_list = list(reader)\n",
    "    \n",
    "n_non_binned_spike_trains = len(sua_non_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_non_binned_spike_trains))\n",
    "\n",
    "# transform data to a dict, key is unit_id, values is a list of spike trains (one spike train per trial)\n",
    "units_dict = {}\n",
    "for spike_train in sua_non_binned_list:\n",
    "    spike_train_ = np.asarray(spike_train[5:]).astype(int)\n",
    "    # spike_train_1000 = spike_train_[spike_train_ <= 1000]\n",
    "    if int(spike_train[0]) in units_dict:\n",
    "        units_dict[int(spike_train[0])].append(spike_train_)\n",
    "    else:\n",
    "        units_dict[int(spike_train[0])] = []\n",
    "        units_dict[int(spike_train[0])].append(spike_train_)\n",
    "\n",
    "n_non_binned_units = len(units_dict)\n",
    "print('n units {}'.format(n_non_binned_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ce9e8-388a-483a-95b0-15285186924d",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edd5da-3409-49fa-8855-7d2ba5253fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 20\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))\n",
    "\n",
    "# params for sttc\n",
    "bin_size = 50\n",
    "sttc_dt = 49\n",
    "trial_len = n_lags * bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791116b7-2a33-41ca-9924-5e5891622cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pearsonr_trial_avg = True\n",
    "calc_sttc_trial_avg = True\n",
    "calc_sttc_trial_concat = True\n",
    "calc_sttc_trial_concat_global = False\n",
    "calc_acf_proper_per_trial = False\n",
    "calc_isttc_per_trial = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a1f52-078c-48e5-b47b-ef700dc2e46f",
   "metadata": {},
   "source": [
    "#### Using Pearson trial-average (as in papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c7e11-fdc9-4e54-b277-547deea41c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_pearsonr_trial_avg:\n",
    "    acf_pearsonr_trial_avg_l = []\n",
    "    acf_matrix_pearsonr_trial_avg_l = []\n",
    "    \n",
    "    unit_id_l = sua_binned_df['unit_id'].unique()\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for unit in unit_id_l:\n",
    "        print('Processing unit {}'.format(unit))\n",
    "        sua_binned_unit_df = sua_binned_df.query('unit_id == @unit')\n",
    "        print('N trials {}'.format(len(sua_binned_unit_df)))\n",
    "        \n",
    "        if len(sua_binned_unit_df) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_pearsonr_trial_avg(sua_binned_unit_df[bin_cols].values, n_lags, verbose_=False)\n",
    "            acf_pearsonr_trial_avg_l.append(acf_average)\n",
    "            acf_matrix_pearsonr_trial_avg_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(unit)\n",
    "    \n",
    "    acf_pearsonr_trial_avg_df = pd.DataFrame(np.array(acf_pearsonr_trial_avg_l), columns=acf_cols)\n",
    "    acf_pearsonr_trial_avg_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_pearsonr_trial_avg_df.isnull().any().any()))\n",
    "    acf_pearsonr_trial_avg_df.head(3)\n",
    "    \n",
    "    acf_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "    np.save(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_matrix_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.npy', acf_matrix_pearsonr_trial_avg_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f23dd-bc6a-4e79-b030-e2e5803cca93",
   "metadata": {},
   "source": [
    "#### Using STTC trial-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24628ef1-c2f5-429f-9bdb-be23461eeea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_sttc_trial_avg:\n",
    "    acf_sttc_trial_avg_l = []\n",
    "    acf_matrix_sttc_trial_avg_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "        \n",
    "        if len(v) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_sttc_trial_avg(v, n_lags_=n_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, zero_padding_len_=150, verbose_=False)\n",
    "            acf_sttc_trial_avg_l.append(acf_average)\n",
    "            acf_matrix_sttc_trial_avg_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_sttc_trial_avg_df = pd.DataFrame(np.array(acf_sttc_trial_avg_l), columns=acf_cols)\n",
    "    acf_sttc_trial_avg_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_sttc_trial_avg_df.isnull().any().any()))\n",
    "    acf_sttc_trial_avg_df.head(3)\n",
    "    \n",
    "    acf_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "    np.save(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_matrix_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.npy', acf_matrix_sttc_trial_avg_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c33e28-f316-4237-b0cb-700129399ac3",
   "metadata": {},
   "source": [
    "#### Using STTC trial-concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3eb72-e4c5-426f-ba48-a531aceb1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_sttc_trial_concat:\n",
    "    acf_sttc_trial_concat_l = []\n",
    "    acf_matrix_sttc_trial_concat_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "        \n",
    "        if len(v) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_concat = acf_sttc_trial_concat(v, n_lags_=n_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, trial_len_=trial_len,\n",
    "                                               zero_padding_len_=3000, verbose_=False)\n",
    "            acf_sttc_trial_concat_l.append(acf_concat)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_sttc_trial_concat_df = pd.DataFrame(np.array(acf_sttc_trial_concat_l), columns=acf_cols)\n",
    "    acf_sttc_trial_concat_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_sttc_trial_concat_df.isnull().any().any()))\n",
    "    acf_sttc_trial_concat_df.head(3)\n",
    "    \n",
    "    acf_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd769de-a5bc-4dca-95f2-a270f9af1f17",
   "metadata": {},
   "source": [
    "#### Using STTC trial-concat global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49580ddb-39cd-497e-a005-685315e86b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_sttc_trial_concat_global:\n",
    "    acf_sttc_trial_concat_l = []\n",
    "    acf_matrix_sttc_trial_concat_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "        \n",
    "        if len(v) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_concat = acf_sttc_trial_concat_global(v, n_lags_=n_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, trial_len_=trial_len,\n",
    "                                               zero_padding_len_=3000, verbose_=False)\n",
    "            acf_sttc_trial_concat_l.append(acf_concat)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_sttc_trial_concat_df = pd.DataFrame(np.array(acf_sttc_trial_concat_l), columns=acf_cols)\n",
    "    acf_sttc_trial_concat_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_sttc_trial_concat_df.isnull().any().any()))\n",
    "    acf_sttc_trial_concat_df.head(3)\n",
    "    \n",
    "    acf_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_global_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ed64a-2f04-439b-b897-24e9858a6696",
   "metadata": {},
   "source": [
    "#### Per trial: using ACF formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43c7f3-fc86-40f1-b9c8-ea9932892c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_acf_proper_per_trial:\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_per_trial_proper_cal_log.txt', 'w')\n",
    "    \n",
    "    acf_trial_proper_l, unit_id_proper_l, trial_id_proper_l, condition_id_proper_l, spike_count_proper_l, fr_hz_proper_l = [],[],[],[],[],[]\n",
    "    \n",
    "    for idx in range(len(sua_binned_df)):\n",
    "        print('Processing unit {}, trial {}'.format(sua_binned_df['unit_id'].values[idx], sua_binned_df['trial_id'].values[idx]))\n",
    "        if np.count_nonzero(sua_binned_df[bin_cols].values[idx, :]) <= 1:\n",
    "            print('WARNING: trial has {} non zero bins, nothing to correlate, skipping...'.format(np.count_nonzero(sua_binned_df[bin_cols].values[idx, :])))\n",
    "        else:\n",
    "            acf_proper = acf(sua_binned_df[bin_cols].values[idx, :], nlags=n_lags)\n",
    "            acf_trial_proper_l.append(acf_proper)\n",
    "            unit_id_proper_l.append(sua_binned_df['unit_id'].values[idx])\n",
    "            trial_id_proper_l.append(sua_binned_df['trial_id'].values[idx])\n",
    "            condition_id_proper_l.append(sua_binned_df['condition_id'].values[idx])\n",
    "            spike_count_proper_l.append(sua_binned_df['spike_count'].values[idx])\n",
    "            fr_hz_proper_l.append(sua_binned_df['fr_hz'].values[idx])\n",
    "    \n",
    "    acf_proper_df = pd.DataFrame(np.array(acf_trial_proper_l), columns=acf_cols)\n",
    "    acf_proper_df.insert(0, 'unit_id', unit_id_proper_l)\n",
    "    acf_proper_df.insert(1, 'trial_id', trial_id_proper_l)\n",
    "    acf_proper_df.insert(2, 'condition_id', condition_id_proper_l)\n",
    "    acf_proper_df.insert(3, 'spike_count', spike_count_proper_l)\n",
    "    acf_proper_df.insert(4, 'fr_hz', fr_hz_proper_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_proper_df.isnull().any().any()))\n",
    "    acf_proper_df.head(3)\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    acf_proper_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_proper_per_trial_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664570f-5ff4-4e8e-9fba-a47c6047f7cb",
   "metadata": {},
   "source": [
    "#### Per trial: using iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ea851-84b3-469a-9961-cbd4f6718a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_isttc_per_trial:\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_per_trial_isttc_cal_log.txt', 'w')\n",
    "    \n",
    "    acf_trial_isttc_l, unit_id_isttc_l, trial_id_isttc_l, condition_id_isttc_l, spike_count_isttc_l, fr_hz_isttc_l = [],[],[],[],[],[]\n",
    "    \n",
    "    for idx in range(len(sua_non_binned_list)):\n",
    "        print('Processing unit {}, trial {}'.format(sua_non_binned_list[idx][0], sua_non_binned_list[idx][1]))\n",
    "        spike_train = np.asarray(sua_non_binned_list[idx][5:]).astype(int)\n",
    "        # spike_train = spike_train_a[spike_train_a <= 1000]\n",
    "        if len(spike_train) <= 1:\n",
    "            print('WARNING: trial has {} <= 1, nothing to correlate, skipping...'.format(len(spike_train)))\n",
    "        else:\n",
    "            acf_isttc = acf_sttc(spike_train, n_lags, bin_size, sttc_dt, trial_len, verbose_=False)\n",
    "            acf_trial_isttc_l.append(acf_isttc)\n",
    "            unit_id_isttc_l.append(sua_non_binned_list[idx][0])\n",
    "            trial_id_isttc_l.append(sua_non_binned_list[idx][1])\n",
    "            condition_id_isttc_l.append(sua_non_binned_list[idx][2])\n",
    "            spike_count_isttc_l.append(sua_non_binned_list[idx][3])\n",
    "            fr_hz_isttc_l.append(sua_non_binned_list[idx][4])\n",
    "    \n",
    "    acf_isttc_df = pd.DataFrame(np.array(acf_trial_isttc_l), columns=acf_cols)\n",
    "    acf_isttc_df.insert(0, 'unit_id', unit_id_isttc_l)\n",
    "    acf_isttc_df.insert(1, 'trial_id', trial_id_isttc_l)\n",
    "    acf_isttc_df.insert(2, 'condition_id', condition_id_isttc_l)\n",
    "    acf_isttc_df.insert(3, 'spike_count', spike_count_isttc_l)\n",
    "    acf_isttc_df.insert(4, 'fr_hz', fr_hz_isttc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_isttc_df.isnull().any().any()))\n",
    "    acf_isttc_df.head(3)\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    acf_isttc_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_isttc_per_trial_1000ms_' + empty_suffix + '_50ms_20lags_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
