{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765fb181-e45a-4541-8970-2c76c0c644fb",
   "metadata": {},
   "source": [
    "Calculate ACFs:\n",
    "1. Pearsonr trial average\n",
    "2. STTC trial average\n",
    "3. STTC trial concat\n",
    "4. Pearsonr per trial\n",
    "5. ACF proper per trial\n",
    "6. iSTTC per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c772e8c-6e8e-4676-b4e5-1326f085ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from calculate_acf import acf_pearsonr_trial_avg, acf_sttc_trial_avg, acf_sttc_trial_concat, acf_pearsonr, acf_sttc\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e632b-f5a0-4ee7-8a58-12740c3154ee",
   "metadata": {},
   "source": [
    "### Get and prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798d1b61-22e1-4227-8a33-220b22d9a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = project_folder_path + 'results\\\\monkey\\\\'\n",
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3c623b-b349-496d-8a19-32155ce4bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfp' # pfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7edf15-b4d3-4cbc-aab7-96ae7c71d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N spike_trains in pfp: 43677\n",
      "n units 543\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>condition_id</th>\n",
       "      <th>spike_count</th>\n",
       "      <th>fr_hz</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_10</th>\n",
       "      <th>bin_11</th>\n",
       "      <th>bin_12</th>\n",
       "      <th>bin_13</th>\n",
       "      <th>bin_14</th>\n",
       "      <th>bin_15</th>\n",
       "      <th>bin_16</th>\n",
       "      <th>bin_17</th>\n",
       "      <th>bin_18</th>\n",
       "      <th>bin_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_id  trial_id  condition_id  spike_count  fr_hz  bin_0  bin_1  bin_2  \\\n",
       "0        0         0             0            1    1.0      0      0      0   \n",
       "1        0         1             0            2    2.0      0      0      0   \n",
       "\n",
       "   bin_3  bin_4  ...  bin_10  bin_11  bin_12  bin_13  bin_14  bin_15  bin_16  \\\n",
       "0      0      1  ...       0       0       0       0       0       0       0   \n",
       "1      1      0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "   bin_17  bin_18  bin_19  \n",
       "0       0       0       0  \n",
       "1       0       0       0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binned data\n",
    "csv_data_file = data_folder + 'data_' + area + '_fixon_1000ms_with_empty_fixation_binned_50ms.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_binned_list = list(reader)\n",
    "    \n",
    "n_binned_spike_trains = len(sua_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_binned_spike_trains))\n",
    "\n",
    "# transform list to an array and to a dataframe \n",
    "sua_binned_array = np.array(sua_binned_list)\n",
    "\n",
    "bin_cols = ['bin_' + str(i) for i in range(sua_binned_array.shape[1]-5)]\n",
    "sua_binned_df = pd.DataFrame(sua_binned_array, columns=['unit_id', 'trial_id','condition_id','spike_count','fr_hz'] + bin_cols)\n",
    "for col_name in ['unit_id', 'trial_id','condition_id','spike_count'] + bin_cols:\n",
    "    sua_binned_df[col_name] = sua_binned_df[col_name].astype(int)\n",
    "sua_binned_df['fr_hz'] = sua_binned_df['fr_hz'].astype(float)\n",
    "\n",
    "n_binned_units = len(sua_binned_df['unit_id'].unique())\n",
    "print('n units {}'.format(n_binned_units))\n",
    "\n",
    "sua_binned_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf246f12-fc79-45c3-a5f0-179ccb5d7f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N spike_trains in pfp: 43677\n",
      "n units 543\n"
     ]
    }
   ],
   "source": [
    "# non-binned data\n",
    "csv_data_file = data_folder + 'data_' + area + '_fixon_1000ms_with_empty_fixation.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_non_binned_list = list(reader)\n",
    "    \n",
    "n_non_binned_spike_trains = len(sua_non_binned_list)\n",
    "print('N spike_trains in {}: {}'.format(area, n_non_binned_spike_trains))\n",
    "\n",
    "# transform data to a dict, key is unit_id, values is a list of spike trains (one spike train per trial)\n",
    "units_dict = {}\n",
    "for spike_train in sua_non_binned_list:\n",
    "    spike_train_ = np.asarray(spike_train[5:]).astype(int)\n",
    "    # spike_train_1000 = spike_train_[spike_train_ <= 1000]\n",
    "    if int(spike_train[0]) in units_dict:\n",
    "        units_dict[int(spike_train[0])].append(spike_train_)\n",
    "    else:\n",
    "        units_dict[int(spike_train[0])] = []\n",
    "        units_dict[int(spike_train[0])].append(spike_train_)\n",
    "\n",
    "n_non_binned_units = len(units_dict)\n",
    "print('n units {}'.format(n_non_binned_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ce9e8-388a-483a-95b0-15285186924d",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30edd5da-3409-49fa-8855-7d2ba5253fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf_cols ['acf_0', 'acf_1', 'acf_2', 'acf_3', 'acf_4', 'acf_5', 'acf_6', 'acf_7', 'acf_8', 'acf_9', 'acf_10', 'acf_11', 'acf_12', 'acf_13', 'acf_14', 'acf_15', 'acf_16', 'acf_17', 'acf_18', 'acf_19']\n"
     ]
    }
   ],
   "source": [
    "n_lags = 20\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))\n",
    "\n",
    "# params for sttc\n",
    "bin_size = 50\n",
    "sttc_dt = 49\n",
    "trial_len = n_lags * bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791116b7-2a33-41ca-9924-5e5891622cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pearsonr_trial_avg = False\n",
    "calc_sttc_trial_avg = False\n",
    "calc_sttc_trial_concat = False\n",
    "calc_pearsonr_per_trial = False\n",
    "calc_acf_proper_per_trial = False\n",
    "calc_isttc_per_trial = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a1f52-078c-48e5-b47b-ef700dc2e46f",
   "metadata": {},
   "source": [
    "#### Using Pearson trial-average (as in papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c7e11-fdc9-4e54-b277-547deea41c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_pearsonr_trial_avg:\n",
    "    acf_pearsonr_trial_avg_l = []\n",
    "    acf_matrix_pearsonr_trial_avg_l = []\n",
    "    \n",
    "    unit_id_l = sua_binned_df['unit_id'].unique()\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for unit in unit_id_l:\n",
    "        print('Processing unit {}'.format(unit))\n",
    "        sua_binned_unit_df = sua_binned_df.query('unit_id == @unit')\n",
    "        print('N trials {}'.format(len(sua_binned_unit_df)))\n",
    "        \n",
    "        if len(sua_binned_unit_df) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_pearsonr_trial_avg(sua_binned_unit_df[bin_cols].values, n_lags, verbose_=False)\n",
    "            acf_pearsonr_trial_avg_l.append(acf_average)\n",
    "            acf_matrix_pearsonr_trial_avg_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(unit)\n",
    "    \n",
    "    acf_pearsonr_trial_avg_df = pd.DataFrame(np.array(acf_pearsonr_trial_avg_l), columns=acf_cols)\n",
    "    acf_pearsonr_trial_avg_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_pearsonr_trial_avg_df.isnull().any().any()))\n",
    "    acf_pearsonr_trial_avg_df.head(3)\n",
    "    \n",
    "    acf_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "    np.save(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_matrix_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.npy', acf_matrix_pearsonr_trial_avg_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f23dd-bc6a-4e79-b030-e2e5803cca93",
   "metadata": {},
   "source": [
    "#### Using STTC trial-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24628ef1-c2f5-429f-9bdb-be23461eeea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_sttc_trial_avg:\n",
    "    acf_sttc_trial_avg_l = []\n",
    "    acf_matrix_sttc_trial_avg_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "        \n",
    "        if len(v) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_matrix, acf_average = acf_sttc_trial_avg(v, n_lags_=n_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, zero_padding_len_=150, verbose_=False)\n",
    "            acf_sttc_trial_avg_l.append(acf_average)\n",
    "            acf_matrix_sttc_trial_avg_l.append(acf_matrix)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_sttc_trial_avg_df = pd.DataFrame(np.array(acf_sttc_trial_avg_l), columns=acf_cols)\n",
    "    acf_sttc_trial_avg_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_sttc_trial_avg_df.isnull().any().any()))\n",
    "    acf_sttc_trial_avg_df.head(3)\n",
    "    \n",
    "    acf_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "    np.save(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_matrix_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.npy', acf_matrix_sttc_trial_avg_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c33e28-f316-4237-b0cb-700129399ac3",
   "metadata": {},
   "source": [
    "#### Using STTC trial-concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3eb72-e4c5-426f-ba48-a531aceb1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_sttc_trial_concat:\n",
    "    acf_sttc_trial_concat_l = []\n",
    "    acf_matrix_sttc_trial_concat_l = []\n",
    "    unit_id_calc_l = []\n",
    "    \n",
    "    for k,v in units_dict.items():\n",
    "        print('Processing unit {}, n trials {}'.format(k, len(v)))\n",
    "        \n",
    "        if len(v) <= 1:\n",
    "            print('ONLY 1 TRIAL: can not calculate, skipping...')\n",
    "        else:\n",
    "            acf_concat = acf_sttc_trial_concat(v, n_lags_=n_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, trial_len_=trial_len,\n",
    "                                               zero_padding_len_=2000, verbose_=False)\n",
    "            acf_sttc_trial_concat_l.append(acf_concat)\n",
    "            unit_id_calc_l.append(k)\n",
    "    \n",
    "    acf_sttc_trial_concat_df = pd.DataFrame(np.array(acf_sttc_trial_concat_l), columns=acf_cols)\n",
    "    acf_sttc_trial_concat_df.insert(0, 'unit_id', unit_id_calc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_sttc_trial_concat_df.isnull().any().any()))\n",
    "    acf_sttc_trial_concat_df.head(3)\n",
    "    \n",
    "    acf_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd891b-1da5-426a-ae5b-d68f29b955ae",
   "metadata": {},
   "source": [
    "#### Per trial: using Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4079639-7724-4537-ba5c-512b5ede6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo I use df now but I can also use just a list here? (in trial average I use df to get all trials fro a specific unit)\n",
    "if calc_pearsonr_per_trial:\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_per_trial_pearsonr_cal_log.txt', 'w')\n",
    "    \n",
    "    acf_trial_pearsonr_l, unit_id_pearsonr_l, trial_id_pearsonr_l, condition_id_pearsonr_l, spike_count_pearsonr_l, fr_hz_pearsonr_l = [],[],[],[],[],[]\n",
    "    \n",
    "    for idx in range(len(sua_binned_df)):\n",
    "        print('Processing unit {}, trial {}'.format(sua_binned_df['unit_id'].values[idx], sua_binned_df['trial_id'].values[idx]))\n",
    "        if np.count_nonzero(sua_binned_df[bin_cols].values[idx, :]) <= 1:\n",
    "            print('WARNING: trial has {} non zero bins, nothing to correlate, skipping...'.format(np.count_nonzero(sua_binned_df[bin_cols].values[idx, :])))\n",
    "        else:\n",
    "            acf_pearsonr_ = acf_pearsonr(sua_binned_df[bin_cols].values[idx, :], n_lags_=n_lags, verbose_=False) \n",
    "            acf_trial_pearsonr_l.append(acf_pearsonr_)\n",
    "            unit_id_pearsonr_l.append(sua_binned_df['unit_id'].values[idx])\n",
    "            trial_id_pearsonr_l.append(sua_binned_df['trial_id'].values[idx])\n",
    "            condition_id_pearsonr_l.append(sua_binned_df['condition_id'].values[idx])\n",
    "            spike_count_pearsonr_l.append(sua_binned_df['spike_count'].values[idx])\n",
    "            fr_hz_pearsonr_l.append(sua_binned_df['fr_hz'].values[idx])\n",
    "    \n",
    "    acf_per_trial_pearsonr_df = pd.DataFrame(np.array(acf_trial_pearsonr_l), columns=acf_cols[:-1])\n",
    "    acf_per_trial_pearsonr_df.insert(0, 'unit_id', unit_id_pearsonr_l)\n",
    "    acf_per_trial_pearsonr_df.insert(1, 'trial_id', trial_id_pearsonr_l)\n",
    "    acf_per_trial_pearsonr_df.insert(2, 'condition_id', condition_id_pearsonr_l)\n",
    "    acf_per_trial_pearsonr_df.insert(3, 'spike_count', spike_count_pearsonr_l)\n",
    "    acf_per_trial_pearsonr_df.insert(4, 'fr_hz', fr_hz_pearsonr_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_per_trial_pearsonr_df.isnull().any().any()))\n",
    "    acf_per_trial_pearsonr_df.head(3)\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    acf_per_trial_pearsonr_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ed64a-2f04-439b-b897-24e9858a6696",
   "metadata": {},
   "source": [
    "#### Per trial: using ACF formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43c7f3-fc86-40f1-b9c8-ea9932892c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_acf_proper_per_trial:\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_per_trial_proper_cal_log.txt', 'w')\n",
    "    \n",
    "    acf_trial_proper_l, unit_id_proper_l, trial_id_proper_l, condition_id_proper_l, spike_count_proper_l, fr_hz_proper_l = [],[],[],[],[],[]\n",
    "    \n",
    "    for idx in range(len(sua_binned_df)):\n",
    "        print('Processing unit {}, trial {}'.format(sua_binned_df['unit_id'].values[idx], sua_binned_df['trial_id'].values[idx]))\n",
    "        if np.count_nonzero(sua_binned_df[bin_cols].values[idx, :]) <= 1:\n",
    "            print('WARNING: trial has {} non zero bins, nothing to correlate, skipping...'.format(np.count_nonzero(sua_binned_df[bin_cols].values[idx, :])))\n",
    "        else:\n",
    "            acf_proper = acf(sua_binned_df[bin_cols].values[idx, :], nlags=n_lags)\n",
    "            acf_trial_proper_l.append(acf_proper)\n",
    "            unit_id_proper_l.append(sua_binned_df['unit_id'].values[idx])\n",
    "            trial_id_proper_l.append(sua_binned_df['trial_id'].values[idx])\n",
    "            condition_id_proper_l.append(sua_binned_df['condition_id'].values[idx])\n",
    "            spike_count_proper_l.append(sua_binned_df['spike_count'].values[idx])\n",
    "            fr_hz_proper_l.append(sua_binned_df['fr_hz'].values[idx])\n",
    "    \n",
    "    acf_proper_df = pd.DataFrame(np.array(acf_trial_proper_l), columns=acf_cols)\n",
    "    acf_proper_df.insert(0, 'unit_id', unit_id_proper_l)\n",
    "    acf_proper_df.insert(1, 'trial_id', trial_id_proper_l)\n",
    "    acf_proper_df.insert(2, 'condition_id', condition_id_proper_l)\n",
    "    acf_proper_df.insert(3, 'spike_count', spike_count_proper_l)\n",
    "    acf_proper_df.insert(4, 'fr_hz', fr_hz_proper_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_proper_df.isnull().any().any()))\n",
    "    acf_proper_df.head(3)\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    acf_proper_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664570f-5ff4-4e8e-9fba-a47c6047f7cb",
   "metadata": {},
   "source": [
    "#### Per trial: using iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ea851-84b3-469a-9961-cbd4f6718a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_isttc_per_trial:\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_per_trial_isttc_cal_log.txt', 'w')\n",
    "    \n",
    "    acf_trial_isttc_l, unit_id_isttc_l, trial_id_isttc_l, condition_id_isttc_l, spike_count_isttc_l, fr_hz_isttc_l = [],[],[],[],[],[]\n",
    "    \n",
    "    for idx in range(len(sua_non_binned_list)):\n",
    "        print('Processing unit {}, trial {}'.format(sua_non_binned_list[idx][0], sua_non_binned_list[idx][1]))\n",
    "        spike_train = np.asarray(sua_non_binned_list[idx][5:]).astype(int)\n",
    "        # spike_train = spike_train_a[spike_train_a <= 1000]\n",
    "        if len(spike_train) <= 1:\n",
    "            print('WARNING: trial has {} <= 1, nothing to correlate, skipping...'.format(len(spike_train)))\n",
    "        else:\n",
    "            acf_isttc = acf_sttc(spike_train, n_lags, bin_size, sttc_dt, trial_len, verbose_=False)\n",
    "            acf_trial_isttc_l.append(acf_isttc)\n",
    "            unit_id_isttc_l.append(sua_non_binned_list[idx][0])\n",
    "            trial_id_isttc_l.append(sua_non_binned_list[idx][1])\n",
    "            condition_id_isttc_l.append(sua_non_binned_list[idx][2])\n",
    "            spike_count_isttc_l.append(sua_non_binned_list[idx][3])\n",
    "            fr_hz_isttc_l.append(sua_non_binned_list[idx][4])\n",
    "    \n",
    "    acf_isttc_df = pd.DataFrame(np.array(acf_trial_isttc_l), columns=acf_cols)\n",
    "    acf_isttc_df.insert(0, 'unit_id', unit_id_isttc_l)\n",
    "    acf_isttc_df.insert(1, 'trial_id', trial_id_isttc_l)\n",
    "    acf_isttc_df.insert(2, 'condition_id', condition_id_isttc_l)\n",
    "    acf_isttc_df.insert(3, 'spike_count', spike_count_isttc_l)\n",
    "    acf_isttc_df.insert(4, 'fr_hz', fr_hz_isttc_l)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_isttc_df.isnull().any().any()))\n",
    "    acf_isttc_df.head(3)\n",
    "    \n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    acf_isttc_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
