{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf22309-3217-4aa3-abad-42b40ea8a35e",
   "metadata": {},
   "source": [
    "Load dataframes with acf and calculate tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c30cfa-24a1-44c4-ace1-267751e47a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from calculate_tau import fit_single_exp\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172328e-a498-43a0-acec-db8b553551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf708d-0bcb-4354-b331-813d854b8500",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f824a74c-0158-404b-a864-b4d3cab41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tau_per_unit(acf_df_, acf_cols_, start_idx_):\n",
    "    acf_2d = acf_df_[acf_cols_].values\n",
    "    acf_2d = acf_2d.astype(np.float64) # RuntimeWarning: overflow encountered in matmul sttc start_idx 2\n",
    "    n_units = acf_2d.shape[0]\n",
    "    print('Calculating taus for {}'.format(acf_2d.shape))\n",
    "    \n",
    "    fit_popt_a_l, fit_popt_b_l, fit_popt_c_l = [],[],[]\n",
    "    fit_tau_l = []\n",
    "    fit_r_squared_l = []\n",
    "    fit_log_message_l = []\n",
    "    \n",
    "    for i in range(n_units):\n",
    "        fit_popt, fit_pcov, tau, fit_r_squared, log_message = fit_single_exp(acf_2d[i,:], start_idx_)\n",
    "        if  type(fit_popt) == np.ndarray:\n",
    "            fit_popt_a_l.append(fit_popt[0])\n",
    "            fit_popt_b_l.append(fit_popt[1])\n",
    "            fit_popt_c_l.append(fit_popt[2])\n",
    "        else:\n",
    "            fit_popt_a_l.append(np.nan)\n",
    "            fit_popt_b_l.append(np.nan)\n",
    "            fit_popt_c_l.append(np.nan)\n",
    "        fit_tau_l.append(tau)\n",
    "        fit_r_squared_l.append(fit_r_squared)\n",
    "        fit_log_message_l.append(log_message)\n",
    "    \n",
    "    data_df = np.vstack((fit_popt_a_l, fit_popt_b_l, fit_popt_c_l, fit_tau_l, fit_r_squared_l, fit_log_message_l)).T\n",
    "    tau_df = pd.DataFrame(data_df, columns=['fit_a', 'fit_b', 'fit_c','tau', 'r_squared', 'log_message'])\n",
    "    tau_df.insert(0, 'unit_id', acf_df_['unit_id'].values)\n",
    "\n",
    "    for col in ['fit_a', 'fit_b', 'fit_c','tau', 'r_squared']:\n",
    "        tau_df[col] = tau_df[col].astype(float) \n",
    "    \n",
    "    return tau_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5804eef-4f07-4cf0-8930-93b28c40eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tau_per_area_mean(acf_mean_, start_idx_=1):    \n",
    "\n",
    "    fit_popt, fit_pcov, tau, fit_r_squared, log_message = fit_single_exp(acf_mean_, start_idx_)\n",
    "    \n",
    "    # t = np.linspace(0, len(acf_mean_)-1, len(acf_mean_)).astype(int)\n",
    "    # # print(t)\n",
    "    \n",
    "    # popt, pcov = curve_fit(func_single_exp, t[start_idx_:], acf_mean_[start_idx_:], maxfev=1000000000) # I used 5000, now it is like in Siegle\n",
    "    # tau = 1 / popt[1]\n",
    "    \n",
    "    # # fit r-squared\n",
    "    # y_pred = func_single_exp(t[start_idx_:], *popt)\n",
    "    # fit_r_squared = r2_score(acf_mean_[start_idx_:], y_pred)\n",
    "\n",
    "    return fit_popt, fit_pcov, tau, fit_r_squared, log_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1494b-0434-480e-977a-458b4ac9c5bd",
   "metadata": {},
   "source": [
    "### Calculate tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7327f-6320-463f-87af-1984801387a5",
   "metadata": {},
   "source": [
    "#### One tau per area\n",
    "\n",
    "2 methods of doing that:\n",
    "* average ACF over units and fit\n",
    "* fit using all ACFs from all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b79e2c6d-97cf-41e7-baba-8fd341648e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf_cols ['acf_0', 'acf_1', 'acf_2', 'acf_3', 'acf_4', 'acf_5', 'acf_6', 'acf_7', 'acf_8', 'acf_9', 'acf_10', 'acf_11', 'acf_12', 'acf_13', 'acf_14', 'acf_15', 'acf_16', 'acf_17', 'acf_18', 'acf_19']\n",
      "OptimizeWarning: Covariance of the parameters could not be estimated\n"
     ]
    }
   ],
   "source": [
    "area = 'pfdl' # pfp\n",
    "\n",
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))\n",
    "\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "pearsonr_trial_avg_2d = np.nanmean(pearsonr_trial_avg_df[acf_cols].values, axis=0)\n",
    "fit_popt, fit_pcov, tau, fit_r_squared, log_message = fit_single_exp(pearsonr_trial_avg_2d, start_idx_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "225fc01b-2f4a-47d9-afb1-2c097a277ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.19301799, 0.17380271, 0.15017917, 0.12690764,\n",
       "       0.11182733, 0.0921734 , 0.08025915, 0.07329233, 0.06589106,\n",
       "       0.06287036, 0.05711819, 0.05062921, 0.04433904, 0.04278728,\n",
       "       0.04326979, 0.04019387, 0.0382939 , 0.04504843, 0.03197168])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr_trial_avg_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c368d6d4-8a4a-492a-9910-9de9b647dd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264.33377148503706"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau*bin_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d2f02-5b7c-4890-ad37-f713ae93d5ba",
   "metadata": {},
   "source": [
    "#### One tau per unit\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr trial average (as in the paper)\n",
    "* STTC trial average\n",
    "* STTC trial concat\n",
    "\n",
    "todo: take ACF average over trails for a unit and fit? Or fit all ACFs with one function? (this requires calculating ACF per trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6516d2e1-ad61-4f87-b37d-90f6e8fb62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfp' # pfp\n",
    "\n",
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))\n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f10f5-705f-480f-a740-5d69ae4846fd",
   "metadata": {},
   "source": [
    "#### One tau per trial\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr\n",
    "* ACF formula\n",
    "* iSTTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f85d5-e9b7-487b-a820-45213b252421",
   "metadata": {},
   "source": [
    "### todo (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f066b566-b9cb-4edf-8257-7c9f7d95b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf n_rows_with_nans_perc 17.67955801104972, tau n_rows_with_nans_tau_perc 17.67955801104972\n"
     ]
    }
   ],
   "source": [
    "n_rows_with_nans = pearsonr_trial_avg_df[acf_cols].isnull().any(axis=1).sum()\n",
    "n_rows_with_nans_perc = n_rows_with_nans / len(pearsonr_trial_avg_df) * 100\n",
    "# acf_df.dropna(inplace=True)\n",
    "\n",
    "n_rows_with_nans_tau = tau_pearsonr_trial_avg_df['tau_ms'].isnull().sum()\n",
    "n_rows_with_nans_tau_perc = n_rows_with_nans_tau / len(tau_pearsonr_trial_avg_df) * 100\n",
    "# tau_df.dropna(inplace=True)\n",
    "\n",
    "print('acf n_rows_with_nans_perc {}, tau n_rows_with_nans_tau_perc {}'.format(n_rows_with_nans_perc, n_rows_with_nans_tau_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10482216-9577-43a6-ae86-f6f4dd9be4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf n_rows_with_nans_perc 0.0, tau n_rows_with_nans_tau_perc 0.3683241252302026\n"
     ]
    }
   ],
   "source": [
    "n_rows_with_nans = sttc_trial_avg_df[acf_cols].isnull().any(axis=1).sum()\n",
    "n_rows_with_nans_perc = n_rows_with_nans / len(sttc_trial_avg_df) * 100\n",
    "# acf_df.dropna(inplace=True)\n",
    "\n",
    "n_rows_with_nans_tau = tau_sttc_trial_avg_df['tau_ms'].isnull().sum()\n",
    "n_rows_with_nans_tau_perc = n_rows_with_nans_tau / len(tau_sttc_trial_avg_df) * 100\n",
    "# tau_df.dropna(inplace=True)\n",
    "\n",
    "print('acf n_rows_with_nans_perc {}, tau n_rows_with_nans_tau_perc {}'.format(n_rows_with_nans_perc, n_rows_with_nans_tau_perc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
