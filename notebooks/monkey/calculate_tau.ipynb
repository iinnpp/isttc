{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf22309-3217-4aa3-abad-42b40ea8a35e",
   "metadata": {},
   "source": [
    "Load dataframes with acf and calculate tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c30cfa-24a1-44c4-ace1-267751e47a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from calculate_tau import fit_single_exp, func_single_exp_monkey\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e172328e-a498-43a0-acec-db8b553551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf708d-0bcb-4354-b331-813d854b8500",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824a74c-0158-404b-a864-b4d3cab41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tau_per_unit(acf_df_, acf_cols_, start_idx_):\n",
    "    acf_2d = acf_df_[acf_cols_].values\n",
    "    acf_2d = acf_2d.astype(np.float64) # RuntimeWarning: overflow encountered in matmul sttc start_idx 2\n",
    "    n_units = acf_2d.shape[0]\n",
    "    print('Calculating taus for {}'.format(acf_2d.shape))\n",
    "    \n",
    "    fit_popt_a_l, fit_popt_b_l, fit_popt_c_l = [],[],[]\n",
    "    fit_tau_l = []\n",
    "    fit_r_squared_l = []\n",
    "    fit_log_message_l = []\n",
    "    \n",
    "    for i in range(n_units):\n",
    "        fit_popt, fit_pcov, tau, fit_r_squared, log_message = fit_single_exp(acf_2d[i,:], start_idx_, func_single_exp_monkey)\n",
    "        if  type(fit_popt) == np.ndarray:\n",
    "            fit_popt_a_l.append(fit_popt[0])\n",
    "            fit_popt_b_l.append(fit_popt[1])\n",
    "            fit_popt_c_l.append(fit_popt[2])\n",
    "        else:\n",
    "            fit_popt_a_l.append(np.nan)\n",
    "            fit_popt_b_l.append(np.nan)\n",
    "            fit_popt_c_l.append(np.nan)\n",
    "        fit_tau_l.append(tau)\n",
    "        fit_r_squared_l.append(fit_r_squared)\n",
    "        fit_log_message_l.append(log_message)\n",
    "    \n",
    "    data_df = np.vstack((fit_popt_a_l, fit_popt_b_l, fit_popt_c_l, fit_tau_l, fit_r_squared_l, fit_log_message_l)).T\n",
    "    tau_df = pd.DataFrame(data_df, columns=['fit_a', 'fit_b', 'fit_c','tau', 'r_squared', 'log_message'])\n",
    "    tau_df.insert(0, 'unit_id', acf_df_['unit_id'].values)\n",
    "\n",
    "    for col in ['fit_a', 'fit_b', 'fit_c','tau', 'r_squared']:\n",
    "        tau_df[col] = tau_df[col].astype(float) \n",
    "    \n",
    "    return tau_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd552a-219d-4174-9f82-2682108d1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different way of calculating tau per area \n",
    "def calc_tau_area(acf_df_, acf_cols_, start_idx_=1):\n",
    "    acf_2d = acf_df_[acf_cols_].values\n",
    "    print(acf_2d.shape)\n",
    "    \n",
    "    t = np.linspace(start_idx_, acf_2d.shape[1]-start_idx_, acf_2d.shape[1]-start_idx_).astype(int)\n",
    "    # print(t)\n",
    "    \n",
    "    # make 1d for curve_fit\n",
    "    acf_1d = np.hstack(acf_2d[:,1:])\n",
    "    print(acf_1d.shape)\n",
    "    t_1d = np.tile(t, reps=acf_2d.shape[0])\n",
    "    print(t_1d.shape)\n",
    "    \n",
    "    popt, pcov = curve_fit(func_single_exp, t_1d, acf_1d, maxfev=1000000000) # I used 5000, now it is like in Siegle\n",
    "    tau = 1 / popt[1]\n",
    "    \n",
    "    # fit r-squared\n",
    "    y_pred = func_single_exp(t_1d, *popt)\n",
    "    fit_r_squared = r2_score(acf_1d, y_pred)\n",
    "\n",
    "    return tau, popt, fit_r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1494b-0434-480e-977a-458b4ac9c5bd",
   "metadata": {},
   "source": [
    "### Calculate tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7327f-6320-463f-87af-1984801387a5",
   "metadata": {},
   "source": [
    "#### One tau per area\n",
    "\n",
    "2 methods of doing that:\n",
    "* average ACF over units and fit\n",
    "* fit using all ACFs from all neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b382439-54ea-4585-ad38-bb422f70353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81924967-0856-41de-bdb4-8b3ebd511acf",
   "metadata": {},
   "source": [
    "##### average ACF over units and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e2c6d-97cf-41e7-baba-8fd341648e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' \n",
    "\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "pearsonr_trial_avg_2d_mean = np.nanmean(pearsonr_trial_avg_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfdl_pearsonr_trial_avg_fit_popt, _, pfdl_pearsonr_trial_avg_tau, pfdl_pearsonr_trial_avg_fit_r_squared, _ = fit_single_exp(pearsonr_trial_avg_2d_mean, \n",
    "                                                                            start_idx_=2, exp_fun_=func_single_exp_monkey)\n",
    "pfdl_pearsonr_trial_avg_tau_ms = pfdl_pearsonr_trial_avg_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfdl_pearsonr_trial_avg_tau_ms, \n",
    "                                                             pfdl_pearsonr_trial_avg_fit_popt, \n",
    "                                                             pfdl_pearsonr_trial_avg_fit_r_squared))\n",
    "\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "sttc_trial_avg_2d_mean = np.nanmean(sttc_trial_avg_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfdl_sttc_trial_avg_fit_popt, _, pfdl_sttc_trial_avg_tau, pfdl_sttc_trial_avg_fit_r_squared, _ = fit_single_exp(sttc_trial_avg_2d_mean, \n",
    "                                                                                                                start_idx_=2, \n",
    "                                                                                                                exp_fun_=func_single_exp_monkey)\n",
    "pfdl_sttc_trial_avg_tau_ms = pfdl_sttc_trial_avg_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfdl_sttc_trial_avg_tau_ms, \n",
    "                                                             pfdl_sttc_trial_avg_fit_popt, \n",
    "                                                             pfdl_sttc_trial_avg_fit_r_squared))\n",
    "\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "sttc_trial_concat_2d_mean = np.nanmean(sttc_trial_concat_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfdl_sttc_trial_concat_fit_popt, _, pfdl_sttc_trial_concat_tau, pfdl_sttc_trial_concat_fit_r_squared, _ = fit_single_exp(sttc_trial_concat_2d_mean, \n",
    "                                                                                                                start_idx_=2, \n",
    "                                                                                                                exp_fun_=func_single_exp_monkey)\n",
    "pfdl_sttc_trial_concat_tau_ms = pfdl_sttc_trial_concat_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfdl_sttc_trial_concat_tau_ms, \n",
    "                                                             pfdl_sttc_trial_concat_fit_popt, \n",
    "                                                             pfdl_sttc_trial_concat_fit_r_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fc01b-2f4a-47d9-afb1-2c097a277ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfp' \n",
    "\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "pearsonr_trial_avg_2d_mean = np.nanmean(pearsonr_trial_avg_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfp_pearsonr_trial_avg_fit_popt, _, pfp_pearsonr_trial_avg_tau, pfp_pearsonr_trial_avg_fit_r_squared, _ = fit_single_exp(pearsonr_trial_avg_2d_mean, \n",
    "                                                                            start_idx_=2, exp_fun_=func_single_exp_monkey)\n",
    "pfp_pearsonr_trial_avg_tau_ms = pfp_pearsonr_trial_avg_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfp_pearsonr_trial_avg_tau_ms, \n",
    "                                                             pfp_pearsonr_trial_avg_fit_popt, \n",
    "                                                             pfp_pearsonr_trial_avg_fit_r_squared))\n",
    "\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "sttc_trial_avg_2d_mean = np.nanmean(sttc_trial_avg_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfp_sttc_trial_avg_fit_popt, _, pfp_sttc_trial_avg_tau, pfp_sttc_trial_avg_fit_r_squared, _ = fit_single_exp(sttc_trial_avg_2d_mean, \n",
    "                                                                                                                start_idx_=2, \n",
    "                                                                                                                exp_fun_=func_single_exp_monkey)\n",
    "pfp_sttc_trial_avg_tau_ms = pfp_sttc_trial_avg_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfp_sttc_trial_avg_tau_ms, \n",
    "                                                             pfp_sttc_trial_avg_fit_popt, \n",
    "                                                             pfp_sttc_trial_avg_fit_r_squared))\n",
    "\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "sttc_trial_concat_2d_mean = np.nanmean(sttc_trial_concat_df[acf_cols].values, axis=0) # todo remove all rows with NaNs? \n",
    "pfp_sttc_trial_concat_fit_popt, _, pfp_sttc_trial_concat_tau, pfp_sttc_trial_concat_fit_r_squared, _ = fit_single_exp(sttc_trial_concat_2d_mean, \n",
    "                                                                                                                start_idx_=2, \n",
    "                                                                                                                exp_fun_=func_single_exp_monkey)\n",
    "pfp_sttc_trial_concat_tau_ms = pfp_sttc_trial_concat_tau*bin_size\n",
    "print('tau {}, popt {}, fit_r_squared {}'.format(pfp_sttc_trial_concat_tau_ms, \n",
    "                                                             pfp_sttc_trial_concat_fit_popt, \n",
    "                                                             pfp_sttc_trial_concat_fit_r_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d2f02-5b7c-4890-ad37-f713ae93d5ba",
   "metadata": {},
   "source": [
    "#### One tau per unit\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr trial average (as in the paper)\n",
    "* STTC trial average\n",
    "* STTC trial concat\n",
    "\n",
    "todo: take ACF average over trails for a unit and fit? Or fit all ACFs with one function? (this requires calculating ACF per trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545844af-2a85-4a85-8df2-e61c0b65bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd6aff-eea4-4941-b145-f2a4e60c82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516d2e1-ad61-4f87-b37d-90f6e8fb62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfp' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f10f5-705f-480f-a740-5d69ae4846fd",
   "metadata": {},
   "source": [
    "#### One tau per trial\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr\n",
    "* ACF formula\n",
    "* iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf31bf1-1c7c-4371-be0b-b3fdb491c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2e68e-c325-4737-ba33-db125f8b1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' \n",
    "\n",
    "# pearsonr \n",
    "# pearsonr_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(pearsonr_per_trial_df)}, dropping before tau calc ...')\n",
    "# pearsonr_per_trial_df.dropna(inplace=True)\n",
    "# pearsonr_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_pearsonr_per_trial_df = calc_tau_per_unit(pearsonr_per_trial_df, acf_cols[:-1], start_idx_=1)\n",
    "# tau_pearsonr_per_trial_df['tau_ms'] = tau_pearsonr_per_trial_df['tau'] * bin_size\n",
    "# tau_pearsonr_per_trial_df.insert(1, 'trial_id', pearsonr_per_trial_df['trial_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(2, 'condition_id', pearsonr_per_trial_df['condition_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(3, 'spike_count', pearsonr_per_trial_df['spike_count'])\n",
    "# tau_pearsonr_per_trial_df.insert(4, 'fr_hz', pearsonr_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_pearsonr_per_trial_df)}')\n",
    "# tau_pearsonr_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# # acf formula\n",
    "# pcf_proper_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pcf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(pcf_proper_per_trial_df)}, dropping before tau calc ...')\n",
    "# pcf_proper_per_trial_df.dropna(inplace=True)\n",
    "# pcf_proper_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_acf_proper_per_trial_df = calc_tau_per_unit(pcf_proper_per_trial_df, acf_cols, start_idx_=1)\n",
    "# tau_acf_proper_per_trial_df['tau_ms'] = tau_acf_proper_per_trial_df['tau'] * bin_size\n",
    "# tau_acf_proper_per_trial_df.insert(1, 'trial_id', pcf_proper_per_trial_df['trial_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(2, 'condition_id', pcf_proper_per_trial_df['condition_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(3, 'spike_count', pcf_proper_per_trial_df['spike_count'])\n",
    "# tau_acf_proper_per_trial_df.insert(4, 'fr_hz', pcf_proper_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_acf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_acf_proper_per_trial_df)}')\n",
    "# tau_acf_proper_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# isttc\n",
    "sttc_per_trial_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "print(f'N rows with NaN {sttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(sttc_per_trial_df)}, dropping before tau calc ...')\n",
    "sttc_per_trial_df.dropna(inplace=True)\n",
    "sttc_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "tau_isttc_per_trial_df = calc_tau_per_unit(sttc_per_trial_df, acf_cols, start_idx_=1)\n",
    "tau_isttc_per_trial_df['tau_ms'] = tau_isttc_per_trial_df['tau'] * bin_size\n",
    "tau_isttc_per_trial_df.insert(1, 'trial_id', sttc_per_trial_df['trial_id'])\n",
    "tau_isttc_per_trial_df.insert(2, 'condition_id', sttc_per_trial_df['condition_id'])\n",
    "tau_isttc_per_trial_df.insert(3, 'spike_count', sttc_per_trial_df['spike_count'])\n",
    "tau_isttc_per_trial_df.insert(4, 'fr_hz', sttc_per_trial_df['fr_hz'])\n",
    "print(f'N rows with NaN {tau_isttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_isttc_per_trial_df)}')\n",
    "tau_isttc_per_trial_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2bc29-5a5c-42cb-9cac-14b8e3cd8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_acf_proper_per_trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d3e05-bea0-4f7b-83f9-da6839866c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr_per_trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f85d5-e9b7-487b-a820-45213b252421",
   "metadata": {},
   "source": [
    "### todo (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066b566-b9cb-4edf-8257-7c9f7d95b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_with_nans = pearsonr_trial_avg_df[acf_cols].isnull().any(axis=1).sum()\n",
    "n_rows_with_nans_perc = n_rows_with_nans / len(pearsonr_trial_avg_df) * 100\n",
    "# acf_df.dropna(inplace=True)\n",
    "\n",
    "n_rows_with_nans_tau = tau_pearsonr_trial_avg_df['tau_ms'].isnull().sum()\n",
    "n_rows_with_nans_tau_perc = n_rows_with_nans_tau / len(tau_pearsonr_trial_avg_df) * 100\n",
    "# tau_df.dropna(inplace=True)\n",
    "\n",
    "print('acf n_rows_with_nans_perc {}, tau n_rows_with_nans_tau_perc {}'.format(n_rows_with_nans_perc, n_rows_with_nans_tau_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10482216-9577-43a6-ae86-f6f4dd9be4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_with_nans = sttc_trial_avg_df[acf_cols].isnull().any(axis=1).sum()\n",
    "n_rows_with_nans_perc = n_rows_with_nans / len(sttc_trial_avg_df) * 100\n",
    "# acf_df.dropna(inplace=True)\n",
    "\n",
    "n_rows_with_nans_tau = tau_sttc_trial_avg_df['tau_ms'].isnull().sum()\n",
    "n_rows_with_nans_tau_perc = n_rows_with_nans_tau / len(tau_sttc_trial_avg_df) * 100\n",
    "# tau_df.dropna(inplace=True)\n",
    "\n",
    "print('acf n_rows_with_nans_perc {}, tau n_rows_with_nans_tau_perc {}'.format(n_rows_with_nans_perc, n_rows_with_nans_tau_perc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
