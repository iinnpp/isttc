{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f51a4e-eb0d-4189-ae6d-21d8d085b316",
   "metadata": {},
   "source": [
    "Calculate taus:\n",
    "\n",
    "on unit level:\n",
    "1. Pearsonr trial average\n",
    "2. STTC trial average\n",
    "3. STTC trial concat\n",
    "   \n",
    "on trial level (not calculated yet):\n",
    "1. Pearsonr per trial\n",
    "2. ACF proper per trial\n",
    "3. iSTTC per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264f77cb-1fa3-41c5-adc5-336c1d18c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from isttc.scripts.cfg_global import project_folder_path\n",
    "from isttc.tau import fit_single_exp, func_single_exp_monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdba1e5e-1c2e-479f-941c-c76e7d5b3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e172328e-a498-43a0-acec-db8b553551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_suffix = 'no'\n",
    "data_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms_' + empty_suffix + '_empty\\\\'\n",
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms_' + empty_suffix + '_empty\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf708d-0bcb-4354-b331-813d854b8500",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f824a74c-0158-404b-a864-b4d3cab41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tau_per_unit(acf_df_, acf_cols_, start_idx_):\n",
    "    \"\"\"\n",
    "    Calculate tau values per unit using single exponential fitting.\n",
    "\n",
    "    Parameters:\n",
    "    - acf_df (pd.DataFrame): DataFrame containing autocorrelation function (ACF) values.\n",
    "    - acf_cols (list): List of column names containing ACF data.\n",
    "    - start_idx (int): Starting index for fitting.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with fitting parameters and tau values per unit.\n",
    "    \"\"\"\n",
    "    acf_2d = acf_df_[acf_cols_].values.astype(np.float64)\n",
    "    n_units = acf_2d.shape[0]\n",
    "    print(f'Calculating taus for {acf_2d.shape}')\n",
    "    \n",
    "    results = [fit_single_exp(acf_2d[i, :], start_idx_, func_single_exp_monkey) for i in range(n_units)]\n",
    "\n",
    "    fit_popt_a, fit_popt_b, fit_popt_c, fit_tau, tau_ci_lower, tau_ci_upper, fit_r_squared, explained_var, fit_log_message = zip(*[\n",
    "        (fit_popt[0] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         fit_popt[1] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         fit_popt[2] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         tau, tau_ci[0], tau_ci[1], fit_r_squared, explained_var, log_msg)\n",
    "        for fit_popt, _, tau, tau_ci, fit_r_squared, explained_var, log_msg in results\n",
    "    ])\n",
    "\n",
    "    # fit_popt, fit_pcov, tau, tau_ci, fit_r_squared, explained_var, log_message\n",
    "\n",
    "    tau_df = pd.DataFrame({\n",
    "        'unit_id': acf_df_['unit_id'].values,\n",
    "        'fit_a': fit_popt_a,\n",
    "        'fit_b': fit_popt_b,\n",
    "        'fit_c': fit_popt_c,\n",
    "        'tau': fit_tau,\n",
    "        'tau_ci_lower': tau_ci_lower,\n",
    "        'tau_ci_upper': tau_ci_upper,\n",
    "        'r_squared': fit_r_squared,\n",
    "        'explained_var': explained_var,\n",
    "        'log_message': fit_log_message\n",
    "    })\n",
    "\n",
    "    float_cols = ['fit_a', 'fit_b', 'fit_c', 'tau', 'r_squared','explained_var', 'tau_ci_lower', 'tau_ci_upper']\n",
    "    tau_df[float_cols] = tau_df[float_cols].astype(float)\n",
    "    \n",
    "    return tau_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1494b-0434-480e-977a-458b4ac9c5bd",
   "metadata": {},
   "source": [
    "### Calculate tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d2f02-5b7c-4890-ad37-f713ae93d5ba",
   "metadata": {},
   "source": [
    "#### One tau per unit\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr trial average (as in the paper)\n",
    "* STTC trial average\n",
    "* STTC trial concat\n",
    "\n",
    "todo: take ACF average over trails for a unit and fit? Or fit all ACFs with one function? (this requires calculating ACF per trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545844af-2a85-4a85-8df2-e61c0b65bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf_cols ['acf_0', 'acf_1', 'acf_2', 'acf_3', 'acf_4', 'acf_5', 'acf_6', 'acf_7', 'acf_8', 'acf_9', 'acf_10', 'acf_11', 'acf_12', 'acf_13', 'acf_14', 'acf_15', 'acf_16', 'acf_17', 'acf_18', 'acf_19']\n"
     ]
    }
   ],
   "source": [
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd6aff-eea4-4941-b145-f2a4e60c82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'pfdl' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_lower_ms'] = tau_pearsonr_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_upper_ms'] = tau_pearsonr_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_lower_ms'] = tau_sttc_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_upper_ms'] = tau_sttc_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_lower_ms'] = tau_sttc_trial_concat_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_upper_ms'] = tau_sttc_trial_concat_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a998fa-5dd8-4dfc-ab0a-9df6222500d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_sttc_trial_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb70d25-bafe-4260-ba00-0ca69a7fba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_pearsonr_trial_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6516d2e1-ad61-4f87-b37d-90f6e8fb62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating taus for (538, 20)\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "Calculating taus for (538, 20)\n",
      "Calculating taus for (538, 20)\n"
     ]
    }
   ],
   "source": [
    "area = 'pfp' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_lower_ms'] = tau_pearsonr_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_upper_ms'] = tau_pearsonr_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_lower_ms'] = tau_sttc_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_upper_ms'] = tau_sttc_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_lower_ms'] = tau_sttc_trial_concat_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_upper_ms'] = tau_sttc_trial_concat_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1d080-4b63-48ce-97c8-e46d76b52693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculate unit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f10f5-705f-480f-a740-5d69ae4846fd",
   "metadata": {},
   "source": [
    "#### One tau per trial\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr\n",
    "* ACF formula\n",
    "* iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf31bf1-1c7c-4371-be0b-b3fdb491c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_lags = 20\n",
    "# bin_size = 50\n",
    "# acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "# print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2e68e-c325-4737-ba33-db125f8b1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = 'pfdl' \n",
    "\n",
    "# pearsonr \n",
    "# pearsonr_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(pearsonr_per_trial_df)}, dropping before tau calc ...')\n",
    "# pearsonr_per_trial_df.dropna(inplace=True)\n",
    "# pearsonr_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_pearsonr_per_trial_df = calc_tau_per_unit(pearsonr_per_trial_df, acf_cols[:-1], start_idx_=1)\n",
    "# tau_pearsonr_per_trial_df['tau_ms'] = tau_pearsonr_per_trial_df['tau'] * bin_size\n",
    "# tau_pearsonr_per_trial_df.insert(1, 'trial_id', pearsonr_per_trial_df['trial_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(2, 'condition_id', pearsonr_per_trial_df['condition_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(3, 'spike_count', pearsonr_per_trial_df['spike_count'])\n",
    "# tau_pearsonr_per_trial_df.insert(4, 'fr_hz', pearsonr_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_pearsonr_per_trial_df)}')\n",
    "# tau_pearsonr_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# # acf formula\n",
    "# pcf_proper_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pcf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(pcf_proper_per_trial_df)}, dropping before tau calc ...')\n",
    "# pcf_proper_per_trial_df.dropna(inplace=True)\n",
    "# pcf_proper_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_acf_proper_per_trial_df = calc_tau_per_unit(pcf_proper_per_trial_df, acf_cols, start_idx_=1)\n",
    "# tau_acf_proper_per_trial_df['tau_ms'] = tau_acf_proper_per_trial_df['tau'] * bin_size\n",
    "# tau_acf_proper_per_trial_df.insert(1, 'trial_id', pcf_proper_per_trial_df['trial_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(2, 'condition_id', pcf_proper_per_trial_df['condition_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(3, 'spike_count', pcf_proper_per_trial_df['spike_count'])\n",
    "# tau_acf_proper_per_trial_df.insert(4, 'fr_hz', pcf_proper_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_acf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_acf_proper_per_trial_df)}')\n",
    "# tau_acf_proper_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# # isttc\n",
    "# sttc_per_trial_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {sttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(sttc_per_trial_df)}, dropping before tau calc ...')\n",
    "# sttc_per_trial_df.dropna(inplace=True)\n",
    "# sttc_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_isttc_per_trial_df = calc_tau_per_unit(sttc_per_trial_df, acf_cols, start_idx_=1)\n",
    "# tau_isttc_per_trial_df['tau_ms'] = tau_isttc_per_trial_df['tau'] * bin_size\n",
    "# tau_isttc_per_trial_df.insert(1, 'trial_id', sttc_per_trial_df['trial_id'])\n",
    "# tau_isttc_per_trial_df.insert(2, 'condition_id', sttc_per_trial_df['condition_id'])\n",
    "# tau_isttc_per_trial_df.insert(3, 'spike_count', sttc_per_trial_df['spike_count'])\n",
    "# tau_isttc_per_trial_df.insert(4, 'fr_hz', sttc_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_isttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_isttc_per_trial_df)}')\n",
    "# tau_isttc_per_trial_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
