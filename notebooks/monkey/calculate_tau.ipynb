{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f51a4e-eb0d-4189-ae6d-21d8d085b316",
   "metadata": {},
   "source": [
    "Calculate taus:\n",
    "\n",
    "on unit level:\n",
    "1. Pearsonr trial average\n",
    "2. STTC trial average\n",
    "3. STTC trial concat\n",
    "   \n",
    "on trial level (not calculated yet):\n",
    "1. Pearsonr per trial\n",
    "2. ACF proper per trial\n",
    "3. iSTTC per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264f77cb-1fa3-41c5-adc5-336c1d18c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from calculate_tau import fit_single_exp, func_single_exp_monkey\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdba1e5e-1c2e-479f-941c-c76e7d5b3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e172328e-a498-43a0-acec-db8b553551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_suffix = 'no'\n",
    "data_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms_' + empty_suffix + '_empty\\\\'\n",
    "results_folder = project_folder_path + 'results\\\\monkey\\\\fixation_period_1000ms_' + empty_suffix + '_empty\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf708d-0bcb-4354-b331-813d854b8500",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f824a74c-0158-404b-a864-b4d3cab41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tau_per_unit(acf_df_, acf_cols_, start_idx_):\n",
    "    \"\"\"\n",
    "    Calculate tau values per unit using single exponential fitting.\n",
    "\n",
    "    Parameters:\n",
    "    - acf_df (pd.DataFrame): DataFrame containing autocorrelation function (ACF) values.\n",
    "    - acf_cols (list): List of column names containing ACF data.\n",
    "    - start_idx (int): Starting index for fitting.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with fitting parameters and tau values per unit.\n",
    "    \"\"\"\n",
    "    acf_2d = acf_df_[acf_cols_].values.astype(np.float64)\n",
    "    n_units = acf_2d.shape[0]\n",
    "    print(f'Calculating taus for {acf_2d.shape}')\n",
    "    \n",
    "    results = [fit_single_exp(acf_2d[i, :], start_idx_, func_single_exp_monkey) for i in range(n_units)]\n",
    "\n",
    "    fit_popt_a, fit_popt_b, fit_popt_c, fit_tau, tau_ci_lower, tau_ci_upper, fit_r_squared, explained_var, fit_log_message = zip(*[\n",
    "        (fit_popt[0] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         fit_popt[1] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         fit_popt[2] if isinstance(fit_popt, np.ndarray) else np.nan,\n",
    "         tau, tau_ci[0], tau_ci[1], fit_r_squared, explained_var, log_msg)\n",
    "        for fit_popt, _, tau, tau_ci, fit_r_squared, explained_var, log_msg in results\n",
    "    ])\n",
    "\n",
    "    # fit_popt, fit_pcov, tau, tau_ci, fit_r_squared, explained_var, log_message\n",
    "\n",
    "    tau_df = pd.DataFrame({\n",
    "        'unit_id': acf_df_['unit_id'].values,\n",
    "        'fit_a': fit_popt_a,\n",
    "        'fit_b': fit_popt_b,\n",
    "        'fit_c': fit_popt_c,\n",
    "        'tau': fit_tau,\n",
    "        'tau_ci_lower': tau_ci_lower,\n",
    "        'tau_ci_upper': tau_ci_upper,\n",
    "        'r_squared': fit_r_squared,\n",
    "        'explained_var': explained_var,\n",
    "        'log_message': fit_log_message\n",
    "    })\n",
    "\n",
    "    float_cols = ['fit_a', 'fit_b', 'fit_c', 'tau', 'r_squared','explained_var', 'tau_ci_lower', 'tau_ci_upper']\n",
    "    tau_df[float_cols] = tau_df[float_cols].astype(float)\n",
    "    \n",
    "    return tau_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1494b-0434-480e-977a-458b4ac9c5bd",
   "metadata": {},
   "source": [
    "### Calculate tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d2f02-5b7c-4890-ad37-f713ae93d5ba",
   "metadata": {},
   "source": [
    "#### One tau per unit\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr trial average (as in the paper)\n",
    "* STTC trial average\n",
    "* STTC trial concat\n",
    "\n",
    "todo: take ACF average over trails for a unit and fit? Or fit all ACFs with one function? (this requires calculating ACF per trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545844af-2a85-4a85-8df2-e61c0b65bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf_cols ['acf_0', 'acf_1', 'acf_2', 'acf_3', 'acf_4', 'acf_5', 'acf_6', 'acf_7', 'acf_8', 'acf_9', 'acf_10', 'acf_11', 'acf_12', 'acf_13', 'acf_14', 'acf_15', 'acf_16', 'acf_17', 'acf_18', 'acf_19']\n"
     ]
    }
   ],
   "source": [
    "n_lags = 20\n",
    "bin_size = 50\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccd6aff-eea4-4941-b145-f2a4e60c82fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating taus for (539, 20)\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "Calculating taus for (539, 20)\n",
      "Calculating taus for (539, 20)\n"
     ]
    }
   ],
   "source": [
    "area = 'pfdl' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_lower_ms'] = tau_pearsonr_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_upper_ms'] = tau_pearsonr_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_lower_ms'] = tau_sttc_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_upper_ms'] = tau_sttc_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_lower_ms'] = tau_sttc_trial_concat_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_upper_ms'] = tau_sttc_trial_concat_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a998fa-5dd8-4dfc-ab0a-9df6222500d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>fit_a</th>\n",
       "      <th>fit_b</th>\n",
       "      <th>fit_c</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_ci_lower</th>\n",
       "      <th>tau_ci_upper</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>explained_var</th>\n",
       "      <th>log_message</th>\n",
       "      <th>tau_ms</th>\n",
       "      <th>tau_ci_lower_ms</th>\n",
       "      <th>tau_ci_upper_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.506156</td>\n",
       "      <td>17.215169</td>\n",
       "      <td>-0.307676</td>\n",
       "      <td>17.215169</td>\n",
       "      <td>-3.592008</td>\n",
       "      <td>38.022347</td>\n",
       "      <td>0.909495</td>\n",
       "      <td>0.909495</td>\n",
       "      <td>ok</td>\n",
       "      <td>860.758472</td>\n",
       "      <td>-179.600422</td>\n",
       "      <td>1901.117367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.094437</td>\n",
       "      <td>24.765027</td>\n",
       "      <td>-0.816900</td>\n",
       "      <td>24.765027</td>\n",
       "      <td>-333.823036</td>\n",
       "      <td>383.353090</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>ok</td>\n",
       "      <td>1238.251336</td>\n",
       "      <td>-16691.151806</td>\n",
       "      <td>19167.654478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.138842</td>\n",
       "      <td>0.573731</td>\n",
       "      <td>-0.014887</td>\n",
       "      <td>0.573731</td>\n",
       "      <td>-12.137981</td>\n",
       "      <td>13.285444</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>ok</td>\n",
       "      <td>28.686571</td>\n",
       "      <td>-606.899055</td>\n",
       "      <td>664.272197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.237402</td>\n",
       "      <td>7.009008</td>\n",
       "      <td>0.526364</td>\n",
       "      <td>7.009008</td>\n",
       "      <td>3.113288</td>\n",
       "      <td>10.904728</td>\n",
       "      <td>0.910882</td>\n",
       "      <td>0.910882</td>\n",
       "      <td>ok</td>\n",
       "      <td>350.450396</td>\n",
       "      <td>155.664394</td>\n",
       "      <td>545.236399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.156735</td>\n",
       "      <td>3.752469</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>3.752469</td>\n",
       "      <td>-0.260158</td>\n",
       "      <td>7.765095</td>\n",
       "      <td>0.584113</td>\n",
       "      <td>0.584113</td>\n",
       "      <td>ok</td>\n",
       "      <td>187.623437</td>\n",
       "      <td>-13.007884</td>\n",
       "      <td>388.254758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>539</td>\n",
       "      <td>0.211762</td>\n",
       "      <td>4.036824</td>\n",
       "      <td>0.195305</td>\n",
       "      <td>4.036824</td>\n",
       "      <td>-2.072918</td>\n",
       "      <td>10.146567</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>ok</td>\n",
       "      <td>201.841211</td>\n",
       "      <td>-103.645906</td>\n",
       "      <td>507.328328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>540</td>\n",
       "      <td>0.341258</td>\n",
       "      <td>1.990948</td>\n",
       "      <td>-0.163937</td>\n",
       "      <td>1.990948</td>\n",
       "      <td>0.719622</td>\n",
       "      <td>3.262274</td>\n",
       "      <td>0.761931</td>\n",
       "      <td>0.761931</td>\n",
       "      <td>ok</td>\n",
       "      <td>99.547394</td>\n",
       "      <td>35.981090</td>\n",
       "      <td>163.113698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>541</td>\n",
       "      <td>0.641853</td>\n",
       "      <td>2.051229</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>2.051229</td>\n",
       "      <td>1.444164</td>\n",
       "      <td>2.658294</td>\n",
       "      <td>0.937158</td>\n",
       "      <td>0.937158</td>\n",
       "      <td>ok</td>\n",
       "      <td>102.561471</td>\n",
       "      <td>72.208224</td>\n",
       "      <td>132.914717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>542</td>\n",
       "      <td>0.302688</td>\n",
       "      <td>2.928117</td>\n",
       "      <td>-0.160552</td>\n",
       "      <td>2.928117</td>\n",
       "      <td>0.617339</td>\n",
       "      <td>5.238895</td>\n",
       "      <td>0.692949</td>\n",
       "      <td>0.692949</td>\n",
       "      <td>ok</td>\n",
       "      <td>146.405855</td>\n",
       "      <td>30.866963</td>\n",
       "      <td>261.944747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>543</td>\n",
       "      <td>1498.598576</td>\n",
       "      <td>0.095607</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.095607</td>\n",
       "      <td>-634.321621</td>\n",
       "      <td>634.512834</td>\n",
       "      <td>0.065839</td>\n",
       "      <td>0.065839</td>\n",
       "      <td>ok</td>\n",
       "      <td>4.780331</td>\n",
       "      <td>-31716.081055</td>\n",
       "      <td>31725.641716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_id        fit_a      fit_b     fit_c        tau  tau_ci_lower  \\\n",
       "0          0     0.506156  17.215169 -0.307676  17.215169     -3.592008   \n",
       "1          1     0.094437  24.765027 -0.816900  24.765027   -333.823036   \n",
       "2          2     0.138842   0.573731 -0.014887   0.573731    -12.137981   \n",
       "3          3     0.237402   7.009008  0.526364   7.009008      3.113288   \n",
       "4          4     0.156735   3.752469 -0.045313   3.752469     -0.260158   \n",
       "..       ...          ...        ...       ...        ...           ...   \n",
       "534      539     0.211762   4.036824  0.195305   4.036824     -2.072918   \n",
       "535      540     0.341258   1.990948 -0.163937   1.990948      0.719622   \n",
       "536      541     0.641853   2.051229  0.003317   2.051229      1.444164   \n",
       "537      542     0.302688   2.928117 -0.160552   2.928117      0.617339   \n",
       "538      543  1498.598576   0.095607 -0.000005   0.095607   -634.321621   \n",
       "\n",
       "     tau_ci_upper  r_squared  explained_var log_message       tau_ms  \\\n",
       "0       38.022347   0.909495       0.909495          ok   860.758472   \n",
       "1      383.353090   0.123333       0.123333          ok  1238.251336   \n",
       "2       13.285444   0.005730       0.005730          ok    28.686571   \n",
       "3       10.904728   0.910882       0.910882          ok   350.450396   \n",
       "4        7.765095   0.584113       0.584113          ok   187.623437   \n",
       "..            ...        ...            ...         ...          ...   \n",
       "534     10.146567   0.425317       0.425317          ok   201.841211   \n",
       "535      3.262274   0.761931       0.761931          ok    99.547394   \n",
       "536      2.658294   0.937158       0.937158          ok   102.561471   \n",
       "537      5.238895   0.692949       0.692949          ok   146.405855   \n",
       "538    634.512834   0.065839       0.065839          ok     4.780331   \n",
       "\n",
       "     tau_ci_lower_ms  tau_ci_upper_ms  \n",
       "0        -179.600422      1901.117367  \n",
       "1      -16691.151806     19167.654478  \n",
       "2        -606.899055       664.272197  \n",
       "3         155.664394       545.236399  \n",
       "4         -13.007884       388.254758  \n",
       "..               ...              ...  \n",
       "534      -103.645906       507.328328  \n",
       "535        35.981090       163.113698  \n",
       "536        72.208224       132.914717  \n",
       "537        30.866963       261.944747  \n",
       "538    -31716.081055     31725.641716  \n",
       "\n",
       "[539 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_sttc_trial_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccb70d25-bafe-4260-ba00-0ca69a7fba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>fit_a</th>\n",
       "      <th>fit_b</th>\n",
       "      <th>fit_c</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_ci_lower</th>\n",
       "      <th>tau_ci_upper</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>explained_var</th>\n",
       "      <th>log_message</th>\n",
       "      <th>tau_ms</th>\n",
       "      <th>tau_ci_lower_ms</th>\n",
       "      <th>tau_ci_upper_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.719056</td>\n",
       "      <td>19.290684</td>\n",
       "      <td>-0.347091</td>\n",
       "      <td>19.290684</td>\n",
       "      <td>-6.294044</td>\n",
       "      <td>44.875412</td>\n",
       "      <td>0.911963</td>\n",
       "      <td>0.911963</td>\n",
       "      <td>ok</td>\n",
       "      <td>964.534209</td>\n",
       "      <td>-314.702196</td>\n",
       "      <td>2243.770614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueError</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.110822</td>\n",
       "      <td>0.994330</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.994330</td>\n",
       "      <td>-8.054737</td>\n",
       "      <td>10.043397</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>ok</td>\n",
       "      <td>49.716504</td>\n",
       "      <td>-402.736854</td>\n",
       "      <td>502.169862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.279456</td>\n",
       "      <td>6.085777</td>\n",
       "      <td>0.663298</td>\n",
       "      <td>6.085777</td>\n",
       "      <td>2.853887</td>\n",
       "      <td>9.317667</td>\n",
       "      <td>0.902339</td>\n",
       "      <td>0.902339</td>\n",
       "      <td>ok</td>\n",
       "      <td>304.288860</td>\n",
       "      <td>142.694368</td>\n",
       "      <td>465.883353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.194176</td>\n",
       "      <td>3.603661</td>\n",
       "      <td>-0.088259</td>\n",
       "      <td>3.603661</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>6.648427</td>\n",
       "      <td>0.686497</td>\n",
       "      <td>0.686497</td>\n",
       "      <td>ok</td>\n",
       "      <td>180.183037</td>\n",
       "      <td>27.944734</td>\n",
       "      <td>332.421341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>539</td>\n",
       "      <td>0.200109</td>\n",
       "      <td>7.218432</td>\n",
       "      <td>0.110975</td>\n",
       "      <td>7.218432</td>\n",
       "      <td>-6.982118</td>\n",
       "      <td>21.418982</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>ok</td>\n",
       "      <td>360.921577</td>\n",
       "      <td>-349.105924</td>\n",
       "      <td>1070.949078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>540</td>\n",
       "      <td>0.475257</td>\n",
       "      <td>2.092072</td>\n",
       "      <td>-0.143533</td>\n",
       "      <td>2.092072</td>\n",
       "      <td>1.025133</td>\n",
       "      <td>3.159010</td>\n",
       "      <td>0.834083</td>\n",
       "      <td>0.834083</td>\n",
       "      <td>ok</td>\n",
       "      <td>104.603578</td>\n",
       "      <td>51.256647</td>\n",
       "      <td>157.950510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>541</td>\n",
       "      <td>0.809778</td>\n",
       "      <td>2.148375</td>\n",
       "      <td>-0.022680</td>\n",
       "      <td>2.148375</td>\n",
       "      <td>1.503493</td>\n",
       "      <td>2.793256</td>\n",
       "      <td>0.935643</td>\n",
       "      <td>0.935643</td>\n",
       "      <td>ok</td>\n",
       "      <td>107.418727</td>\n",
       "      <td>75.174664</td>\n",
       "      <td>139.662790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>542</td>\n",
       "      <td>0.277749</td>\n",
       "      <td>2.963283</td>\n",
       "      <td>-0.157117</td>\n",
       "      <td>2.963283</td>\n",
       "      <td>0.397074</td>\n",
       "      <td>5.529491</td>\n",
       "      <td>0.653134</td>\n",
       "      <td>0.653134</td>\n",
       "      <td>ok</td>\n",
       "      <td>148.164128</td>\n",
       "      <td>19.853704</td>\n",
       "      <td>276.474552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ValueError</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_id     fit_a      fit_b     fit_c        tau  tau_ci_lower  \\\n",
       "0          0  0.719056  19.290684 -0.347091  19.290684     -6.294044   \n",
       "1          1       NaN        NaN       NaN        NaN           NaN   \n",
       "2          2  0.110822   0.994330  0.019220   0.994330     -8.054737   \n",
       "3          3  0.279456   6.085777  0.663298   6.085777      2.853887   \n",
       "4          4  0.194176   3.603661 -0.088259   3.603661      0.558895   \n",
       "..       ...       ...        ...       ...        ...           ...   \n",
       "534      539  0.200109   7.218432  0.110975   7.218432     -6.982118   \n",
       "535      540  0.475257   2.092072 -0.143533   2.092072      1.025133   \n",
       "536      541  0.809778   2.148375 -0.022680   2.148375      1.503493   \n",
       "537      542  0.277749   2.963283 -0.157117   2.963283      0.397074   \n",
       "538      543       NaN        NaN       NaN        NaN           NaN   \n",
       "\n",
       "     tau_ci_upper  r_squared  explained_var log_message      tau_ms  \\\n",
       "0       44.875412   0.911963       0.911963          ok  964.534209   \n",
       "1             NaN        NaN            NaN  ValueError         NaN   \n",
       "2       10.043397   0.018581       0.018581          ok   49.716504   \n",
       "3        9.317667   0.902339       0.902339          ok  304.288860   \n",
       "4        6.648427   0.686497       0.686497          ok  180.183037   \n",
       "..            ...        ...            ...         ...         ...   \n",
       "534     21.418982   0.459831       0.459831          ok  360.921577   \n",
       "535      3.159010   0.834083       0.834083          ok  104.603578   \n",
       "536      2.793256   0.935643       0.935643          ok  107.418727   \n",
       "537      5.529491   0.653134       0.653134          ok  148.164128   \n",
       "538           NaN        NaN            NaN  ValueError         NaN   \n",
       "\n",
       "     tau_ci_lower_ms  tau_ci_upper_ms  \n",
       "0        -314.702196      2243.770614  \n",
       "1                NaN              NaN  \n",
       "2        -402.736854       502.169862  \n",
       "3         142.694368       465.883353  \n",
       "4          27.944734       332.421341  \n",
       "..               ...              ...  \n",
       "534      -349.105924      1070.949078  \n",
       "535        51.256647       157.950510  \n",
       "536        75.174664       139.662790  \n",
       "537        19.853704       276.474552  \n",
       "538              NaN              NaN  \n",
       "\n",
       "[539 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_pearsonr_trial_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6516d2e1-ad61-4f87-b37d-90f6e8fb62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating taus for (538, 20)\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n",
      "ValueError: array must not contain infs or NaNs\n",
      "Possible reason: acf contains NaNs, low spike count\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\monkey\\\\fixation_period_1000ms_no_empty\\\\non_binned\\\\pfp\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m tau_pearsonr_trial_avg_df\u001b[38;5;241m.\u001b[39mto_pickle(results_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinned\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m area \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtaus\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtau_pearsonr_trial_avg_1000ms_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m empty_suffix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_empty_50ms_20lags_df.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# sttc trial avg\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m sttc_trial_avg_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnon_binned\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marea\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43macf\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43macf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m tau_sttc_trial_avg_df \u001b[38;5;241m=\u001b[39m calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m tau_sttc_trial_avg_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tau_sttc_trial_avg_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m bin_size\n",
      "File \u001b[1;32m~\\.conda\\envs\\isttc\\Lib\\site-packages\\pandas\\io\\pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\isttc\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\monkey\\\\fixation_period_1000ms_no_empty\\\\non_binned\\\\pfp\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl'"
     ]
    }
   ],
   "source": [
    "area = 'pfp' \n",
    "\n",
    "# pearsonr trial avg\n",
    "pearsonr_trial_avg_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "tau_pearsonr_trial_avg_df = calc_tau_per_unit(pearsonr_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_pearsonr_trial_avg_df['tau_ms'] = tau_pearsonr_trial_avg_df['tau'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_lower_ms'] = tau_pearsonr_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_pearsonr_trial_avg_df['tau_ci_upper_ms'] = tau_pearsonr_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_pearsonr_trial_avg_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial avg\n",
    "sttc_trial_avg_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_avg_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_avg_df = calc_tau_per_unit(sttc_trial_avg_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_avg_df['tau_ms'] = tau_sttc_trial_avg_df['tau'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_lower_ms'] = tau_sttc_trial_avg_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_avg_df['tau_ci_upper_ms'] = tau_sttc_trial_avg_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_avg_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_avg_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# sttc trial concat\n",
    "sttc_trial_concat_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_sttc_trial_concat_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "tau_sttc_trial_concat_df = calc_tau_per_unit(sttc_trial_concat_df, acf_cols, start_idx_=1)\n",
    "tau_sttc_trial_concat_df['tau_ms'] = tau_sttc_trial_concat_df['tau'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_lower_ms'] = tau_sttc_trial_concat_df['tau_ci_lower'] * bin_size\n",
    "tau_sttc_trial_concat_df['tau_ci_upper_ms'] = tau_sttc_trial_concat_df['tau_ci_upper'] * bin_size\n",
    "tau_sttc_trial_concat_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_sttc_trial_concat_1000ms_' + empty_suffix + '_empty_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f10f5-705f-480f-a740-5d69ae4846fd",
   "metadata": {},
   "source": [
    "#### One tau per trial\n",
    "\n",
    "3 methods of doing that:\n",
    "* Pearsonr\n",
    "* ACF formula\n",
    "* iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf31bf1-1c7c-4371-be0b-b3fdb491c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_lags = 20\n",
    "# bin_size = 50\n",
    "# acf_cols = ['acf_' + str(i) for i in range(n_lags)]\n",
    "# print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2e68e-c325-4737-ba33-db125f8b1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = 'pfdl' \n",
    "\n",
    "# pearsonr \n",
    "# pearsonr_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(pearsonr_per_trial_df)}, dropping before tau calc ...')\n",
    "# pearsonr_per_trial_df.dropna(inplace=True)\n",
    "# pearsonr_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_pearsonr_per_trial_df = calc_tau_per_unit(pearsonr_per_trial_df, acf_cols[:-1], start_idx_=1)\n",
    "# tau_pearsonr_per_trial_df['tau_ms'] = tau_pearsonr_per_trial_df['tau'] * bin_size\n",
    "# tau_pearsonr_per_trial_df.insert(1, 'trial_id', pearsonr_per_trial_df['trial_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(2, 'condition_id', pearsonr_per_trial_df['condition_id'])\n",
    "# tau_pearsonr_per_trial_df.insert(3, 'spike_count', pearsonr_per_trial_df['spike_count'])\n",
    "# tau_pearsonr_per_trial_df.insert(4, 'fr_hz', pearsonr_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_pearsonr_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_pearsonr_per_trial_df)}')\n",
    "# tau_pearsonr_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_pearsonr_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# # acf formula\n",
    "# pcf_proper_per_trial_df = pd.read_pickle(results_folder + 'binned\\\\' + area + '\\\\acf\\\\acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {pcf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(pcf_proper_per_trial_df)}, dropping before tau calc ...')\n",
    "# pcf_proper_per_trial_df.dropna(inplace=True)\n",
    "# pcf_proper_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_acf_proper_per_trial_df = calc_tau_per_unit(pcf_proper_per_trial_df, acf_cols, start_idx_=1)\n",
    "# tau_acf_proper_per_trial_df['tau_ms'] = tau_acf_proper_per_trial_df['tau'] * bin_size\n",
    "# tau_acf_proper_per_trial_df.insert(1, 'trial_id', pcf_proper_per_trial_df['trial_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(2, 'condition_id', pcf_proper_per_trial_df['condition_id'])\n",
    "# tau_acf_proper_per_trial_df.insert(3, 'spike_count', pcf_proper_per_trial_df['spike_count'])\n",
    "# tau_acf_proper_per_trial_df.insert(4, 'fr_hz', pcf_proper_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_acf_proper_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_acf_proper_per_trial_df)}')\n",
    "# tau_acf_proper_per_trial_df.to_pickle(results_folder + 'binned\\\\' + area + '\\\\taus\\\\tau_acf_proper_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "\n",
    "# # isttc\n",
    "# sttc_per_trial_df = pd.read_pickle(results_folder + 'non_binned\\\\' + area + '\\\\acf\\\\acf_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')\n",
    "# print(f'N rows with NaN {sttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(sttc_per_trial_df)}, dropping before tau calc ...')\n",
    "# sttc_per_trial_df.dropna(inplace=True)\n",
    "# sttc_per_trial_df.reset_index(drop=True, inplace=True)\n",
    "# tau_isttc_per_trial_df = calc_tau_per_unit(sttc_per_trial_df, acf_cols, start_idx_=1)\n",
    "# tau_isttc_per_trial_df['tau_ms'] = tau_isttc_per_trial_df['tau'] * bin_size\n",
    "# tau_isttc_per_trial_df.insert(1, 'trial_id', sttc_per_trial_df['trial_id'])\n",
    "# tau_isttc_per_trial_df.insert(2, 'condition_id', sttc_per_trial_df['condition_id'])\n",
    "# tau_isttc_per_trial_df.insert(3, 'spike_count', sttc_per_trial_df['spike_count'])\n",
    "# tau_isttc_per_trial_df.insert(4, 'fr_hz', sttc_per_trial_df['fr_hz'])\n",
    "# print(f'N rows with NaN {tau_isttc_per_trial_df.isnull().any(axis=1).sum()} out of {len(tau_isttc_per_trial_df)}')\n",
    "# tau_isttc_per_trial_df.to_pickle(results_folder + 'non_binned\\\\' + area + '\\\\taus\\\\tau_isttc_per_trial_1000ms_with_empty_50ms_20lags_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
