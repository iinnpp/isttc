{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d26204e-a3f8-4427-a73d-499b764a51f2",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Take the full signal and randomly pick N trials\n",
    "2. Calculate Pearson trial-average\n",
    "3. Calculate STTC trial-average\n",
    "4. Calculate STTC on concatenated data\n",
    "5. Compare 2,3,4, values calculated on full signal, and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d5b39b-6558-4e4a-a238-1d1521fcd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "# IP import warnings because of \"module 'numpy' has no attribute 'warnings'\"\n",
    "import warnings\n",
    "np.warnings = warnings\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.optimize import curve_fit, OptimizeWarning\n",
    "#from sklearn.metrics import r2_score\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "os.chdir(os.path.expanduser(\"D:\\\\intr_timescales\\\\isttc\\\\scripts\"))\n",
    "#os.chdir(os.path.expanduser(\"C:\\\\Users\\\\ipoch\\\\Documents\\\\repos\\\\isttc\\\\scripts\"))\n",
    "from calculate_acf import acf_sttc, acf_pearsonr_trial_avg, acf_sttc_trial_avg, acf_sttc_trial_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9b715-8f16-44ff-a720-311c2fbfcd88",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef635d5-4556-49bf-9437-72eccccb9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = np.load('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\spike_times.npy')\n",
    "ou_spiketrain_binned = np.load('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\ou_spiketrain_binned.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4543c43-7a31-48a8-aba3-de91ea663701",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lags = 20\n",
    "bin_size = 50\n",
    "sttc_dt = 49\n",
    "signal_len = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a945d46-44bc-4c2d-989e-d19a2c6dd7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_exp_abc_like(x, a, tau):\n",
    "    return a * np.exp(-x/tau) \n",
    "\n",
    "def func_single_exp_monkey_like(x, a, b, c):\n",
    "    #return a * np.exp(-b * x) + c\n",
    "    return a * (np.exp(-b * x) + c) # as in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849fbe3-d2b6-4eaf-bc71-5ce53eb7c63a",
   "metadata": {},
   "source": [
    "### Calculate acf and sttc for the full signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759ab17-ea10-4f90-a7cf-46fea0c31d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_axes = np.linspace(0,num_lags,num_lags+1).astype(int)\n",
    "print(t_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a20e32-2082-4f56-b936-939733aec04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using acf func\n",
    "spike_train_binned_acf = acf(ou_spiketrain_binned[0], nlags=num_lags)\n",
    "print('spike_train_binned_acf shape {}, \\nspike_train_binned_acf: {}'.format(spike_train_binned_acf.shape, spike_train_binned_acf))\n",
    "\n",
    "# Using isttc\n",
    "spike_train_acf = acf_sttc(spike_times, num_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, signal_length_=signal_len, verbose_=False)\n",
    "print('spike_train_acf shape {}, \\nspike_train_acf: {}'.format(len(spike_train_acf), spike_train_acf))\n",
    "\n",
    "# calculate tau\n",
    "spike_train_binned_popt, _ = curve_fit(func_single_exp_monkey_like, t_axes, spike_train_binned_acf, maxfev=5000)\n",
    "spike_train_binned_tau_ms = (1/spike_train_binned_popt[1]) * bin_size\n",
    "print('spike_train_binned_popt: {}, spike_train_binned_tau_ms: {}'.format(spike_train_binned_popt, spike_train_binned_tau_ms))\n",
    "\n",
    "spike_train_popt, _ = curve_fit(func_single_exp_monkey_like, t_axes, spike_train_acf, maxfev=5000)\n",
    "spike_train_tau_ms = (1/spike_train_popt[1]) * bin_size\n",
    "print('spike_train_popt: {}, spike_train_tau_ms: {}'.format(spike_train_popt, spike_train_tau_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4e002-650e-47eb-9a2d-a6ab2a642ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(8,3))\n",
    "\n",
    "axes[0].plot(t_axes, spike_train_binned_acf, c='orange', label='acf')\n",
    "axes[0].plot(t_axes, func_single_exp_monkey_like(t_axes, spike_train_binned_popt[0], spike_train_binned_popt[1], spike_train_binned_popt[2]), \n",
    "             label='fitted')\n",
    "axes[0].axvline(x=spike_train_binned_popt[1], lw=0.5, color='red')\n",
    "axes[0].set_title('ACF, tau={}, diff={}'.format(np.round(spike_train_binned_tau_ms, 2), np.round(100-spike_train_binned_tau_ms, 2)))\n",
    "axes[0].set_xticks(np.linspace(0,20,6))\n",
    "axes[0].set_xticklabels(np.linspace(0,1000,6).astype(int))\n",
    "\n",
    "axes[1].plot(t_axes, spike_train_acf, c='orange', label='isttc')\n",
    "axes[1].plot(t_axes, func_single_exp_monkey_like(t_axes, spike_train_popt[0], spike_train_popt[1], spike_train_popt[2]), label='fitted')\n",
    "axes[1].axvline(x=spike_train_popt[1], lw=0.5, color='red')\n",
    "axes[1].set_title('iSTTC, tau={}, diff={}'.format(np.round(spike_train_tau_ms, 2), np.round(100-spike_train_tau_ms, 2)))\n",
    "axes[1].set_xticks(np.linspace(0,20,6))\n",
    "axes[1].set_xticklabels(np.linspace(0,1000,6).astype(int))\n",
    "\n",
    "fig.suptitle('Full signal', y=1.05)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.legend(frameon=False)\n",
    "    ax.axvline(x=2, lw=0.5, color='k')\n",
    "    ax.axhline(y=0, lw=0.5, color='k')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('ACF')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "#fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\figs\\\\' + 'full_signal.png' , bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed50ffd-c22f-4fab-b74d-af9a2c279deb",
   "metadata": {},
   "source": [
    "### Make trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bc3d1-ffbc-4ca4-bff0-445a5b65c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(spike_times_, signal_len_, n_trials_, trial_len_, verbose_=False):\n",
    "    # get random trail starts and ends\n",
    "    trials_start = [randrange(0, signal_len_-trial_len_+1) for i in range(n_trials_)]\n",
    "    trials_end = [trial_start + trial_len_ for trial_start in trials_start]\n",
    "    trial_intervals = np.vstack((trials_start, trials_end)).T\n",
    "    if verbose_:\n",
    "        print('N trials {}, trail len {}, n trial starts {}, \\ntrial starts {}, \\ntrial starts {}'.format(n_trials_, trial_len_, \n",
    "                                                                                                          len(trials_start), \n",
    "                                                                                                          trials_start, trials_end))\n",
    "    # get spikes\n",
    "    spikes_trials = []\n",
    "    for i in range(n_trials_):\n",
    "        spikes_trial = spike_times_[np.logical_and(spike_times_ >= trial_intervals[i,0], spike_times_ < trial_intervals[i,1])]\n",
    "        spikes_trials.append(spikes_trial)\n",
    "\n",
    "    # realign all trails to start with 0\n",
    "    spikes_trials_realigned_l = []\n",
    "    for idx, trial in enumerate(spikes_trials):\n",
    "        spikes_trial_realigned = trial - trial_intervals[idx,0] \n",
    "        spikes_trials_realigned_l.append(spikes_trial_realigned)\n",
    "\n",
    "    return spikes_trials_realigned_l\n",
    "\n",
    "def bin_trials(spikes_trials_l_, trial_len_, bin_size_):\n",
    "    binned_spikes_trials_l = []\n",
    "\n",
    "    n_bin_edges =  int(trial_len_/bin_size_)\n",
    "    bins_ = np.linspace(0, bin_size * n_bin_edges, n_bin_edges + 1).astype(int)\n",
    "    for trial in spikes_trials_l_:\n",
    "        binned_spike_train, _ = np.histogram(trial, bins_)\n",
    "        binned_spikes_trials_l.append(binned_spike_train)\n",
    "    binned_spikes_trials_2d = np.asarray(binned_spikes_trials_l)\n",
    "\n",
    "    return binned_spikes_trials_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203802da-6266-456e-acaf-5230ee747153",
   "metadata": {},
   "source": [
    "### Run for one trial realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ee6c5c-a65e-4f34-a405-b05d97363cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 30\n",
    "trial_len = num_lags * bin_size\n",
    "\n",
    "#spikes_trials_30 = get_trials(spike_times, signal_len, n_trials, trial_len, verbose_=False)\n",
    "#spikes_trials_30_binned = bin_trials(spikes_trials_30, trial_len, bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc3fc1-2cac-4d22-8916-5d384cbe1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_30_runs_1\\\\spikes_trials_30.npy', \n",
    "#         np.asarray(spikes_trials_30, dtype='object'))\n",
    "# np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_30_runs_1\\\\spikes_trials_30_binned.npy', \n",
    "#         spikes_trials_30_binned, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b102f81d-9ac3-4ec8-8272-8aa5d37e7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_trials_30 = np.load('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_30_runs_1\\\\spikes_trials_30.npy', \n",
    "                           allow_pickle=True)\n",
    "spikes_trials_30_binned = np.load('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_30_runs_1\\\\spikes_trials_30_binned.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2515df2-4da1-46cc-bf10-e650c1f70145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_bins to use 20\n",
      "55.03184201908251\n",
      "66.55308493335758\n",
      "83.14618805426548\n"
     ]
    }
   ],
   "source": [
    "# Pearson trial-average\n",
    "acf_matrix_trail_avg, acf_average_trial_avg = acf_pearsonr_trial_avg(spikes_trials_30_binned, n_lags_=num_lags)\n",
    "spike_train_trial_avg_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), acf_average_trial_avg, maxfev=5000)\n",
    "spike_train_trial_avg_tau_ms = (1/spike_train_trial_avg_popt[1]) * bin_size\n",
    "print(spike_train_trial_avg_tau_ms)\n",
    "\n",
    "# STTC trial-average\n",
    "sttc_matrix_trail_avg, sttc_average_trial_avg = acf_sttc_trial_avg(spikes_trials_30, \n",
    "                                                                   n_lags_ = num_lags,\n",
    "                                                                   lag_shift_=bin_size, \n",
    "                                                                   zero_padding_len_=150, \n",
    "                                                                   sttc_dt_=sttc_dt, \n",
    "                                                                   verbose_=False)\n",
    "spike_train_trial_avg_sttc_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), sttc_average_trial_avg, maxfev=5000)\n",
    "spike_train_trial_avg_sttc_tau_ms = (1/spike_train_trial_avg_sttc_popt[1]) * bin_size\n",
    "print(spike_train_trial_avg_sttc_tau_ms)\n",
    "\n",
    "# STTC concat\n",
    "acf_sttc_trial_concat_v2 = acf_sttc_trial_concat(spikes_trials_30, \n",
    "                                                                      n_lags_ = num_lags,\n",
    "                                                                      lag_shift_=bin_size, \n",
    "                                                                      sttc_dt_=sttc_dt, \n",
    "                                                                      trial_len_=trial_len, \n",
    "                                                                      zero_padding_len_=2000,\n",
    "                                                                      verbose_=False)\n",
    "spike_train_trial_concat_sttc_v2_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,num_lags-1,num_lags), acf_sttc_trial_concat_v2, maxfev=5000)\n",
    "spike_train_trial_concat_sttc_v2_tau_ms = (1/spike_train_trial_concat_sttc_v2_popt[1]) * bin_size\n",
    "print(spike_train_trial_concat_sttc_v2_tau_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade41cd-60d2-458a-a331-d1cf99f71a2d",
   "metadata": {},
   "source": [
    "### Run for multiple realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03008c06-b252-4b6a-94c1-18027f954710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run for 100 realizations\n",
    "n_stims = 500\n",
    "\n",
    "n_trials = 100\n",
    "trial_len = num_lags * bin_size\n",
    "\n",
    "pearson_avg_l = []\n",
    "sttc_avg_l = []\n",
    "sttc_concat_l = []\n",
    "stim_l = []\n",
    "\n",
    "for i in range(n_stims):\n",
    "    print(f'Run {i}')\n",
    "    spikes_trials_stim = get_trials(spike_times, signal_len, n_trials, trial_len, verbose_=False)\n",
    "    spikes_trials_binned_stim = bin_trials(spikes_trials_stim, trial_len, bin_size)\n",
    "\n",
    "    np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\spikes_trials_stim_run' + str(i) \n",
    "            + '.npy', np.asarray(spikes_trials_stim, dtype='object'))\n",
    "    np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\spikes_trials_binned_stim' + str(i) \n",
    "            + '.npy', spikes_trials_binned_stim, allow_pickle=True)\n",
    "\n",
    "    # Pearson trial-average\n",
    "    acf_matrix_trail_avg, acf_average_trial_avg = acf_pearsonr_trial_avg(spikes_trials_binned_stim, n_lags_=num_lags, verbose_=False)\n",
    "    spike_train_trial_avg_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), acf_average_trial_avg, maxfev=5000)\n",
    "    spike_train_trial_avg_tau_ms = (1/spike_train_trial_avg_popt[1]) * bin_size\n",
    "    #print(spike_train_trial_avg_tau_ms)\n",
    "    \n",
    "    # STTC trial-average\n",
    "    sttc_matrix_trail_avg, sttc_average_trial_avg = acf_sttc_trial_avg(spikes_trials_stim, \n",
    "                                                                       lag_shift_=bin_size, \n",
    "                                                                       zero_padding_len_=120, \n",
    "                                                                       fs_=1000, \n",
    "                                                                       sttc_dt_=sttc_dt, \n",
    "                                                                       verbose_=False)\n",
    "    spike_train_trial_avg_sttc_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), sttc_average_trial_avg, maxfev=5000)\n",
    "    spike_train_trial_avg_sttc_tau_ms = (1/spike_train_trial_avg_sttc_popt[1]) * bin_size\n",
    "    #print(spike_train_trial_avg_sttc_tau_ms)\n",
    "\n",
    "    # STTC concat v3\n",
    "    acf_sttc_trial_concat = acf_sttc_trail_concat(spikes_trials_stim, \n",
    "                                                                          n_lags_ = num_lags,\n",
    "                                                                          lag_shift_=bin_size, \n",
    "                                                                          sttc_dt_=sttc_dt, \n",
    "                                                                          trial_len_=trial_len, \n",
    "                                                                          zero_padding_len_=2000,\n",
    "                                                                          verbose_=False)\n",
    "    spike_train_trial_concat_sttc_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,num_lags-1,num_lags), acf_sttc_trial_concat, maxfev=5000)\n",
    "    spike_train_trial_concat_sttc_tau_ms = (1/spike_train_trial_concat_sttc_popt[1]) * bin_size\n",
    "    #print(spike_train_trial_concat_sttc_v2_tau_ms)\n",
    "\n",
    "    stim_l.append(i)\n",
    "    pearson_avg_l.append(spike_train_trial_avg_tau_ms)\n",
    "    sttc_avg_l.append(spike_train_trial_avg_sttc_tau_ms)\n",
    "    sttc_concat_l.append(spike_train_trial_concat_sttc_tau_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f7e38-7cea-45e8-b5bb-f75462d6be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df = pd.DataFrame(np.vstack((stim_l, pearson_avg_l, sttc_avg_l, sttc_concat_l)).T, \n",
    "                      columns=['run_id', 'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'])\n",
    "tau_df_long = pd.melt(tau_df, id_vars=['run_id'], value_vars=['tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'], \n",
    "                      value_name='tau_ms', var_name='method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051940a-26d2-4798-bba2-b87f94ad91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34ecbe-9bbd-4a08-bd23-0afebc81ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df.to_pickle('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\tau_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d270b-82b4-4eab-b325-b2aa53005c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b8a0f-06a6-4335-8354-ab80eb0d6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,3))\n",
    "\n",
    "sns.violinplot(ax=axes[0], x='method', y='tau_ms', data=tau_df_long, cut=0,  density_norm='width')\n",
    "axes[0].axhline(y=100, color='k')\n",
    "\n",
    "sns.violinplot(ax=axes[1], x='method', y='tau_ms', data=tau_df_long, cut=0,  density_norm='width')\n",
    "axes[1].axhline(y=100, color='k')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "fig.suptitle('trials_100_runs_500, tau=100. Median: P_avg: {}, STTC_avg: {}, STTC_concat: {}'\n",
    "             .format(np.round(np.nanmedian(tau_df['tau_pearsonr_avg'].values), 2),\n",
    "             np.round(np.nanmedian(tau_df['tau_sttc_avg']), 2), np.round(np.nanmedian(tau_df['tau_sttc_concat']), 2)), y=1.05)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\' \n",
    "            + 'taus.png' , bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e812566-1537-44b9-9ebd-20d24898ccc0",
   "metadata": {},
   "source": [
    "### Calculate on 100 signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc1bdd-c676-4c78-bb7f-108921b9d494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e931cd-e590-450f-aa9a-81d398b8b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_folder = 'Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\dataset\\\\'\n",
    "dataset_folder = 'D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\dataset\\\\'\n",
    "\n",
    "n_signals = 100\n",
    "\n",
    "acf_full = []\n",
    "sttc_full = []\n",
    "pearsonr_avg_trial_med = []\n",
    "sttc_avg_trial_med = []\n",
    "sttc_concat_trial_med = []\n",
    "\n",
    "for i in range(50):\n",
    "    print('Processing {}'.format(i))\n",
    "    print(dataset_folder + 'spike_times_' + str(i) + '.npy')\n",
    "    print(dataset_folder + 'spike_times_binned_' + str(i) + '.npy')\n",
    "\n",
    "    spike_times = np.load(dataset_folder + 'spike_times_' + str(i) + '.npy')\n",
    "    ou_spiketrain_binned = np.load(dataset_folder + 'spike_times_binned_' + str(i) + '.npy')\n",
    "\n",
    "    # on full signal\n",
    "    # Using acf func\n",
    "    spike_train_binned_acf = acf(ou_spiketrain_binned[0], nlags=num_lags)\n",
    "    #print('spike_train_binned_acf shape {}, \\nspike_train_binned_acf: {}'.format(spike_train_binned_acf.shape, spike_train_binned_acf))\n",
    "    spike_train_binned_popt, _ = curve_fit(func_single_exp_monkey_like, t_axes, spike_train_binned_acf, maxfev=5000)\n",
    "    spike_train_binned_tau_ms = (1/spike_train_binned_popt[1]) * bin_size\n",
    "    #print('spike_train_binned_popt: {}, spike_train_binned_tau_ms: {}'.format(spike_train_binned_popt, spike_train_binned_tau_ms))\n",
    "    acf_full.append(spike_train_binned_tau_ms)\n",
    "    \n",
    "    # Using isttc\n",
    "    spike_train_acf = acf_sttc(spike_times, num_lags, lag_shift_=bin_size, sttc_dt_=sttc_dt, signal_length_=signal_len, verbose_=False)\n",
    "    #print('spike_train_acf shape {}, \\nspike_train_acf: {}'.format(len(spike_train_acf), spike_train_acf))\n",
    "    spike_train_popt, _ = curve_fit(func_single_exp_monkey_like, t_axes, spike_train_acf, maxfev=5000)\n",
    "    spike_train_tau_ms = (1/spike_train_popt[1]) * bin_size\n",
    "    #print('spike_train_popt: {}, spike_train_tau_ms: {}'.format(spike_train_popt, spike_train_tau_ms))\n",
    "    sttc_full.append(spike_train_tau_ms)\n",
    "\n",
    "    # # on trials\n",
    "    # ### Run for 500 realizations\n",
    "    # n_stims = 50\n",
    "    \n",
    "    # n_trials = 30\n",
    "    # trial_len = num_lags * bin_size\n",
    "    \n",
    "    # pearson_avg_l = []\n",
    "    # sttc_avg_l = []\n",
    "    # sttc_concat_l = []\n",
    "    # stim_l = []\n",
    "    \n",
    "    # for j in range(n_stims):\n",
    "    #     #print(f'Run {j}')\n",
    "    #     spikes_trials_stim = get_trials(spike_times, signal_len, n_trials, trial_len, verbose_=False)\n",
    "    #     spikes_trials_binned_stim = bin_trials(spikes_trials_stim, trial_len, bin_size)\n",
    "    \n",
    "    #     # np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\spikes_trials_stim_run' + str(i) \n",
    "    #     #         + '.npy', np.asarray(spikes_trials_stim, dtype='object'))\n",
    "    #     # np.save('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split\\\\trials_100_runs_500\\\\spikes_trials_binned_stim' + str(i) \n",
    "    #     #         + '.npy', spikes_trials_binned_stim, allow_pickle=True)\n",
    "    \n",
    "    #     # Pearson trial-average\n",
    "    #     acf_matrix_trail_avg, acf_average_trial_avg = acf_pearsonr_trial_avg(spikes_trials_binned_stim, n_lags_=num_lags, verbose_=False)\n",
    "    #     spike_train_trial_avg_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), acf_average_trial_avg, maxfev=5000)\n",
    "    #     spike_train_trial_avg_tau_ms = (1/spike_train_trial_avg_popt[1]) * bin_size\n",
    "    #     #print(spike_train_trial_avg_tau_ms)\n",
    "        \n",
    "    #     # STTC trial-average\n",
    "    #     sttc_matrix_trail_avg, sttc_average_trial_avg = acf_sttc_trial_avg(spikes_trials_stim, \n",
    "    #                                                                        lag_shift_=bin_size, \n",
    "    #                                                                        zero_padding_len_=120, \n",
    "    #                                                                        fs_=1000, \n",
    "    #                                                                        sttc_dt_=sttc_dt, \n",
    "    #                                                                        verbose_=False)\n",
    "    #     spike_train_trial_avg_sttc_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,19,20), sttc_average_trial_avg, maxfev=5000)\n",
    "    #     spike_train_trial_avg_sttc_tau_ms = (1/spike_train_trial_avg_sttc_popt[1]) * bin_size\n",
    "    #     #print(spike_train_trial_avg_sttc_tau_ms)\n",
    "    \n",
    "    #     # STTC concat v3\n",
    "    #     acf_sttc_trial_concat = acf_sttc_trail_concat(spikes_trials_stim, \n",
    "    #                                                                           n_lags_ = num_lags,\n",
    "    #                                                                           lag_shift_=bin_size, \n",
    "    #                                                                           sttc_dt_=sttc_dt, \n",
    "    #                                                                           trial_len_=trial_len, \n",
    "    #                                                                           zero_padding_len_=2000,\n",
    "    #                                                                           verbose_=False)\n",
    "    #     spike_train_trial_concat_sttc_popt, _ = curve_fit(func_single_exp_monkey_like, np.linspace(0,num_lags-1,num_lags), acf_sttc_trial_concat, maxfev=5000)\n",
    "    #     spike_train_trial_concat_sttc_tau_ms = (1/spike_train_trial_concat_sttc_popt[1]) * bin_size\n",
    "    #     #print(spike_train_trial_concat_sttc_v2_tau_ms)\n",
    "    \n",
    "    #     stim_l.append(j)\n",
    "    #     pearson_avg_l.append(spike_train_trial_avg_tau_ms)\n",
    "    #     sttc_avg_l.append(spike_train_trial_avg_sttc_tau_ms)\n",
    "    #     sttc_concat_l.append(spike_train_trial_concat_sttc_tau_ms)\n",
    "\n",
    "    # tau_df = pd.DataFrame(np.vstack((stim_l, pearson_avg_l, sttc_avg_l, sttc_concat_l)).T, \n",
    "    #                   columns=['run_id', 'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'])\n",
    "\n",
    "    # # tau_df.to_pickle('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods\\\\trial_tau_df\\\\tau_df_' \n",
    "    # #                      + str(i) + '.pkl')\n",
    "    # tau_df.to_pickle('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\trial_tau_df\\\\tau_df_' \n",
    "    #                  + str(i) + '.pkl')\n",
    "\n",
    "    # pearsonr_avg_trial_med.append(np.nanmedian(pearson_avg_l))\n",
    "    # sttc_avg_trial_med.append(np.nanmedian(sttc_avg_l))\n",
    "    # sttc_concat_trial_med.append(np.nanmedian(sttc_concat_l))\n",
    "\n",
    "    # # save the plot\n",
    "    # tau_df_long = pd.melt(tau_df, id_vars=['run_id'], value_vars=['tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'], \n",
    "    #                   value_name='tau_ms', var_name='method')\n",
    "    \n",
    "    # fig, axes = plt.subplots(1,2, figsize=(10,3))\n",
    "\n",
    "    # sns.violinplot(ax=axes[0], x='method', y='tau_ms', data=tau_df_long, cut=0,  density_norm='width')\n",
    "    # axes[0].axhline(y=100, color='k')\n",
    "    \n",
    "    # sns.violinplot(ax=axes[1], x='method', y='tau_ms', data=tau_df_long, cut=0,  density_norm='width')\n",
    "    # axes[1].axhline(y=100, color='k')\n",
    "    # axes[1].set_yscale('log')\n",
    "    \n",
    "    # fig.suptitle('trials_30_runs_500, tau=100. Median: P_avg: {}, STTC_avg: {}, STTC_concat: {}'\n",
    "    #              .format(np.round(np.nanmedian(tau_df['tau_pearsonr_avg'].values), 2),\n",
    "    #              np.round(np.nanmedian(tau_df['tau_sttc_avg']), 2), np.round(np.nanmedian(tau_df['tau_sttc_concat']), 2)), y=1.05)\n",
    "    \n",
    "    # sns.despine()\n",
    "    \n",
    "    # # fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods\\\\trial_tau_figs\\\\' \n",
    "    # #             + 'taus' + str(i) + '.png' , bbox_inches='tight')\n",
    "    # fig.savefig('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\trial_tau_figs\\\\' \n",
    "    #             + 'taus' + str(i) + '.png' , bbox_inches='tight')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f13e27-cce9-445c-aeee-995e7314c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr_avg_trial_med = []\n",
    "sttc_avg_trial_med = []\n",
    "sttc_concat_trial_med = []\n",
    "\n",
    "for k in range(50):\n",
    "    tau_df = pd.read_pickle('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\trial_tau_df\\\\tau_df_' + str(k) + '.pkl')\n",
    "    pearsonr_avg_trial_med.append(np.nanmedian(tau_df['tau_pearsonr_avg']))\n",
    "    sttc_avg_trial_med.append(np.nanmedian(tau_df['tau_sttc_avg']))\n",
    "    sttc_concat_trial_med.append(np.nanmedian(tau_df['tau_sttc_concat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60865764-1418-4ef0-b57d-22cc187bf432",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_df = pd.DataFrame(np.vstack((np.linspace(0,49, 50).astype(int), acf_full, sttc_full, \n",
    "                                         pearsonr_avg_trial_med, sttc_avg_trial_med, sttc_concat_trial_med)).T, \n",
    "                  columns=['signal_id', 'tau_acf_full', 'tau_sttc_full', 'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97b01e-d979-445f-a5d0-25f11c5c4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf82d5-4e07-4177-a344-90fb5fef59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_diff_df = pd.DataFrame(np.vstack((np.linspace(0,49, 50).astype(int),\n",
    "                                               100-np.asarray(acf_full), \n",
    "                                               100-np.asarray(sttc_full), \n",
    "                                         100-np.asarray(pearsonr_avg_trial_med), \n",
    "                                               100-np.asarray(sttc_avg_trial_med), \n",
    "                                               100-np.asarray(sttc_concat_trial_med))).T, \n",
    "                  columns=['signal_id', 'tau_acf_full', 'tau_sttc_full', 'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558c134-0937-4160-8e97-d4987566ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_diff_abs_df = pd.DataFrame(np.vstack((np.linspace(0,49, 50).astype(int),\n",
    "                                               np.abs(100-np.asarray(acf_full)), \n",
    "                                               np.abs(100-np.asarray(sttc_full)), \n",
    "                                               np.abs(100-np.asarray(pearsonr_avg_trial_med)), \n",
    "                                               np.abs(100-np.asarray(sttc_avg_trial_med)), \n",
    "                                               np.abs(100-np.asarray(sttc_concat_trial_med)))).T, \n",
    "                  columns=['signal_id', 'tau_acf_full', 'tau_sttc_full', 'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2162b7d-0620-4f75-a3bf-18493538c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_df.to_pickle('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\tau_5methods_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19089af3-e34c-46e7-8fcd-8131c01e15bd",
   "metadata": {},
   "source": [
    "### ZZZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df89fb-6319-4b83-a1de-48cc36521118",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_df_long = pd.melt(tau_5methods_df, id_vars=['signal_id'], value_vars=['tau_acf_full', 'tau_sttc_full', \n",
    "                                                                                   'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'], \n",
    "                  value_name='tau_ms', var_name='method')\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(8,4))\n",
    "\n",
    "sns.violinplot(ax=axes, x='method', y='tau_ms', data=tau_5methods_df_long, cut=0,  density_norm='width')\n",
    "axes.axhline(y=100, color='k')\n",
    "\n",
    "fig.suptitle('50 signals (len 100s), 30 trials (len 1s) x 50 runs', y=1.05)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods\\\\trial_tau_figs\\\\' \n",
    "#             + 'taus' + str(i) + '.png' , bbox_inches='tight')\n",
    "fig.savefig('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\' \n",
    "            + 'taus.png' , bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb37f38-644f-442c-86ee-b5c31e4eb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_diff_df_long = pd.melt(tau_5methods_diff_df, id_vars=['signal_id'], value_vars=['tau_acf_full', 'tau_sttc_full', \n",
    "                                                                                   'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'], \n",
    "                  value_name='diff(100, tau_ms)', var_name='method')\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(8,4))\n",
    "\n",
    "sns.violinplot(ax=axes, x='method', y='diff(100, tau_ms)', data=tau_5methods_diff_df_long, cut=0,  density_norm='width')\n",
    "axes.axhline(y=0, color='k')\n",
    "axes.axhline(y=10, color='k', lw=0.5)\n",
    "axes.axhline(y=-10, color='k', lw=0.5)\n",
    "axes.axhline(y=20, color='k', lw=0.5)\n",
    "axes.axhline(y=-20, color='k', lw=0.5)\n",
    "axes.axhline(y=30, color='k', lw=0.5)\n",
    "axes.axhline(y=-30, color='k', lw=0.5)\n",
    "\n",
    "fig.suptitle('50 signals (len 100s), 30 trials (len 1s) x 50 runs', y=1.05)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods\\\\trial_tau_figs\\\\' \n",
    "#             + 'taus' + str(i) + '.png' , bbox_inches='tight')\n",
    "fig.savefig('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\' \n",
    "            + 'taus_diff.png' , bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b3ed0-da0b-47d2-b2ed-3cbd69ae84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_5methods_diff_abs_df_long = pd.melt(tau_5methods_diff_abs_df, id_vars=['signal_id'], value_vars=['tau_acf_full', 'tau_sttc_full', \n",
    "                                                                                   'tau_pearsonr_avg', 'tau_sttc_avg', 'tau_sttc_concat'], \n",
    "                  value_name='abs(diff(100, tau_ms))', var_name='method')\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(8,4))\n",
    "\n",
    "sns.violinplot(ax=axes, x='method', y='abs(diff(100, tau_ms))', data=tau_5methods_diff_abs_df_long, cut=0,  density_norm='width')\n",
    "axes.axhline(y=0, color='k')\n",
    "axes.axhline(y=10, color='k', lw=0.5)\n",
    "axes.axhline(y=20, color='k', lw=0.5)\n",
    "axes.axhline(y=30, color='k', lw=0.5)\n",
    "\n",
    "fig.suptitle('50 signals (len 100s), 30 trials (len 1s) x 50 runs', y=1.05)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# fig.savefig('Q:\\\\Personal\\\\Irina\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods\\\\trial_tau_figs\\\\' \n",
    "#             + 'taus' + str(i) + '.png' , bbox_inches='tight')\n",
    "fig.savefig('D:\\\\isttc\\\\results\\\\synthetic_data\\\\test_full_split_parametric\\\\five_methods_50\\\\' \n",
    "            + 'taus_diff_abs.png' , bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
