{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da579cb-cb2b-4a3b-b83a-0d91833552d6",
   "metadata": {},
   "source": [
    "Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b95934c7-5172-4158-8b13-fcb057908108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# add the path to the abcTau package\n",
    "import sys\n",
    "#sys.path.append('./abcTau')\n",
    "sys.path.append('C:\\\\Users\\\\ipochino\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\isttc\\\\Lib\\\\site-packages\\\\abcTau') # IP: replaced previous line with that; relative path was not working\n",
    "import abcTau\n",
    "from scipy.optimize import curve_fit\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "#from calculate_tau import fit_single_exp, func_single_exp_monkey\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b6381-429d-4eee-9d28-89acac735d35",
   "metadata": {},
   "source": [
    "### Generate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d335f8-82e4-46c6-bd4f-e33126b7802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = project_folder_path + 'results\\\\synthetic_data\\\\dataset\\\\'\n",
    "\n",
    "n_signals = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3190e170-88bb-42b7-b142-31b711eddbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "tau = np.array([100])\n",
    "D = 1/tau\n",
    "deltaT = 1 # 1ms\n",
    "T = 10*60*1000\n",
    "numTrials = 1\n",
    "\n",
    "data_mean = 0.001 # average of firing rate\n",
    "data_var = 0.002 # variance of firing rate\n",
    "\n",
    "binSize = 50 # bins size for binning the data for calculating acf\n",
    "binsData =  np.arange(0, T + binSize, binSize)\n",
    "numBinData = len(binsData)-1\n",
    "#print(binsData)\n",
    "print(numBinData)\n",
    "\n",
    "# num_lags = 20\n",
    "# maxTimeLag = int(T/binSize)\n",
    "# print(maxTimeLag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55ebd7ed-2655-4218-b66a-52aaca076486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou.shape:  (1, 600000)\n",
      "3.9912667971237683\n",
      "ou_all.shape:  (1, 600000)\n",
      "(1, 600000)\n",
      "N spikes (7677,)\n",
      "(1, 12000)\n",
      "(1, 12000)\n"
     ]
    }
   ],
   "source": [
    "for signal_ in range(n_signals):\n",
    "    ###############\n",
    "    # OU process \n",
    "    ou = abcTau.OU_gen(tau, D, deltaT, T, numTrials)\n",
    "    print('ou.shape: ', ou.shape)\n",
    "    \n",
    "    ou_check = np.max(ou)\n",
    "    print(ou_check)\n",
    "    # adjust OU process - scale, shift \n",
    "    ou_std = np.sqrt(data_var)\n",
    "    ou_mean = data_mean\n",
    "    ou_all = ou_std * ou + ou_mean # this is scale and shift, where is rectify? - no rectify here, this will come for the Poisson rate\n",
    "    print('ou_all.shape: ', ou_all.shape)\n",
    "    \n",
    "    ###############\n",
    "    # One tau UO with Poisson spike count\n",
    "    ou_std =  np.sqrt(data_var - data_mean)/deltaT # law of total variance  \n",
    "    ou_mean = data_mean/deltaT # law of total expectation\n",
    "    \n",
    "    # fit mean and var\n",
    "    ou_poisson = ou_std * ou + ou_mean\n",
    "    ou_poisson[ou_poisson < 0] = 0 # rectifying\n",
    "    \n",
    "    # bin rate and generate spikes\n",
    "    numBin = int(T/deltaT)\n",
    "    ou_poisson_rate_ = abcTau.binData(ou_poisson, [numTrials,numBin]) * deltaT\n",
    "    ou_poisson_rate = np.random.poisson(ou_poisson_rate_)\n",
    "    \n",
    "    ###############\n",
    "    # Going from rate to spikes\n",
    "    spikeTrain = np.zeros(ou_poisson_rate.shape)\n",
    "    print(spikeTrain.shape)\n",
    "    \n",
    "    for i in range(ou_poisson_rate.shape[0]):\n",
    "        spikeTrain[i,:] = [1 if ou_poisson_rate[i,j] > np.random.random() else 0 for j in range(ou_poisson_rate.shape[1])]\n",
    "    \n",
    "    spike_times = np.where(np.squeeze(spikeTrain) == 1)[0]\n",
    "    print('N spikes {}'.format(spike_times.shape))\n",
    "    \n",
    "    # bin for ACF calculation\n",
    "    ou_spiketrain_binned = abcTau.binData(spikeTrain, [numTrials, numBinData]) * deltaT\n",
    "    print(ou_spiketrain_binned.shape)\n",
    "\n",
    "    ###############\n",
    "    # Going from rate to spikes - Poisson thinning\n",
    "    binary_spikeTrain = (np.random.random(ou_poisson_rate.shape) < ou_poisson_rate / np.max(ou_poisson_rate)).astype(int)\n",
    "\n",
    "    ou_spiketrain_binned_thinned = abcTau.binData(binary_spikeTrain, [numTrials, numBinData]) * deltaT\n",
    "    print(ou_spiketrain_binned_thinned.shape)\n",
    "\n",
    "    \n",
    "    # store\n",
    "    np.save(save_folder + 'spike_times_' + str(signal_) + '.npy', spike_times)\n",
    "    np.save(save_folder + 'spike_times_thinned_' + str(signal_) + '.npy', binary_spikeTrain)\n",
    "    np.save(save_folder + 'spike_times_binned_' + str(signal_) + '.npy', ou_spiketrain_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fd7493e-6f97-4e89-a300-ec72346ecab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.795"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spike_times)/(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e02ee13c-6225-4cb6-876b-374634e0dba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.266666666666667"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(binary_spikeTrain)/(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab81ed1-f08e-4f03-b808-5c582a5cde80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_spikeTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b86523-0e46-4e00-ac4b-cbf4de1d0892",
   "metadata": {},
   "source": [
    "#### Check taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fa69ac3-f2ba-4f09-8c7d-4963058a1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_sumStat [ 1.          0.35231731  0.1983266   0.1001099   0.06176073  0.04460339\n",
      "  0.02815224  0.0063208  -0.00530664 -0.0097806  -0.02232358 -0.01064589\n",
      " -0.01930655 -0.01062005 -0.00846279  0.0128664   0.00367727 -0.00676934\n",
      " -0.02459739 -0.03508495], data_mean 0.6518333333333334, data_var 1.3752799722222222, T 600000, numTrials 1\n",
      "[0.98565689 1.13348638]\n",
      "56.67431900758323\n"
     ]
    }
   ],
   "source": [
    "def func_exp_abc_like(x, a, tau):\n",
    "    return a * np.exp(-x/tau) \n",
    "\n",
    "disp = None # put the dispersion parameter if computed with grid-search\n",
    "#maxTimeLag = 20 # only used when using autocorrelation for summary statistics\n",
    "summStat_metric = 'comp_cc'\n",
    "ifNorm = True # if normalize the autocorrelation or PSD\n",
    "data_sumStat, data_mean, data_var, T, numTrials =  abcTau.preprocessing.extract_stats(ou_poisson_rate, deltaT, binSize,\n",
    "                                                                                  summStat_metric, ifNorm, maxTimeLag=1000)\n",
    "\n",
    "# summStat_metric = 'comp_cc'\n",
    "# ifNorm = True # if normalize the autocorrelation or PSD\n",
    "# ou_all_data_sumStat, ou_all_data_mean, ou_all_data_var, ou_all_T, ou_all_numTrials =  abcTau.preprocessing.extract_stats(ou_all, deltaT, binSize,\n",
    "#                                                                                   summStat_metric, ifNorm, maxTimeLag)\n",
    "\n",
    "print('data_sumStat {}, data_mean {}, data_var {}, T {}, numTrials {}'.format(data_sumStat, data_mean, data_var, T, numTrials))\n",
    "\n",
    "ou_all_popt, ou_all_pcov = curve_fit(func_exp_abc_like, np.linspace(0,19,20), data_sumStat, maxfev=5000)\n",
    "print(ou_all_popt)\n",
    "ou_all_tau_ms = ou_all_popt[1] * binSize\n",
    "print(ou_all_tau_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e63166f-80e2-4455-a1fe-9c4ae7b7e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ou_spiketrain_binned[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c059d535-5b1e-4df1-816c-a10c55e451ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou_all_acf: [ 1.          0.3527988   0.20088661  0.10281354  0.06249033  0.04495517\n",
      "  0.02859173  0.00726834 -0.00362977 -0.00789085 -0.02128301 -0.0114812\n",
      " -0.01835881 -0.01055834 -0.00898902  0.01338487  0.00256841 -0.00701768\n",
      " -0.02570155 -0.03532331 -0.02379843]\n",
      "57.09269001922627\n"
     ]
    }
   ],
   "source": [
    "# Using acf func\n",
    "num_lags = 20\n",
    "ou_all_acf = acf(ou_spiketrain_binned[0], nlags=num_lags)\n",
    "print('ou_all_acf: {}'.format(ou_all_acf))\n",
    "\n",
    "# Using curve_fit\n",
    "ou_all_popt, ou_all_pcov = curve_fit(func_exp_abc_like, np.linspace(0,20,21), ou_all_acf, maxfev=5000)\n",
    "\n",
    "ou_all_tau_ms = ou_all_popt[1] * binSize\n",
    "print(ou_all_tau_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14ccfde2-5a51-41ea-9176-c0194e539c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou_all_acf: [ 1.00000000e+00  1.68664228e-01  9.12982538e-02  5.71330272e-02\n",
      "  5.37415220e-02  2.89169975e-02  3.64930334e-02  1.05009211e-02\n",
      "  2.71243611e-04 -4.70428894e-03 -2.76848032e-04  5.85558237e-04\n",
      " -7.01704678e-03 -2.58960587e-03  2.65125451e-03  8.18401183e-03\n",
      " -6.36184842e-03 -2.51820140e-03 -5.68008095e-03 -1.23447238e-02\n",
      " -7.10386342e-03]\n",
      "30.8419397349076\n"
     ]
    }
   ],
   "source": [
    "# Using acf func\n",
    "num_lags = 20\n",
    "ou_all_acf = acf(ou_spiketrain_binned_thinned[0], nlags=num_lags)\n",
    "print('ou_all_acf: {}'.format(ou_all_acf))\n",
    "\n",
    "# Using curve_fit\n",
    "ou_all_popt, ou_all_pcov = curve_fit(func_exp_abc_like, np.linspace(0,20,21), ou_all_acf, maxfev=5000)\n",
    "\n",
    "ou_all_tau_ms = ou_all_popt[1] * binSize\n",
    "print(ou_all_tau_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c398440-4f2c-4daf-b96a-e6158d419dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.108816189936\n"
     ]
    }
   ],
   "source": [
    "ou_all_tau_ms = ou_all_popt[1] * binSize\n",
    "print(ou_all_tau_ms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
