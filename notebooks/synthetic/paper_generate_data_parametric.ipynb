{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd9a45b-545b-4c6d-afc8-710878aa2e80",
   "metadata": {},
   "source": [
    "Generate datasets:\n",
    "* 100 signals with tau 100ms and length 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95934c7-5172-4158-8b13-fcb057908108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# add the path to the abcTau package\n",
    "import sys\n",
    "#sys.path.append('./abcTau')\n",
    "#sys.path.append('C:\\\\Users\\\\ipochino\\\\.conda\\\\envs\\\\isttc\\\\Lib\\\\site-packages\\\\abcTau') # IP: replaced previous line with that; relative path was not working\n",
    "sys.path.append('C:\\\\Users\\\\ipochino\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\isttc\\\\Lib\\\\site-packages\\\\abcTau') \n",
    "import abcTau\n",
    "\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from calculate_tau import fit_single_exp, func_single_exp_monkey\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b6381-429d-4eee-9d28-89acac735d35",
   "metadata": {},
   "source": [
    "### Generate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d335f8-82e4-46c6-bd4f-e33126b7802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = project_folder_path + 'results\\\\synthetic_data\\\\dataset_long\\\\'\n",
    "\n",
    "n_signals = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3190e170-88bb-42b7-b142-31b711eddbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "36000\n"
     ]
    }
   ],
   "source": [
    "tau = np.array([100])\n",
    "D = 1/tau\n",
    "deltaT = 1 # 1ms\n",
    "T = 30*60*1000 \n",
    "numTrials = 1\n",
    "\n",
    "data_mean = 0.01 # average of firing rate\n",
    "data_var = 0.02 # variance of firing rate\n",
    "\n",
    "binSize = 50 # bins size for binning the data for calculating acf\n",
    "binsData =  np.arange(0, T + binSize, binSize)\n",
    "numBinData = len(binsData)-1\n",
    "#print(binsData)\n",
    "print(numBinData)\n",
    "\n",
    "num_lags = 20\n",
    "maxTimeLag = int(T/binSize)\n",
    "print(maxTimeLag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1671a-485d-4cb7-81b4-7391a0d97829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68dfb7a-4a06-4edf-be39-c254f557e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\work\\\\q_backup_06_03_2025\\\\projects\\\\isttc\\\\results\\\\synthetic_data\\\\dataset_long\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ebd7ed-2655-4218-b66a-52aaca076486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou.shape:  (1, 1800000)\n",
      "4.5959717494259\n",
      "ou_all.shape:  (1, 1800000)\n",
      "(1, 1800000)\n",
      "N spikes (76596,)\n",
      "(1, 36000)\n"
     ]
    }
   ],
   "source": [
    "for signal_ in range(n_signals):\n",
    "    ###############\n",
    "    # OU process \n",
    "    ou = abcTau.OU_gen(tau, D, deltaT, T, numTrials)\n",
    "    print('ou.shape: ', ou.shape)\n",
    "    \n",
    "    ou_check = np.max(ou)\n",
    "    print(ou_check)\n",
    "    # adjust OU process - scale, shift \n",
    "    ou_std = np.sqrt(data_var)\n",
    "    ou_mean = data_mean\n",
    "    ou_all = ou_std * ou + ou_mean # this is scale and shift, where is rectify? - no rectify here, this will come for the Poisson rate\n",
    "    print('ou_all.shape: ', ou_all.shape)\n",
    "    \n",
    "    ###############\n",
    "    # One tau UO with Poisson spike count\n",
    "    ou_std =  np.sqrt(data_var - data_mean)/deltaT # law of total variance  \n",
    "    ou_mean = data_mean/deltaT # law of total expectation\n",
    "    \n",
    "    # fit mean and var\n",
    "    ou_poisson = ou_std * ou + ou_mean\n",
    "    ou_poisson[ou_poisson < 0] = 0 # rectifying\n",
    "    \n",
    "    # bin rate and generate spikes\n",
    "    numBin = int(T/deltaT)\n",
    "    ou_poisson_rate_ = abcTau.binData(ou_poisson, [numTrials,numBin]) * deltaT\n",
    "    ou_poisson_rate = np.random.poisson(ou_poisson_rate_)\n",
    "    \n",
    "    ###############\n",
    "    # Going from rate to spikes\n",
    "    spikeTrain = np.zeros(ou_poisson_rate.shape)\n",
    "    print(spikeTrain.shape)\n",
    "    \n",
    "    for i in range(ou_poisson_rate.shape[0]):\n",
    "        spikeTrain[i,:] = [1 if ou_poisson_rate[i,j] > np.random.random() else 0 for j in range(ou_poisson_rate.shape[1])]\n",
    "    \n",
    "    spike_times = np.where(np.squeeze(spikeTrain) == 1)[0]\n",
    "    print('N spikes {}'.format(spike_times.shape))\n",
    "    \n",
    "    # bin for ACF calculation\n",
    "    ou_spiketrain_binned = abcTau.binData(spikeTrain, [numTrials, numBinData]) * deltaT\n",
    "    print(ou_spiketrain_binned.shape)\n",
    "    \n",
    "    # store\n",
    "    np.save(save_folder + 'spike_times_' + str(signal_) + '.npy', spike_times)\n",
    "    np.save(save_folder + 'spike_times_binned_' + str(signal_) + '.npy', ou_spiketrain_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654e1bd2-83c9-4033-a7b4-f2eb746cf1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76596"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spike_times/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcec9cfa-bdc7-412e-ac77-e5b624143dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,19,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4cf56d2-05b7-4290-9939-1541eb019bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_sumStat [ 1.00000000e+00  5.39026731e-01  3.01175887e-01  1.74050285e-01\n",
      "  1.00660631e-01  5.62569172e-02  3.25571885e-02  2.19457135e-02\n",
      "  1.14701791e-02  4.85115094e-03  3.17066012e-03  5.04209629e-05\n",
      " -3.11343603e-03  7.39495636e-04  4.57300007e-03  5.32260338e-03\n",
      "  5.02920010e-03 -8.45639803e-04 -1.48969201e-03  2.67018792e-04], data_mean 2.2703611111111113, data_var 10.285099314043208, T 1800000, numTrials 1\n",
      "[0.99478033 1.68961454]\n",
      "84.48072696828667\n"
     ]
    }
   ],
   "source": [
    "def func_exp_abc_like(x, a, tau):\n",
    "    return a * np.exp(-x/tau) \n",
    "\n",
    "disp = None # put the dispersion parameter if computed with grid-search\n",
    "#maxTimeLag = 20 # only used when using autocorrelation for summary statistics\n",
    "summStat_metric = 'comp_cc'\n",
    "ifNorm = True # if normalize the autocorrelation or PSD\n",
    "data_sumStat, data_mean, data_var, T, numTrials =  abcTau.preprocessing.extract_stats(ou_poisson_rate, deltaT, binSize,\n",
    "                                                                                  summStat_metric, ifNorm, maxTimeLag=1000)\n",
    "\n",
    "# summStat_metric = 'comp_cc'\n",
    "# ifNorm = True # if normalize the autocorrelation or PSD\n",
    "# ou_all_data_sumStat, ou_all_data_mean, ou_all_data_var, ou_all_T, ou_all_numTrials =  abcTau.preprocessing.extract_stats(ou_all, deltaT, binSize,\n",
    "#                                                                                   summStat_metric, ifNorm, maxTimeLag)\n",
    "\n",
    "print('data_sumStat {}, data_mean {}, data_var {}, T {}, numTrials {}'.format(data_sumStat, data_mean, data_var, T, numTrials))\n",
    "\n",
    "ou_all_popt, ou_all_pcov = curve_fit(func_exp_abc_like, np.linspace(0,19,20), data_sumStat, maxfev=5000)\n",
    "print(ou_all_popt)\n",
    "ou_all_tau_ms = ou_all_popt[1] * binSize\n",
    "print(ou_all_tau_ms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
