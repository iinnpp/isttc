{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1b6c08-9434-4f91-9117-5eb95ee10ad4",
   "metadata": {},
   "source": [
    "Spike trains are generated using univariate, self‐exciting Hawkes point process with an exponential kernel, using Ogata’s thinning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33aee8d9-673e-4302-b31b-e56b96b123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from cfg_global import project_folder_path\n",
    "from spike_train_utils import simulate_hawkes_thinning\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca96473-a0d8-461a-be79-b2c2ef2d4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'results\\\\synthetic\\\\dataset\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3a0461-66e4-49e2-a0dd-1a9f4babe1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349c97f-8809-4186-945c-0dc173336786",
   "metadata": {},
   "source": [
    "### Main dataset \n",
    "\n",
    "1000 spike trains, 3 parameters are fixed \n",
    "\n",
    "Fig2 B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cc1ae-4ca4-4a75-afba-239ab19d4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_hz     = 3.5     # target firing rate (Hz)\n",
    "tau_ms      = 100.0    # desired autocorr time constant (ms)\n",
    "alpha       = 0.3     # self‐excitation weight (must be <1)\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# generate\n",
    "num_trials = 1000\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_tau100ms_alpha0_3_fr3_5hz_len600sec_1000.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alpha,\n",
    "            'fr_values': rate_hz,\n",
    "            'tau_ms': tau_ms,\n",
    "            'duration_ms': duration_ms\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fc131-c3f7-4b7d-b5c8-18abdcf894bb",
   "metadata": {},
   "source": [
    "### Parametric dataset 1\n",
    "\n",
    "10000 spike trains, tau is fixed, fr and alpha are variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639630f-1ce0-475a-86ef-c2396b476127",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_min, fr_max = 0.01, 10.0  \n",
    "alpha_min, alpha_max = 0.1, 0.9  \n",
    "\n",
    "tau_ms      = 100.0    # desired autocorr time constant (ms)\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# generate\n",
    "num_trials = 10000\n",
    "\n",
    "# Random sampling of parameters\n",
    "global_rng = np.random.default_rng(42)\n",
    "fr_values = global_rng.uniform(fr_min, fr_max, size=num_trials)\n",
    "alphas = global_rng.uniform(alpha_min, alpha_max, size=num_trials)\n",
    "\n",
    "# Generate spike trains\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    rate_hz = fr_values[trial]\n",
    "    alpha = alphas[trial]\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial for reproducibility\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_tau100ms_alpha_var_fr_var_len600sec_10000.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alphas,\n",
    "            'fr_values': fr_values,\n",
    "            'tau_ms': tau_ms,\n",
    "            'duration_ms': duration_ms\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e575196-10ad-4844-b54f-8f533dddec52",
   "metadata": {},
   "source": [
    "### Parametric dataset 2\n",
    "\n",
    "100000 spike trains, tau, fr and alpha are variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed816273-cd11-425c-afea-abc5da66ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_min, fr_max = 0.01, 10.0  \n",
    "alpha_min, alpha_max = 0.1, 0.9  \n",
    "tau_ms_min, tau_ms_max = 50, 300\n",
    "\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# generate\n",
    "num_trials = 100000\n",
    "\n",
    "# Random sampling of parameters\n",
    "global_rng = np.random.default_rng(42)\n",
    "fr_values = global_rng.uniform(fr_min, fr_max, size=num_trials)\n",
    "alphas = global_rng.uniform(alpha_min, alpha_max, size=num_trials)\n",
    "taus = global_rng.uniform(tau_ms_min, tau_ms_max, size=num_trials)\n",
    "\n",
    "# Generate spike trains\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    rate_hz = fr_values[trial]\n",
    "    alpha = alphas[trial]\n",
    "    tau_ms = taus[trial]\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial for reproducibility\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_3params_var_len600sec_100000.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alphas,\n",
    "            'fr_values': fr_values,\n",
    "            'tau_ms': taus,\n",
    "            'duration_ms': duration_ms\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499d51f-ff8b-4e7a-82d4-9777f55dc1e1",
   "metadata": {},
   "source": [
    "### Datasets for Lv tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed98e22-2c35-4057-a976-c1533252293d",
   "metadata": {},
   "source": [
    "#### Same alpha and tau, diff fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3d1666-ff45-4627-a1dc-3eaea884664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_min, fr_max = 0.01, 10.0  \n",
    "tau_ms = 100.0   \n",
    "alpha = 0.3  \n",
    "\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# generate\n",
    "num_trials = 1000\n",
    "\n",
    "# Random sampling of parameters\n",
    "global_rng = np.random.default_rng(42)\n",
    "fr_values = global_rng.uniform(fr_min, fr_max, size=num_trials)\n",
    "\n",
    "# Generate spike trains\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    rate_hz = fr_values[trial]\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial for reproducibility\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_lv_1param_var_fr_len600sec_1000.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alpha,\n",
    "            'fr_values': fr_values,\n",
    "            'tau_ms': tau_ms,\n",
    "            'duration_ms': duration_ms\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d768d-b654-4103-a801-1af36e3b44d8",
   "metadata": {},
   "source": [
    "#### Same fr and tau, different alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2cbf3dc-d25e-4730-ba38-a05b35598af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_hz = 3.5 \n",
    "alpha_min, alpha_max = 0.1, 0.9  \n",
    "tau_ms = 100.0   \n",
    "\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# generate\n",
    "num_trials = 1000\n",
    "\n",
    "# Random sampling of parameters\n",
    "global_rng = np.random.default_rng(42)\n",
    "alphas = global_rng.uniform(alpha_min, alpha_max, size=num_trials)\n",
    "\n",
    "duration_ms = 10*60*1000*1    # simulate for 10 min\n",
    "\n",
    "# Generate spike trains\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    alpha = alphas[trial]\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial for reproducibility\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_lv_1param_var_alpha_len600sec_1000.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alphas,\n",
    "            'fr_values': rate_hz,\n",
    "            'tau_ms': tau_ms,\n",
    "            'duration_ms': duration_ms\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f16a3-d4d0-46f8-92e9-f024fa929e2c",
   "metadata": {},
   "source": [
    "### Dataset for signal len effect test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb99a31-527f-48a2-899e-751122ad2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_hz     = 3.5     \n",
    "tau_ms      = 100.0   \n",
    "alpha       = 0.3   \n",
    "\n",
    "duration_ms_min, duration_ms_max = 2*1000, 10*60*1000 # 2s - 600sec \n",
    "\n",
    "num_trials = 10000\n",
    "global_rng = np.random.default_rng(42)\n",
    "duration_ms_all = global_rng.integers(duration_ms_min,\n",
    "                              duration_ms_max,\n",
    "                              size=num_trials,\n",
    "                              endpoint=True)\n",
    "\n",
    "# generate\n",
    "all_spike_trains = []\n",
    "for trial in range(num_trials):\n",
    "    duration_ms = duration_ms_all[trial]\n",
    "    spikes = simulate_hawkes_thinning(\n",
    "        fr_hz_=rate_hz,\n",
    "        tau_ms_=tau_ms,\n",
    "        alpha_=alpha,\n",
    "        duration_ms_=duration_ms,\n",
    "        seed_=trial  # different seed per trial\n",
    "    )\n",
    "    all_spike_trains.append(spikes)\n",
    "\n",
    "if save_data:\n",
    "    file_name = 'spike_trains_tau100ms_alpha0_3_fr3_5hz_len600sec_var_duration.pkl'\n",
    "    with open(dataset_folder + file_name, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'spike_trains': all_spike_trains,\n",
    "            'alphas': alpha,\n",
    "            'fr_values': rate_hz,\n",
    "            'tau_ms': tau_ms,\n",
    "            'duration_ms': duration_ms_all\n",
    "        }, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
