{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1b6c08-9434-4f91-9117-5eb95ee10ad4",
   "metadata": {},
   "source": [
    "Prepare summary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33aee8d9-673e-4302-b31b-e56b96b123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from isttc.scripts.cfg_global import project_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca96473-a0d8-461a-be79-b2c2ef2d4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'synthetic_dataset\\\\'\n",
    "results_folder = project_folder_path + 'results\\\\synthetic\\\\results\\\\param_fr_alpha_tau\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3c84a-c3a3-4ebb-9c41-416a5787fc2e",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1362c68-e0b0-4d91-9715-660f2471c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acf_decline_flag(acf_, start_idx=1, end_idx=4):\n",
    "    acf_decay = np.all(np.diff(acf_[start_idx:end_idx]) <= 0)\n",
    "    return acf_decay\n",
    "\n",
    "def get_tau_df(acf_dict_, signal_len_, method_, alphas_, fr_values_, taus_ms_):\n",
    "    data = []\n",
    "    for unit_id, unit_data in acf_dict_.items():\n",
    "        taus = unit_data['taus']  \n",
    "        data.append({\n",
    "            'unit_id': unit_id,\n",
    "            'tau': taus['tau'],\n",
    "            'tau_lower': taus['tau_lower'],\n",
    "            'tau_upper': taus['tau_upper'],\n",
    "            'fit_r_squared': taus['fit_r_squared'],\n",
    "            'acf_decline': calculate_acf_decline_flag(unit_data['acf'], start_idx=1, end_idx=4)\n",
    "        })\n",
    "    tau_df = pd.DataFrame(data)\n",
    "    tau_df['method'] = method_\n",
    "    tau_df['tau_ms'] = tau_df['tau'] * 50\n",
    "    tau_df['duration_s'] = signal_len_\n",
    "    tau_df['fr'] = fr_values_\n",
    "    tau_df['alpha'] = alphas_\n",
    "    tau_df['tau_ms_true'] = taus_ms_\n",
    "    tau_df['tau_diff_abs'] = np.abs(tau_df['tau_ms'] - tau_df['tau_ms_true'])\n",
    "    tau_df['tau_diff_rel'] = tau_df['tau_diff_abs'] / tau_df['tau_ms_true'] * 100\n",
    "    tau_df['ci_width'] = np.abs(tau_df['tau_upper'] - tau_df['tau_lower'])\n",
    "    \n",
    "    rows_with_nans_df = tau_df[tau_df.isna().any(axis=1)]\n",
    "    n_rows_with_nan = len(rows_with_nans_df)\n",
    "    print(f'N rows with NaNs {n_rows_with_nan}')\n",
    "    \n",
    "    return tau_df\n",
    "\n",
    "def get_trials_plot_df(trial_dict_, method_, alphas_, fr_values_, taus_ms_, n_iteration_=None):\n",
    "    records = []\n",
    "    for unit_id, data in trial_dict_.items():\n",
    "        taus = data['taus']\n",
    "        acfs = data['acf']\n",
    "\n",
    "        if n_iteration_ is not None:\n",
    "            # only one trial per unit\n",
    "            idx = n_iteration_[unit_id]\n",
    "            taus_to_iter = [(taus[idx], acfs[idx])]\n",
    "        else:\n",
    "            # all trials for this unit\n",
    "            taus_to_iter = zip(taus, acfs)\n",
    "\n",
    "        for tau_dict, acf_array in taus_to_iter:\n",
    "            records.append({\n",
    "                'unit_id': unit_id,\n",
    "                'tau': tau_dict['tau'],\n",
    "                'tau_lower': tau_dict['tau_lower'],\n",
    "                'tau_upper': tau_dict['tau_upper'],\n",
    "                'fit_r_squared': tau_dict['fit_r_squared'],\n",
    "                'acf_decline': calculate_acf_decline_flag(acf_array, start_idx=1, end_idx=4),\n",
    "                'method': method_,\n",
    "            })\n",
    "\n",
    "    tau_df = pd.DataFrame.from_records(records)\n",
    "    tau_df['tau_ms'] = tau_df['tau'] * 50\n",
    "    tau_df['fr'] = fr_values_\n",
    "    tau_df['alpha'] = alphas_\n",
    "    tau_df['tau_ms_true'] = taus_ms_\n",
    "    tau_df['tau_diff_abs'] = np.abs(tau_df['tau_ms'] - tau_df['tau_ms_true'])\n",
    "    tau_df['tau_diff_rel'] = tau_df['tau_diff_abs'] / tau_df['tau_ms_true'] * 100\n",
    "    tau_df['ci_width'] = np.abs(tau_df['tau_upper'] - tau_df['tau_lower'])\n",
    "\n",
    "    nan_count = tau_df.isna().any(axis=1).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f'N rows with NaNs {nan_count}')\n",
    "\n",
    "    return tau_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52b4bc-f454-41cf-b175-39758c89e077",
   "metadata": {},
   "source": [
    "### Load spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def971cb-e6f7-44d5-8844-4ad3f2e842cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n spike trains 100000, len 598.8243581617338, duration_ms 600000\n",
      "Lv loaded for n spike trains 100000\n"
     ]
    }
   ],
   "source": [
    "with open(dataset_folder + 'spike_trains.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "spike_trains = data['spike_trains']\n",
    "alphas = data['alphas']\n",
    "fr_values = data['fr_values']\n",
    "taus_ms = data['tau_ms']\n",
    "duration_ms = data['duration_ms']\n",
    "\n",
    "print(f'n spike trains {len(spike_trains)}, len {spike_trains[0][-1]/1000}, duration_ms {duration_ms}')\n",
    "\n",
    "lv_df = pd.read_pickle(results_folder + 'lv_df.pkl')\n",
    "print(f'Lv loaded for n spike trains {len(lv_df)}')\n",
    "\n",
    "#fs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a76ba-bf17-493a-9076-fe96191ecec7",
   "metadata": {},
   "source": [
    "### ACF, iSTTC, PersonR, iSTTC trails (сoncat)\n",
    "\n",
    "The summary dataset includes only units where all 4 methods have valid (non-NaN) rows and fit_r_squared ≥ 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc42d3c0-c37b-4bdd-acdc-b4f2652141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len pearsonr_trial_avg_dict 100000\n",
      "len sttc_trial_concat_dict 100000\n",
      "len isttc_full_dict 100000\n",
      "len acf_full_dict 100000\n",
      "N rows with NaNs 11\n",
      "N rows with NaNs 0\n",
      "N rows with NaNs 12393\n",
      "len tau_all_long_df 400000\n",
      "len tau_all_long_df_clean 326180, per method 81545.0\n"
     ]
    }
   ],
   "source": [
    "# load per method\n",
    "with open(results_folder + 'tau_isttc_full_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    isttc_full_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_acf_full_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    acf_full_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_pearsonr_trial_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    pearsonr_trial_avg_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_isttc_trial_concat_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    sttc_trial_concat_dict = pickle.load(f)\n",
    "\n",
    "print(f'len pearsonr_trial_avg_dict {len(pearsonr_trial_avg_dict)}')\n",
    "print(f'len sttc_trial_concat_dict {len(sttc_trial_concat_dict)}')\n",
    "print(f'len isttc_full_dict {len(isttc_full_dict)}')\n",
    "print(f'len acf_full_dict {len(acf_full_dict)}')\n",
    "\n",
    "acf_tau_full_df = get_tau_df(acf_full_dict, 600, 'acf_full', alphas, fr_values, taus_ms)\n",
    "isttc_tau_full_df = get_tau_df(isttc_full_dict, 600, 'isttc_full', alphas, fr_values, taus_ms)\n",
    "random_trials_impl = np.zeros(len(sttc_trial_concat_dict)).astype(int)\n",
    "pearsontr_trial_avg_plot_df = get_trials_plot_df(pearsonr_trial_avg_dict, 'pearsonr_trial_avg', alphas, fr_values, taus_ms, random_trials_impl)\n",
    "sttc_trial_concat_plot_df = get_trials_plot_df(sttc_trial_concat_dict, 'sttc_trial_concat', alphas, fr_values, taus_ms, random_trials_impl)\n",
    "\n",
    "# prepare df\n",
    "tau_all_long_df = pd.concat([acf_tau_full_df, isttc_tau_full_df, pearsontr_trial_avg_plot_df, sttc_trial_concat_plot_df])\n",
    "tau_all_long_df.reset_index(inplace=True, drop=True)\n",
    "tau_all_long_df.drop(columns=['duration_s'], inplace=True)\n",
    "tau_all_long_df = tau_all_long_df.merge(lv_df[['unit_id', 'lv']].copy(), on='unit_id', how='left')\n",
    "print(f'len tau_all_long_df {len(tau_all_long_df)}')\n",
    "# leave only units with both methods (no NaNs and r_squared >= 0)\n",
    "required = {'acf_full', 'isttc_full', 'pearsonr_trial_avg', 'sttc_trial_concat'}\n",
    "tau_all_long_df_clean = (\n",
    "    tau_all_long_df.groupby(\"unit_id\")\n",
    "      .filter(lambda g: (\n",
    "          len(g) == 4\n",
    "          and set(g[\"method\"]) == required\n",
    "          and g.notna().all().all()\n",
    "          and (g[\"fit_r_squared\"] >= 0).all()\n",
    "      ))\n",
    ")\n",
    "tau_all_long_df_clean.reset_index(inplace=True, drop=True)\n",
    "print(f'len tau_all_long_df_clean {len(tau_all_long_df_clean)}, per method {len(tau_all_long_df_clean)/4}')\n",
    "\n",
    "#save df\n",
    "tau_all_long_df_clean.to_csv(results_folder + 'summary_tau_all_long_df.csv')\n",
    "tau_all_long_df_clean.to_pickle(results_folder + 'summary_tau_all_long_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728431f-ae03-45a5-8b6d-2276eb26d88a",
   "metadata": {},
   "source": [
    "### ACF vs iSTTC, full signal\n",
    "\n",
    "The summary dataset includes only units where all 2 methods have valid (non-NaN) rows and fit_r_squared ≥ 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73168ac0-59c6-4e9d-942a-fbccfc92232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len isttc_full_dict 100000\n",
      "len acf_full_dict 100000\n",
      "N rows with NaNs 11\n",
      "N rows with NaNs 0\n",
      "len tau_full_long_df 200000\n",
      "len tau_full_long_df_clean 199316, per method 99658.0\n"
     ]
    }
   ],
   "source": [
    "# load per method\n",
    "with open(results_folder + 'tau_isttc_full_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    isttc_full_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_acf_full_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    acf_full_dict = pickle.load(f)\n",
    "\n",
    "print(f'len isttc_full_dict {len(isttc_full_dict)}')\n",
    "print(f'len acf_full_dict {len(acf_full_dict)}')\n",
    "\n",
    "acf_tau_full_df = get_tau_df(acf_full_dict, 600, 'acf_full', alphas, fr_values, taus_ms)\n",
    "isttc_tau_full_df = get_tau_df(isttc_full_dict, 600, 'isttc_full', alphas, fr_values, taus_ms)\n",
    "\n",
    "# prepare df\n",
    "tau_full_long_df = pd.concat([acf_tau_full_df, isttc_tau_full_df])\n",
    "tau_full_long_df.reset_index(inplace=True, drop=True)\n",
    "tau_full_long_df = tau_full_long_df.merge(lv_df[['unit_id', 'lv']].copy(), on='unit_id', how='left')\n",
    "print(f'len tau_full_long_df {len(tau_full_long_df)}')\n",
    "# leave only units with both methods (no NaNs and r_squared >= 0)\n",
    "required = {\"acf_full\", \"isttc_full\"}\n",
    "tau_full_long_df_clean = (\n",
    "    tau_full_long_df.groupby(\"unit_id\")\n",
    "      .filter(lambda g: (\n",
    "          len(g) == 2\n",
    "          and set(g[\"method\"]) == required\n",
    "          and g.notna().all().all()\n",
    "          and (g[\"fit_r_squared\"] >= 0).all()\n",
    "      ))\n",
    ")\n",
    "tau_full_long_df_clean.reset_index(inplace=True, drop=True)\n",
    "print(f'len tau_full_long_df_clean {len(tau_full_long_df_clean)}, per method {len(tau_full_long_df_clean)/2}')\n",
    "\n",
    "#save df\n",
    "tau_full_long_df_clean.to_csv(results_folder + 'summary_tau_full_long_df.csv')\n",
    "tau_full_long_df_clean.to_pickle(results_folder + 'summary_tau_full_long_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c7826-6b49-4ab0-b00f-062ed53c3d61",
   "metadata": {},
   "source": [
    "### PearsonR vs iSTTC (concat and avg), trails\n",
    "\n",
    "The summary dataset includes only units where all 3 methods have valid (non-NaN) rows and fit_r_squared ≥ 0. STTC trail avg is not included in the paper figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddfa6cd-447d-47c7-93b9-41f43c20f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len pearsonr_trial_avg_dict 100000\n",
      "len sttc_trial_avg_dict 100000\n",
      "len sttc_trial_concat_dict 100000\n",
      "N rows with NaNs 12393\n",
      "len tau_trials_long_df 300000\n",
      "len tau_trials_long_df_clean 242847, per method 80949.0\n"
     ]
    }
   ],
   "source": [
    "# load per method\n",
    "with open(results_folder + 'tau_pearsonr_trial_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    pearsonr_trial_avg_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_sttc_trial_avg_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    sttc_trial_avg_dict = pickle.load(f)\n",
    "\n",
    "with open(results_folder + 'tau_isttc_trial_concat_50ms_20lags_dict.pkl', \"rb\") as f:\n",
    "    sttc_trial_concat_dict = pickle.load(f)\n",
    "\n",
    "print(f'len pearsonr_trial_avg_dict {len(pearsonr_trial_avg_dict)}')\n",
    "print(f'len sttc_trial_avg_dict {len(sttc_trial_avg_dict)}')\n",
    "print(f'len sttc_trial_concat_dict {len(sttc_trial_concat_dict)}')\n",
    "\n",
    "# for trial based measures one realization of trials is taken\n",
    "random_trials_impl = np.zeros(len(sttc_trial_concat_dict)).astype(int)\n",
    "\n",
    "pearsontr_trial_avg_plot_df = get_trials_plot_df(pearsonr_trial_avg_dict, 'pearsonr_trial_avg', alphas, fr_values, taus_ms, random_trials_impl)\n",
    "sttc_trial_concat_plot_df = get_trials_plot_df(sttc_trial_concat_dict, 'sttc_trial_concat', alphas, fr_values, taus_ms, random_trials_impl)\n",
    "sttc_trial_avg_plot_df = get_trials_plot_df(sttc_trial_avg_dict, 'sttc_trial_avg', alphas, fr_values, taus_ms, random_trials_impl)\n",
    "\n",
    "# prepare df\n",
    "tau_trials_long_df = pd.concat([pearsontr_trial_avg_plot_df, sttc_trial_concat_plot_df, sttc_trial_avg_plot_df])\n",
    "tau_trials_long_df.reset_index(inplace=True, drop=True)\n",
    "tau_trials_long_df = tau_trials_long_df.merge(lv_df[['unit_id', 'lv']].copy(), on='unit_id', how='left')\n",
    "print(f'len tau_trials_long_df {len(tau_trials_long_df)}')\n",
    "# leave only units with both methods (no NaNs and r_squared >= 0)\n",
    "required = {'pearsonr_trial_avg', 'sttc_trial_concat', 'sttc_trial_avg'}\n",
    "tau_trials_long_df_clean = (\n",
    "    tau_trials_long_df.groupby(\"unit_id\")\n",
    "      .filter(lambda g: (\n",
    "          len(g) == 3\n",
    "          and set(g[\"method\"]) == required\n",
    "          and g.notna().all().all()\n",
    "          and (g[\"fit_r_squared\"] >= 0).all()\n",
    "      ))\n",
    ")\n",
    "tau_trials_long_df_clean.reset_index(inplace=True, drop=True)\n",
    "print(f'len tau_trials_long_df_clean {len(tau_trials_long_df_clean)}, per method {len(tau_trials_long_df_clean)/3}')\n",
    "\n",
    "#save df\n",
    "tau_trials_long_df_clean.to_csv(results_folder + 'summary_tau_trials_long_df.csv')\n",
    "tau_trials_long_df_clean.to_pickle(results_folder + 'summary_tau_trials_long_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
