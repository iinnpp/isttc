{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6452f561-0fc1-4840-8216-4d8a86032aeb",
   "metadata": {},
   "source": [
    "Generating trials dataset using resampling procedure.\n",
    "\n",
    "* Number of resampling iterations: 100 (based on bootstrapping stability analysis)\n",
    "* Number of trials per resampling: N = 40 (based on data in monkey dataset so the number of trials is from experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e092926-3abe-4a61-b1c9-c62409412ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "#os.chdir(os.path.abspath(\"C:\\\\Users\\\\ipoch\\\\Documents\\\\repos\\\\isttc\\\\scripts\"))\n",
    "from cfg_global import project_folder_path\n",
    "from spike_train_utils import get_trials, bin_trials\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536dcb61-d571-4621-9a2b-55d665cd354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'results\\\\mice\\\\dataset\\\\cut_30min\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908140b-15a8-40ad-89bd-69c69b5d4c00",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63afe5b7-19c6-4818-96b8-5d3cd801a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file E:\\work\\q_backup_06_03_2025\\projects\\isttc\\results\\mice\\dataset\\cut_30min\\sua_list_constrained.csv\n",
      "Loaded N units 5775\n"
     ]
    }
   ],
   "source": [
    "csv_data_file = dataset_folder + 'sua_list_constrained.csv'\n",
    "print(f'Loading file {csv_data_file}')\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_list = list(reader)\n",
    "print(f'Loaded N units {len(sua_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e87fa8-9cd1-43c0-8b1d-c5e508c25751",
   "metadata": {},
   "source": [
    "### Make trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b6de93-bccc-4a1e-8ada-32787b288df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 200  \n",
    "m_iterations = 1\n",
    "\n",
    "fs = 30000\n",
    "bin_size = 50 # in ms\n",
    "signal_len = int(30 * 60 * fs)\n",
    "trial_len = int(1000 * (fs / 1000)) # 1000ms trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4071460-7bc7-4827-8722-1d5f0dfa96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unit 0\n",
      "Processing unit 100\n",
      "Processing unit 200\n",
      "Processing unit 300\n",
      "Processing unit 400\n",
      "Processing unit 500\n",
      "Processing unit 600\n",
      "Processing unit 700\n",
      "Processing unit 800\n",
      "Processing unit 900\n",
      "Processing unit 1000\n",
      "Processing unit 1100\n",
      "Processing unit 1200\n",
      "Processing unit 1300\n",
      "Processing unit 1400\n",
      "Processing unit 1500\n",
      "Processing unit 1600\n",
      "Processing unit 1700\n",
      "Processing unit 1800\n",
      "Processing unit 1900\n",
      "Processing unit 2000\n",
      "Processing unit 2100\n",
      "Processing unit 2200\n",
      "Processing unit 2300\n",
      "Processing unit 2400\n",
      "Processing unit 2500\n",
      "Processing unit 2600\n",
      "Processing unit 2700\n",
      "Processing unit 2800\n",
      "Processing unit 2900\n",
      "Processing unit 3000\n",
      "Processing unit 3100\n",
      "Processing unit 3200\n",
      "Processing unit 3300\n",
      "Processing unit 3400\n",
      "Processing unit 3500\n",
      "Processing unit 3600\n",
      "Processing unit 3700\n",
      "Processing unit 3800\n",
      "Processing unit 3900\n",
      "Processing unit 4000\n",
      "Processing unit 4100\n",
      "Processing unit 4200\n",
      "Processing unit 4300\n",
      "Processing unit 4400\n",
      "Processing unit 4500\n",
      "Processing unit 4600\n",
      "Processing unit 4700\n",
      "Processing unit 4800\n",
      "Processing unit 4900\n",
      "Processing unit 5000\n",
      "Processing unit 5100\n",
      "Processing unit 5200\n",
      "Processing unit 5300\n",
      "Processing unit 5400\n",
      "Processing unit 5500\n",
      "Processing unit 5600\n",
      "Processing unit 5700\n"
     ]
    }
   ],
   "source": [
    "trial_dict = {}\n",
    "trial_binned_dict = {}\n",
    "\n",
    "for i in range(len(sua_list)):\n",
    "    if (i % 100) == 0:\n",
    "        print(f'Processing unit {i}')\n",
    "    unit_trial_dict = {}\n",
    "    unit_trial_binned_dict = {}\n",
    "    for m in range(m_iterations):\n",
    "        spikes = np.asarray([int(spike) for spike in sua_list[i][8:]])\n",
    "        spikes_trials = get_trials(spikes, signal_len, n_trials, trial_len, verbose_=False)\n",
    "        spikes_trials_binned = bin_trials(spikes_trials, trial_len, int(bin_size*(fs/1000)))\n",
    "        unit_trial_dict[m] = spikes_trials\n",
    "        unit_trial_binned_dict[m] = spikes_trials_binned\n",
    "\n",
    "    trial_dict[sua_list[i][2]] = unit_trial_dict\n",
    "    trial_binned_dict[sua_list[i][2]] = unit_trial_binned_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266307d-a9c5-49c2-a247-f9a3b204254c",
   "metadata": {},
   "source": [
    "### Save trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a589855a-abe9-47cb-af21-33790aea5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_folder + 'trial_' + str(n_trials) + '_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(trial_dict, f)\n",
    "\n",
    "with open(dataset_folder + 'trial_binned_' + str(n_trials) + '_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(trial_binned_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
