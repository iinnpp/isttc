{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5c618e-ef3a-4d40-959f-09191178be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from isttc.scripts.cfg_global import project_folder_path\n",
    "from isttc.tau import fit_single_exp, fit_single_exp_2d, func_single_exp_monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f308a9-a5ea-4856-a500-fb11290b6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdce273a-4ce2-4376-b989-b6cad09a6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True - calc and plot, False only plot\n",
    "calc_taus = False\n",
    "save_taus = False\n",
    "save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721a31e0-045a-47d5-b095-76ba184ff466",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'results\\\\mice\\\\dataset\\\\'\n",
    "fig_folder = project_folder_path + 'results\\\\mice\\\\fig_draft_paper\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bb72c-279f-43ef-b73b-3ce78a697037",
   "metadata": {},
   "source": [
    "### Load data (or calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ca247a-5006-4aac-99f5-ae06c309a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acf_decline_flag(acf_, start_idx=1, end_idx=4):\n",
    "    acf_decay = np.all(np.diff(acf_[start_idx:end_idx]) <= 0)\n",
    "    return acf_decay\n",
    "\n",
    "def get_trials_plot_df(trial_dict_, units_info_df_subset_, method_, n_trials_):\n",
    "    unit_ids = []\n",
    "    taus = []\n",
    "    tau_lower = []\n",
    "    tau_upper = []\n",
    "    fit_r_squared = []\n",
    "    decline_flags = []\n",
    "\n",
    "    for unit_id, unit_data in trial_dict_.items():\n",
    "        unit_ids.append(unit_id)\n",
    "        taus.append(unit_data['taus'][0]['tau'])\n",
    "        tau_lower.append(unit_data['taus'][0]['tau_lower'])\n",
    "        tau_upper.append(unit_data['taus'][0]['tau_upper'])\n",
    "        fit_r_squared.append(unit_data['taus'][0]['fit_r_squared'])\n",
    "        decline_flags.append(calculate_acf_decline_flag(unit_data['acf'][0], start_idx=1, end_idx=4))\n",
    "\n",
    "    trial_plot_df = pd.DataFrame({\n",
    "        'unit_id': unit_ids,\n",
    "        'tau': taus,\n",
    "        'tau_lower': tau_lower,\n",
    "        'tau_upper': tau_upper,\n",
    "        'fit_r_squared': fit_r_squared,\n",
    "        'decline_150_250': decline_flags,\n",
    "        'method': method_,\n",
    "        'n_trials': n_trials_\n",
    "    })\n",
    "\n",
    "    trial_plot_df['tau_ms'] = trial_plot_df['tau'] * 50\n",
    "    trial_plot_df = trial_plot_df.merge(units_info_df_subset_, on='unit_id', how='left')\n",
    "\n",
    "    n_rows_with_nan = trial_plot_df.isna().any(axis=1).sum()\n",
    "    print(f'N rows with NaNs {n_rows_with_nan}')\n",
    "    \n",
    "    return trial_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9497d61-1eda-4b72-b259-cf7c05bd1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>ecephys_structure_acronym</th>\n",
       "      <th>fr_hz_spont_30min</th>\n",
       "      <th>lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950913540</td>\n",
       "      <td>VISam</td>\n",
       "      <td>6.038333</td>\n",
       "      <td>1.239003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950915005</td>\n",
       "      <td>VISam</td>\n",
       "      <td>4.030556</td>\n",
       "      <td>0.628989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_id ecephys_structure_acronym  fr_hz_spont_30min        lv\n",
       "0  950913540                     VISam           6.038333  1.239003\n",
       "1  950915005                     VISam           4.030556  0.628989"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units_info_df = pd.read_pickle(dataset_folder + 'cut_30min\\\\lv_df.pkl')\n",
    "units_info_df_subset = units_info_df[['unit_id', 'ecephys_structure_acronym', 'fr_hz_spont_30min', 'lv']].copy()\n",
    "units_info_df_subset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529888e0-d8d3-4f0a-af8f-b1662fe6f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsontr_60_file = dataset_folder + 'cut_30min\\\\binned\\\\pearsonr_trial_avg_50ms_20lags_60trials_dict.pkl'\n",
    "# pearsontr_trial_acf_60_dict = pd.read_pickle(pearsontr_60_file)\n",
    "# pearsontr_60_df = get_trials_plot_df(pearsontr_trial_acf_60_dict, units_info_df_subset, 'pearsonr_trial_avg', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7496889f-6e90-4dc6-87d1-5920ed52e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows with NaNs 995\n",
      "N rows with NaNs 677\n",
      "N rows with NaNs 491\n",
      "N rows with NaNs 385\n"
     ]
    }
   ],
   "source": [
    "pearsontr_40_file = dataset_folder + 'cut_30min\\\\binned\\\\pearsonr_trial_avg_50ms_20lags_dict.pkl'\n",
    "pearsontr_trial_acf_40_dict = pd.read_pickle(pearsontr_40_file)\n",
    "pearsontr_40_df = get_trials_plot_df(pearsontr_trial_acf_40_dict, units_info_df_subset, 'pearsonr_trial_avg', 40)\n",
    "\n",
    "pearsontr_60_file = dataset_folder + 'cut_30min\\\\binned\\\\pearsonr_trial_avg_50ms_20lags_60trials_dict.pkl'\n",
    "pearsontr_trial_acf_60_dict = pd.read_pickle(pearsontr_60_file)\n",
    "pearsontr_60_df = get_trials_plot_df(pearsontr_trial_acf_60_dict, units_info_df_subset, 'pearsonr_trial_avg', 60)\n",
    "\n",
    "pearsontr_80_file = dataset_folder + 'cut_30min\\\\binned\\\\pearsonr_trial_avg_50ms_20lags_80trials_dict.pkl'\n",
    "pearsontr_trial_acf_80_dict = pd.read_pickle(pearsontr_80_file)\n",
    "pearsontr_80_df = get_trials_plot_df(pearsontr_trial_acf_80_dict, units_info_df_subset, 'pearsonr_trial_avg', 80)\n",
    "\n",
    "pearsontr_100_file = dataset_folder + 'cut_30min\\\\binned\\\\pearsonr_trial_avg_50ms_20lags_100trials_dict.pkl'\n",
    "pearsontr_trial_acf_100_dict = pd.read_pickle(pearsontr_100_file)\n",
    "pearsontr_100_df = get_trials_plot_df(pearsontr_trial_acf_100_dict, units_info_df_subset, 'pearsonr_trial_avg', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171007c0-20ea-469c-9f08-de93f683eb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows with NaNs 0\n",
      "N rows with NaNs 0\n",
      "N rows with NaNs 0\n",
      "N rows with NaNs 0\n"
     ]
    }
   ],
   "source": [
    "isttc_40_file = dataset_folder + 'cut_30min\\\\non_binned\\\\sttc_trial_concat_50ms_20lags_dict.pkl'\n",
    "isttc_acf_40_dict = pd.read_pickle(isttc_40_file)\n",
    "isttc_40_df = get_trials_plot_df(isttc_acf_40_dict, units_info_df_subset, 'isttc_trial_concat', 40)\n",
    "\n",
    "isttc_60_file = dataset_folder + 'cut_30min\\\\non_binned\\\\sttc_trial_concat_50ms_20lags_60trials_dict.pkl'\n",
    "isttc_acf_60_dict = pd.read_pickle(isttc_60_file)\n",
    "isttc_60_df = get_trials_plot_df(isttc_acf_60_dict, units_info_df_subset, 'isttc_trial_concat', 60)\n",
    "\n",
    "isttc_80_file = dataset_folder + 'cut_30min\\\\non_binned\\\\sttc_trial_concat_50ms_20lags_80trials_dict.pkl'\n",
    "isttc_acf_80_dict = pd.read_pickle(isttc_80_file)\n",
    "isttc_80_df = get_trials_plot_df(isttc_acf_80_dict, units_info_df_subset, 'isttc_trial_concat', 80)\n",
    "\n",
    "isttc_100_file = dataset_folder + 'cut_30min\\\\non_binned\\\\sttc_trial_concat_50ms_20lags_100trials_dict.pkl'\n",
    "isttc_acf_100_dict = pd.read_pickle(isttc_100_file)\n",
    "isttc_100_df = get_trials_plot_df(isttc_acf_100_dict, units_info_df_subset, 'isttc_trial_concat', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efac8bd-5455-4228-a508-d147bf27f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(pearson_df_, sttc_df_):\n",
    "    # check for NaNs \n",
    "    \n",
    "    rows_with_nans_acf_df = pearson_df_[pearson_df_.isna().any(axis=1)]\n",
    "    n_rows_with_nan_acf = len(rows_with_nans_acf_df)\n",
    "    print(f'N rows with NaNs {n_rows_with_nan_acf}')\n",
    "    \n",
    "    rows_with_nans_isttc_df = sttc_df_[sttc_df_.isna().any(axis=1)]\n",
    "    n_rows_with_nan_isttc = len(rows_with_nans_isttc_df)\n",
    "    print(f'N rows with NaNs {n_rows_with_nan_isttc}')\n",
    "    \n",
    "    # take from isttc dataset only rows where acf df has no NaNs\n",
    "    sttc_df = sttc_df_[~sttc_df_['unit_id'].isin(rows_with_nans_acf_df['unit_id'].values)]\n",
    "    #sttc_df = sttc_df_\n",
    "    pearson_df = pearson_df_[~pearson_df_['unit_id'].isin(rows_with_nans_acf_df['unit_id'].values)]\n",
    "    \n",
    "    print(f'len acf_full_plot_df {len(pearson_df)}, len isttc_acf_df {len(sttc_df)}')\n",
    "\n",
    "    return pearson_df, sttc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd13f6-dd8c-4425-8e7e-c7c960f629a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsontr_trial_acf_40_df, isttc_acf_40_df = remove_nans(pearsontr_trial_acf_40_df, isttc_acf_40_df)\n",
    "pearsontr_trial_acf_60_df, isttc_acf_60_df = remove_nans(pearsontr_trial_acf_60_df, isttc_acf_60_df)\n",
    "pearsontr_trial_acf_80_df, isttc_acf_80_df = remove_nans(pearsontr_trial_acf_80_df, isttc_acf_80_df)\n",
    "pearsontr_trial_acf_100_df, isttc_acf_100_df = remove_nans(pearsontr_trial_acf_100_df, isttc_acf_100_df)\n",
    "pearsontr_trial_acf_150_df, isttc_acf_150_df = remove_nans(pearsontr_trial_acf_150_df, isttc_acf_150_df)\n",
    "pearsontr_trial_acf_200_df, isttc_acf_200_df = remove_nans(pearsontr_trial_acf_200_df, isttc_acf_200_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89b5c8-40de-420d-aeee-bd1515d0b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acf_full_df_file = dataset_folder + 'cut_30min\\\\binned\\\\acf_full_50ms_20lags_df.pkl'\n",
    "# acf_full_df = pd.read_pickle(acf_full_df_file)\n",
    "# acf_isttc_full_df_file = dataset_folder + 'cut_30min\\\\non_binned\\\\acf_isttc_full_50ms_20lags_df_25dt.pkl'\n",
    "# acf_isttc_full_df = pd.read_pickle(acf_isttc_full_df_file)\n",
    "\n",
    "def unit_taus(acf_full_df_file_):\n",
    "    n_lags = 20\n",
    "    acf_cols = ['acf_' + str(i) for i in range(n_lags+1)]\n",
    "    print('acf_cols {}'.format(acf_cols))\n",
    "    \n",
    "    acf_full_df = pd.read_pickle(acf_full_df_file_)\n",
    "    \n",
    "    acf_full_2d = acf_full_df[acf_cols].values\n",
    "    print(f'acf_2d shape {acf_full_2d.shape}')\n",
    "    acf_full_unit_ids = acf_full_df['unit_id'].values\n",
    "    print(f'acf_full_unit_ids shape {acf_full_unit_ids.shape}')\n",
    "    \n",
    "    acf_full_dict = {}\n",
    "    for unit_id_idx, unit_id in enumerate(acf_full_unit_ids):\n",
    "        if unit_id_idx % 1000 == 0:\n",
    "            print(f'#####\\nProcessing unit {unit_id}, {unit_id_idx+1}/{len(acf_full_unit_ids)}, {datetime.now()}')\n",
    "        fit_popt, fit_pcov, tau, tau_ci, fit_r_squared, explained_var, log_message = fit_single_exp(acf_full_2d[unit_id_idx,:],\n",
    "                                                                                  start_idx_=1, exp_fun_=func_single_exp_monkey)\n",
    "        taus = {'tau':tau,\n",
    "                'tau_lower':tau_ci[0],\n",
    "                'tau_upper':tau_ci[1],\n",
    "                'fit_r_squared': fit_r_squared,\n",
    "                'explained_var': explained_var,\n",
    "                'popt': fit_popt,\n",
    "                'pcov': fit_pcov,\n",
    "                'log_message': log_message}\n",
    "        acf_full_dict[unit_id] = {'taus': taus,\n",
    "                                  'acf': acf_full_2d[unit_id_idx,:]}\n",
    "    return acf_full_dict\n",
    "\n",
    "acf_full_dict_30 = unit_taus(dataset_folder + 'cut_30min\\\\binned\\\\acf_full_50ms_20lags_df.pkl')\n",
    "isttc_full_dict_30 = unit_taus(dataset_folder + 'cut_30min\\\\non_binned\\\\acf_isttc_full_50ms_20lags_df_25dt.pkl')\n",
    "\n",
    "\n",
    "def calculate_acf_decline_flag(acf_, start_idx=3, end_idx=5):\n",
    "    acf_decay = np.all(np.diff(acf_[start_idx:end_idx]) <= 0)\n",
    "    return acf_decay\n",
    "\n",
    "def make_plot_df(acf_full_dict, method, length):\n",
    "    data = []\n",
    "    for unit_id, unit_data in acf_full_dict.items():\n",
    "        taus = unit_data['taus']  \n",
    "        data.append({\n",
    "            'unit_id': unit_id,\n",
    "            'tau': taus['tau'],\n",
    "            # 'tau_lower': taus['tau_lower'],\n",
    "            # 'tau_upper': taus['tau_upper'],\n",
    "            'fit_r_squared': taus['fit_r_squared'],\n",
    "            'decline_150_250': calculate_acf_decline_flag(unit_data['acf'], start_idx=2, end_idx=4)\n",
    "        })\n",
    "    acf_full_plot_df = pd.DataFrame(data)\n",
    "    acf_full_plot_df['method'] = method\n",
    "    acf_full_plot_df['length'] = length\n",
    "    acf_full_plot_df['tau_ms'] = acf_full_plot_df['tau'] * 50\n",
    "    acf_full_plot_df = acf_full_plot_df.merge(units_info_df_subset, on='unit_id', how='left')\n",
    "    \n",
    "    rows_with_nans_df = acf_full_plot_df[acf_full_plot_df.isna().any(axis=1)]\n",
    "    n_rows_with_nan = len(rows_with_nans_df)\n",
    "    print(f'N rows with NaNs {n_rows_with_nan}')\n",
    "\n",
    "    return acf_full_plot_df\n",
    "\n",
    "acf_30_plot = make_plot_df(acf_full_dict_30, 'acf_full', 30)\n",
    "sttc_30_plot = make_plot_df(isttc_full_dict_30, 'sttc_full', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0194c-5bd9-44c6-bccc-d5fba9a69efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsontr_40_df['tau_diff_rel'] = np.abs(pearsontr_40_df['tau_ms'] - acf_30_plot['tau_ms']) / acf_30_plot['tau_ms'] * 100\n",
    "pearsontr_40_df['tau_diff_rel_log10'] = np.log10(pearsontr_40_df['tau_diff_rel'])\n",
    "\n",
    "pearsontr_60_df['tau_diff_rel'] = np.abs(pearsontr_60_df['tau_ms'] - acf_30_plot['tau_ms']) / acf_30_plot['tau_ms'] * 100\n",
    "pearsontr_60_df['tau_diff_rel_log10'] = np.log10(pearsontr_60_df['tau_diff_rel'])\n",
    "\n",
    "pearsontr_80_df['tau_diff_rel'] = np.abs(pearsontr_80_df['tau_ms'] - acf_30_plot['tau_ms']) / acf_30_plot['tau_ms'] * 100\n",
    "pearsontr_80_df['tau_diff_rel_log10'] = np.log10(pearsontr_80_df['tau_diff_rel'])\n",
    "\n",
    "pearsontr_100_df['tau_diff_rel'] = np.abs(pearsontr_100_df['tau_ms'] - acf_30_plot['tau_ms']) / acf_30_plot['tau_ms'] * 100\n",
    "pearsontr_100_df['tau_diff_rel_log10'] = np.log10(pearsontr_40_df['tau_diff_rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b058a24-7b03-424e-a8fd-3a70c9296bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "isttc_40_df['tau_diff_rel'] = np.abs(isttc_40_df['tau_ms'] - acf_30_plot['tau_ms']) / acf_30_plot['tau_ms'] * 100\n",
    "isttc_40_df['tau_diff_rel_log10'] = np.log10(isttc_40_df['tau_diff_rel'])\n",
    "\n",
    "isttc_60_df['tau_diff_rel'] = np.abs(isttc_60_df['tau_ms'] - sttc_30_plot['tau_ms']) / sttc_30_plot['tau_ms'] * 100\n",
    "isttc_60_df['tau_diff_rel_log10'] = np.log10(isttc_60_df['tau_diff_rel'])\n",
    "\n",
    "isttc_80_df['tau_diff_rel'] = np.abs(isttc_80_df['tau_ms'] - sttc_30_plot['tau_ms']) / sttc_30_plot['tau_ms'] * 100\n",
    "isttc_80_df['tau_diff_rel_log10'] = np.log10(isttc_80_df['tau_diff_rel'])\n",
    "\n",
    "isttc_100_df['tau_diff_rel'] = np.abs(isttc_100_df['tau_ms'] - sttc_30_plot['tau_ms']) / sttc_30_plot['tau_ms'] * 100\n",
    "isttc_100_df['tau_diff_rel_log10'] = np.log10(isttc_40_df['tau_diff_rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f65843df-ac6c-48fe-b810-42acfdf6c8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_lower</th>\n",
       "      <th>tau_upper</th>\n",
       "      <th>fit_r_squared</th>\n",
       "      <th>decline_150_250</th>\n",
       "      <th>method</th>\n",
       "      <th>n_trials</th>\n",
       "      <th>tau_ms</th>\n",
       "      <th>ecephys_structure_acronym</th>\n",
       "      <th>fr_hz_spont_30min</th>\n",
       "      <th>lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950913540</td>\n",
       "      <td>0.849050</td>\n",
       "      <td>-7.344097e-01</td>\n",
       "      <td>2.432510e+00</td>\n",
       "      <td>3.352365e-01</td>\n",
       "      <td>True</td>\n",
       "      <td>pearsonr_trial_avg</td>\n",
       "      <td>40</td>\n",
       "      <td>4.245252e+01</td>\n",
       "      <td>VISam</td>\n",
       "      <td>6.038333</td>\n",
       "      <td>1.239003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950915005</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>8.316149e-03</td>\n",
       "      <td>8.316149e-03</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>False</td>\n",
       "      <td>pearsonr_trial_avg</td>\n",
       "      <td>40</td>\n",
       "      <td>4.158075e-01</td>\n",
       "      <td>VISam</td>\n",
       "      <td>4.030556</td>\n",
       "      <td>0.628989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>950915018</td>\n",
       "      <td>0.037434</td>\n",
       "      <td>3.743384e-02</td>\n",
       "      <td>3.743384e-02</td>\n",
       "      <td>-3.997691e-12</td>\n",
       "      <td>False</td>\n",
       "      <td>pearsonr_trial_avg</td>\n",
       "      <td>40</td>\n",
       "      <td>1.871692e+00</td>\n",
       "      <td>VISam</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>0.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950913798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>pearsonr_trial_avg</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VISam</td>\n",
       "      <td>1.045556</td>\n",
       "      <td>0.683688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>950915049</td>\n",
       "      <td>26976.692741</td>\n",
       "      <td>-2.157470e+08</td>\n",
       "      <td>2.158009e+08</td>\n",
       "      <td>3.231913e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>pearsonr_trial_avg</td>\n",
       "      <td>40</td>\n",
       "      <td>1.348835e+06</td>\n",
       "      <td>VISam</td>\n",
       "      <td>0.953889</td>\n",
       "      <td>1.125211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46195</th>\n",
       "      <td>951190507</td>\n",
       "      <td>78726.424176</td>\n",
       "      <td>-4.042800e+08</td>\n",
       "      <td>4.044375e+08</td>\n",
       "      <td>7.406914e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>isttc_trial_concat</td>\n",
       "      <td>100</td>\n",
       "      <td>3.936321e+06</td>\n",
       "      <td>VISrl</td>\n",
       "      <td>2.644444</td>\n",
       "      <td>0.795264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46196</th>\n",
       "      <td>951190510</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>-6.741776e+02</td>\n",
       "      <td>6.744549e+02</td>\n",
       "      <td>4.183524e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>isttc_trial_concat</td>\n",
       "      <td>100</td>\n",
       "      <td>6.934210e+00</td>\n",
       "      <td>VISrl</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.972755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46197</th>\n",
       "      <td>951190529</td>\n",
       "      <td>0.047368</td>\n",
       "      <td>-2.560849e+06</td>\n",
       "      <td>2.560849e+06</td>\n",
       "      <td>-9.963492e-10</td>\n",
       "      <td>False</td>\n",
       "      <td>isttc_trial_concat</td>\n",
       "      <td>100</td>\n",
       "      <td>2.368377e+00</td>\n",
       "      <td>VISrl</td>\n",
       "      <td>5.059444</td>\n",
       "      <td>0.550662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46198</th>\n",
       "      <td>951190848</td>\n",
       "      <td>0.086713</td>\n",
       "      <td>7.602238e-02</td>\n",
       "      <td>9.740421e-02</td>\n",
       "      <td>1.209777e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>isttc_trial_concat</td>\n",
       "      <td>100</td>\n",
       "      <td>4.335665e+00</td>\n",
       "      <td>VISrl</td>\n",
       "      <td>0.303889</td>\n",
       "      <td>1.474969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46199</th>\n",
       "      <td>951190594</td>\n",
       "      <td>28.442351</td>\n",
       "      <td>-7.681353e+01</td>\n",
       "      <td>1.336982e+02</td>\n",
       "      <td>7.383369e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>isttc_trial_concat</td>\n",
       "      <td>100</td>\n",
       "      <td>1.422118e+03</td>\n",
       "      <td>VISrl</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.318724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46200 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unit_id           tau     tau_lower     tau_upper  fit_r_squared  \\\n",
       "0      950913540      0.849050 -7.344097e-01  2.432510e+00   3.352365e-01   \n",
       "1      950915005      0.008316  8.316149e-03  8.316149e-03  -2.220446e-16   \n",
       "2      950915018      0.037434  3.743384e-02  3.743384e-02  -3.997691e-12   \n",
       "3      950913798           NaN           NaN           NaN            NaN   \n",
       "4      950915049  26976.692741 -2.157470e+08  2.158009e+08   3.231913e-01   \n",
       "...          ...           ...           ...           ...            ...   \n",
       "46195  951190507  78726.424176 -4.042800e+08  4.044375e+08   7.406914e-01   \n",
       "46196  951190510      0.138684 -6.741776e+02  6.744549e+02   4.183524e-04   \n",
       "46197  951190529      0.047368 -2.560849e+06  2.560849e+06  -9.963492e-10   \n",
       "46198  951190848      0.086713  7.602238e-02  9.740421e-02   1.209777e-01   \n",
       "46199  951190594     28.442351 -7.681353e+01  1.336982e+02   7.383369e-01   \n",
       "\n",
       "       decline_150_250              method  n_trials        tau_ms  \\\n",
       "0                 True  pearsonr_trial_avg        40  4.245252e+01   \n",
       "1                False  pearsonr_trial_avg        40  4.158075e-01   \n",
       "2                False  pearsonr_trial_avg        40  1.871692e+00   \n",
       "3                False  pearsonr_trial_avg        40           NaN   \n",
       "4                False  pearsonr_trial_avg        40  1.348835e+06   \n",
       "...                ...                 ...       ...           ...   \n",
       "46195            False  isttc_trial_concat       100  3.936321e+06   \n",
       "46196            False  isttc_trial_concat       100  6.934210e+00   \n",
       "46197            False  isttc_trial_concat       100  2.368377e+00   \n",
       "46198            False  isttc_trial_concat       100  4.335665e+00   \n",
       "46199            False  isttc_trial_concat       100  1.422118e+03   \n",
       "\n",
       "      ecephys_structure_acronym  fr_hz_spont_30min        lv  \n",
       "0                         VISam           6.038333  1.239003  \n",
       "1                         VISam           4.030556  0.628989  \n",
       "2                         VISam           1.903333  0.557600  \n",
       "3                         VISam           1.045556  0.683688  \n",
       "4                         VISam           0.953889  1.125211  \n",
       "...                         ...                ...       ...  \n",
       "46195                     VISrl           2.644444  0.795264  \n",
       "46196                     VISrl           0.751667  0.972755  \n",
       "46197                     VISrl           5.059444  0.550662  \n",
       "46198                     VISrl           0.303889  1.474969  \n",
       "46199                     VISrl           1.460000  1.318724  \n",
       "\n",
       "[46200 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_df = pd.concat([pearsontr_40_df, isttc_40_df, pearsontr_60_df, isttc_60_df, \n",
    "                    pearsontr_80_df, isttc_80_df, pearsontr_100_df, isttc_100_df])\n",
    "\n",
    "tau_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "tau_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad84bd5c-e00f-48cc-a225-85236ea1d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df.to_pickle(dataset_folder + 'tau_unit_long_2_methods_var_trials_with_nans_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dada6f-55f6-4081-91de-97c6042cb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop rows where tau_ms is NaN\n",
    "df_clean = tau_df.dropna(subset=['tau_ms'])\n",
    "#df_clean = df_clean[df_clean['fit_r_squared'] > 0]\n",
    "#df_clean = df_clean[df_clean['tau_ms'] < 1000]\n",
    "\n",
    "# Step 2: Count unique method × n_trials combos per unit_id\n",
    "required_combos = df_clean.groupby(['method', 'n_trials']).ngroups\n",
    "\n",
    "# Step 3: Count actual valid combos per unit_id\n",
    "valid_units = (\n",
    "    df_clean\n",
    "    .groupby('unit_id')\n",
    "    .agg(n_combos=('tau_ms', lambda x: x.count()),\n",
    "         unique_combos=('tau_ms', lambda x: x.groupby([df_clean.loc[x.index, 'method'], \n",
    "                                                        df_clean.loc[x.index, 'n_trials']]).ngroups))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 4: Keep only unit_ids with all required combinations\n",
    "complete_units = valid_units[\n",
    "    valid_units['unique_combos'] == required_combos\n",
    "]['unit_id']\n",
    "\n",
    "# Step 5: Filter the original df\n",
    "df_filtered = df_clean[df_clean['unit_id'].isin(complete_units)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62c96d-52c2-4f4d-9e18-f15fd0930681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby(by=['method', 'n_trials'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95982e-dd99-403f-83f4-53449d71db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(dataset_folder + 'tau_unit_long_2_methods_var_trials_df.csv')\n",
    "df_filtered.to_pickle(dataset_folder + 'tau_unit_long_2_methods_var_trials_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff9f3b-2682-4cb6-abbb-95fc01be5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby(by=['method', 'n_trials'], as_index=False)['tau_diff_rel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472e6a2-64db-4721-aa57-c53de54db7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_taus:\n",
    "#     class NumpyEncoder(json.JSONEncoder):\n",
    "#         def default(self, obj):\n",
    "#             if isinstance(obj, np.ndarray):\n",
    "#                 return obj.tolist()  # Convert ndarray to list\n",
    "#             return super().default(obj)\n",
    "    \n",
    "#     with open(dataset_folder + 'area_taus_dict.json', 'w') as f:\n",
    "#         json.dump(area_taus_dict, f, cls=NumpyEncoder, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697f924-4c98-48b1-8257-3cbb2bcd407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(dataset_folder + 'area_taus_dict.json', 'r') as f:\n",
    "#     area_taus_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7f803-7497-4ff4-bc7d-b71878dd0625",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db53d27-4b1f-46e9-8b03-79c5e0a8ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_pickle(dataset_folder + 'tau_unit_long_2_methods_var_trials_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e611f5b-786e-4736-9aeb-ff62e57aceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235762d6-a3d9-400f-ae6b-ee5a58ee7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby(by=['method', 'n_trials'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013b142-3ac0-4307-9c8e-1ff914e2cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_pearson_trail_avg = '#f4a91c' \n",
    "color_sttc_trail_concat = '#955da2' \n",
    "\n",
    "colors = [color_pearson_trail_avg, color_sttc_trail_concat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb434f5-dcf2-48c5-9e15-8f8556e42fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1, figsize=(5, 3), sharey=False)\n",
    "\n",
    "sns.regplot(x='n_trials', y='tau_diff_rel_log10', data = df_filtered.query('method == \"pearsonr_trial_avg\"').copy(),\n",
    "            scatter=None, ax=axes, label='pearsonr', color=color_pearson_trail_avg)\n",
    "sns.regplot(x='n_trials', y='tau_diff_rel_log10', data = df_filtered.query('method == \"isttc_trial_concat\"').copy(),\n",
    "            scatter=None, ax=axes, label='isttc_concat', color=color_sttc_trail_concat)\n",
    "\n",
    "axes.legend(frameon=False)\n",
    "axes.set_xlabel('Signal lenght (min)')\n",
    "\n",
    "# for ax in axes.flat:\n",
    "#     ax.set_ylabel('Log10 diff(IT, \\nground truth) (ms)')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708dd708-0ec6-42c4-8cef-667fd4eb7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863e11d-825b-4985-9a4c-a7159717af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals for error plots\n",
    "intervals = {\n",
    "    '+-100':   (0,   100),\n",
    "    '+-75':  (0,  75),\n",
    "    '+-50':  (0,  50),\n",
    "    '+-25':  (0,  25),\n",
    "}\n",
    "\n",
    "tau_3methods_df = df_filtered[['unit_id', 'method', 'n_trials', 'tau_ms', \n",
    "       'tau_diff_rel', 'tau_diff_rel_log10']].copy()\n",
    "tau_3methods_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df = tau_3methods_df.copy()\n",
    "rows = []\n",
    "for method, sub in df.groupby(by=['method','n_trials']):\n",
    "    total = len(sub)\n",
    "    row = {'method': method}\n",
    "    for name, (lo, hi) in intervals.items():\n",
    "        cnt = sub['tau_diff_rel'].between(lo, hi).sum()\n",
    "        row[name] = cnt/total*100\n",
    "    rows.append(row)\n",
    "tau_3methods_error_df = pd.DataFrame(rows).set_index('method')\n",
    "\n",
    "# make long df\n",
    "tau_3methods_error_df = tau_3methods_error_df.reset_index()\n",
    "tau_3methods_error_long_df = tau_3methods_error_df.melt(\n",
    "    id_vars='method',\n",
    "    var_name='interval',\n",
    "    value_name='percentage'\n",
    ")\n",
    "\n",
    "tau_3methods_error_long_df[['method','n_trials']] = pd.DataFrame(\n",
    "    tau_3methods_error_long_df['method'].tolist(),\n",
    "    index=tau_3methods_error_long_df.index\n",
    ")\n",
    "tau_3methods_error_long_df = tau_3methods_error_long_df.rename(columns={'interval':'error_interval'})\n",
    "tau_3methods_error_long_df = tau_3methods_error_long_df[['method','n_trials','error_interval','percentage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4ea23-e8d4-47e8-9a95-62bd3e3f8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for heatmaps\n",
    "# ACF\n",
    "pearsonr_trial_avg = tau_3methods_error_long_df[\n",
    "    tau_3methods_error_long_df['method']=='pearsonr_trial_avg'\n",
    "]\n",
    "pearsonr_trial_avg_pivot = pearsonr_trial_avg.pivot(\n",
    "    index='n_trials',\n",
    "    columns='error_interval',\n",
    "    values='percentage'\n",
    ")\n",
    "\n",
    "# ISTTC\n",
    "sttc_trial_concat = tau_3methods_error_long_df[\n",
    "    tau_3methods_error_long_df['method']=='isttc_trial_concat'\n",
    "]\n",
    "sttc_trial_concat_pivot = sttc_trial_concat.pivot(\n",
    "    index='n_trials',\n",
    "    columns='error_interval',\n",
    "    values='percentage'\n",
    ")\n",
    "\n",
    "diff_pivot_pearsonr_concat = pearsonr_trial_avg_pivot - sttc_trial_concat_pivot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7726236-f46f-40b7-8548-8667c27cd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['+-100', '+-75', '+-50', '+-25']\n",
    "\n",
    "row_order = sorted(diff_pivot_pearsonr_concat.index, reverse=True)\n",
    "\n",
    "pearsonr_trial_avg_ordered  = pearsonr_trial_avg_pivot.reindex(index=row_order, columns=col_order)\n",
    "sttc_trial_concat_ordered  = sttc_trial_concat_pivot.reindex(index=row_order, columns=col_order)\n",
    "diff_pivot_pearsonr_concat_pivot_ordered  = diff_pivot_pearsonr_concat.reindex(index=row_order, columns=col_order)\n",
    "\n",
    "# plot ACF heatmap\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 3), sharey=True)\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "diff_limit = np.max([np.abs(diff_pivot_pearsonr_concat_pivot_ordered.min().min()), \n",
    "                     np.abs(diff_pivot_pearsonr_concat_pivot_ordered.max().max())])\n",
    "\n",
    "norm = TwoSlopeNorm(vcenter=0, vmin=-diff_limit, vmax=diff_limit)\n",
    "#norm = TwoSlopeNorm(vcenter=0)\n",
    "\n",
    "sns.heatmap(\n",
    "    pearsonr_trial_avg_ordered,\n",
    "    cmap=\"magma\", vmin=0, vmax=75,\n",
    "    cbar_kws={'label': 'Percentage'}, \n",
    "    annot=True, fmt=\".1f\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Pearsonr avg: % signals\")\n",
    "\n",
    "sns.heatmap(\n",
    "    sttc_trial_concat_ordered,\n",
    "    cmap=\"magma\", vmin=0, vmax=75,\n",
    "    cbar_kws={'label': 'Percentage'}, \n",
    "    annot=True, fmt=\".1f\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title('STTC concat: % signals')\n",
    "\n",
    "sns.heatmap(\n",
    "    diff_pivot_pearsonr_concat_pivot_ordered,\n",
    "    cmap=\"RdBu_r\", \n",
    "    norm=norm,\n",
    "    cbar_kws={'label': 'Percentage'}, \n",
    "    annot=True, fmt=\".1f\",\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title('PearsonR - iSTTC')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Error (ms)')\n",
    "    ax.set_ylabel('N trials')\n",
    "\n",
    "save_fig = True\n",
    "if save_fig:\n",
    "    plt.savefig(fig_folder + 'taus_n_trial_var_p_vs_concat_parametric_heatmaps.png' , bbox_inches='tight', dpi=300)\n",
    "    plt.savefig(fig_folder + 'taus_n_trial_var_p_vs_concat_parametric_heatmaps.svg' , bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
