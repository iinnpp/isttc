{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset from Allen repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "from cfg_global import project_folder_path\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys.visualization import raster_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain_observatory_1.1', 'functional_connectivity']\n"
     ]
    }
   ],
   "source": [
    "# cache directory path, it determines where downloaded data will be stored\n",
    "output_dir = project_folder_path + 'ecephys_cache_dir//'\n",
    "manifest_path = os.path.join(output_dir, \"manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "print(cache.get_all_session_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_warehouse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'results\\\\allen_mice\\\\dataset\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data to local drive \n",
    "\n",
    "already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all sessions to local drive \n",
    "if download_from_warehouse:\n",
    "    for session_id, row in brain_observatory_type_sessions.iterrows():\n",
    "    \n",
    "        truncated_file = True\n",
    "        directory = os.path.join(output_dir + '/session_' + str(session_id))\n",
    "    \n",
    "        while truncated_file:\n",
    "            session = cache.get_session_data(session_id)\n",
    "            try:\n",
    "                print(session_id)\n",
    "                print(session.specimen_name)\n",
    "                truncated_file = False\n",
    "            except OSError:\n",
    "                shutil.rmtree(directory)\n",
    "                print(\" Truncated spikes file, re-downloading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sessions data\n",
    "\n",
    "Sessions are already loaded on local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len sessions: 58\n",
      "len brain_observatory_type_sessions = functional_connectivity: 26\n",
      "Index(['published_at', 'specimen_id', 'session_type', 'age_in_days', 'sex',\n",
      "       'full_genotype', 'unit_count', 'channel_count', 'probe_count',\n",
      "       'ecephys_structure_acronyms'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_at</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>session_type</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>sex</th>\n",
       "      <th>full_genotype</th>\n",
       "      <th>unit_count</th>\n",
       "      <th>channel_count</th>\n",
       "      <th>probe_count</th>\n",
       "      <th>ecephys_structure_acronyms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839557629</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>821469666</td>\n",
       "      <td>functional_connectivity</td>\n",
       "      <td>115.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>450</td>\n",
       "      <td>1853</td>\n",
       "      <td>5</td>\n",
       "      <td>[APN, NOT, MB, DG, CA1, VISam, nan, VISpm, LGd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840012044</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>820866121</td>\n",
       "      <td>functional_connectivity</td>\n",
       "      <td>116.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>758</td>\n",
       "      <td>2298</td>\n",
       "      <td>6</td>\n",
       "      <td>[APN, DG, CA1, VISam, nan, LP, VISpm, VISp, LG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847657808</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>827809884</td>\n",
       "      <td>functional_connectivity</td>\n",
       "      <td>126.0</td>\n",
       "      <td>F</td>\n",
       "      <td>wt/wt</td>\n",
       "      <td>874</td>\n",
       "      <td>2298</td>\n",
       "      <td>6</td>\n",
       "      <td>[APN, NOT, DG, HPF, ProS, CA1, VISam, nan, MB,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   published_at  specimen_id             session_type  \\\n",
       "id                                                                      \n",
       "839557629  2019-10-03T00:00:00Z    821469666  functional_connectivity   \n",
       "840012044  2019-10-03T00:00:00Z    820866121  functional_connectivity   \n",
       "847657808  2019-10-03T00:00:00Z    827809884  functional_connectivity   \n",
       "\n",
       "           age_in_days sex                                    full_genotype  \\\n",
       "id                                                                            \n",
       "839557629        115.0   M  Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt   \n",
       "840012044        116.0   M  Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt   \n",
       "847657808        126.0   F                                            wt/wt   \n",
       "\n",
       "           unit_count  channel_count  probe_count  \\\n",
       "id                                                  \n",
       "839557629         450           1853            5   \n",
       "840012044         758           2298            6   \n",
       "847657808         874           2298            6   \n",
       "\n",
       "                                  ecephys_structure_acronyms  \n",
       "id                                                            \n",
       "839557629  [APN, NOT, MB, DG, CA1, VISam, nan, VISpm, LGd...  \n",
       "840012044  [APN, DG, CA1, VISam, nan, LP, VISpm, VISp, LG...  \n",
       "847657808  [APN, NOT, DG, HPF, ProS, CA1, VISam, nan, MB,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functional connecivity dataset contains 30 min spontaneous activity block\n",
    "sessions = cache.get_session_table()\n",
    "print('len sessions: {}'.format(len(sessions)))\n",
    "\n",
    "brain_observatory_type_sessions = sessions[sessions[\"session_type\"] == \"functional_connectivity\"]\n",
    "print('len brain_observatory_type_sessions = functional_connectivity: {}'.format(len(brain_observatory_type_sessions)))\n",
    "print(brain_observatory_type_sessions.keys())\n",
    "\n",
    "brain_observatory_type_sessions.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_observatory_type_sessions.to_pickle(dataset_folder + 'functional_connectivity_sessions_info_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get single units \n",
    "\n",
    "using 30 min of spontaneous activity (animals were shown grey screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = dataset_folder + 'allen_func_conn_around30min_spont_with_quality_metrics.csv'\n",
    "output_log = dataset_folder + 'dataload_log_with_quality_metrics.txt'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "C:\\Users\\ipochino\\AppData\\Local\\anaconda3\\envs\\allensdk\\lib\\site-packages\\hdmf\\spec\\namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout\n",
    "sys.stdout = open(output_log, 'w')\n",
    "\n",
    "for session_id in brain_observatory_type_sessions.index.values:\n",
    "\n",
    "    print('############################')\n",
    "    print('processing session {}'.format(session_id))\n",
    "    \n",
    "    # load session\n",
    "    session = cache.get_session_data(session_id)\n",
    "    \n",
    "    # load units\n",
    "    units_df = session.units\n",
    "    print('len units df {}'.format(len(units_df)))\n",
    "    \n",
    "    # load stimulus presentation \n",
    "    presentations = session.get_stimulus_table(\"spontaneous\")\n",
    "    spont_period_id = presentations.query('duration > 1200').index.values[0]\n",
    "    print('Spontaneous period {}'.format(presentations.loc[spont_period_id, :]))\n",
    "    \n",
    "    # load spikes from stimulus period\n",
    "    spikes_df = session.presentationwise_spike_times(\n",
    "        stimulus_presentation_ids=spont_period_id,  \n",
    "        unit_ids=units_df.index.values\n",
    "    )\n",
    "    \n",
    "    # make df\n",
    "    spikes_df['time_since_stimulus_presentation_onset_str'] = spikes_df.time_since_stimulus_presentation_onset.astype(str)\n",
    "    spikes_wide_df = spikes_df.groupby(by='unit_id', as_index=False).agg(spike_times=('time_since_stimulus_presentation_onset_str', ','.join))\n",
    "    \n",
    "    units_df_subset = units_df[['ecephys_structure_acronym', 'firing_rate', 'amplitude_cutoff', 'isi_violations', 'presence_ratio']].copy()\n",
    "    units_df_subset.reset_index(inplace=True)\n",
    "    units_df_subset['specimen_id'] = brain_observatory_type_sessions.loc[session_id, :]['specimen_id']\n",
    "    units_df_subset['session_id'] = session_id\n",
    "    \n",
    "    units_merged_df = pd.merge(units_df_subset, spikes_wide_df, on='unit_id', how='inner')\n",
    "    \n",
    "    # write to file \n",
    "    spikes_out_dict = units_merged_df.to_dict(orient='index')\n",
    "    print('Writing to csv...')\n",
    "    with open(output_filename, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for k,v in spikes_out_dict.items():\n",
    "            if verbose:\n",
    "                print('Writing unit {}'.format(v['unit_id']))\n",
    "            #    spikes_l = spike_train.tolist()\n",
    "            row = [v[\n",
    "                   'specimen_id']] + [v[\n",
    "                   'session_id']] + [v[\n",
    "                   'unit_id']] + [v[\n",
    "                   'ecephys_structure_acronym']] + [v[\n",
    "                   'firing_rate']] + [v[\n",
    "                   'amplitude_cutoff']] + [v[\n",
    "                   'isi_violations']] + [v[\n",
    "                   'presence_ratio']] + list(map(float, v['spike_times'].split(',')))\n",
    "            writer.writerow(row)\n",
    "\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some usefull line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the AllenSDK applies filters so only units above a set of thresholds are returned.\n",
    "# The default filter values are as follows:\n",
    "\n",
    "# isi_violations < 0.5\n",
    "# amplitude_cutoff < 0.1\n",
    "# presence_ratio > 0.9\n",
    "# units = cache.get_units()\n",
    "\n",
    "units = cache.get_units(amplitude_cutoff_maximum = np.inf,\n",
    "                        presence_ratio_minimum = -np.inf,\n",
    "                        isi_violations_maximum = np.inf)\n",
    "print(units.keys())\n",
    "len(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.query('session_type == \"functional_connectivity\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
