{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821b2ec7-71a8-4c9e-ac53-d569c966e511",
   "metadata": {},
   "source": [
    "We do not have ground truth here but we have the high quality units from neuropixels. The idea is to show that the STTC concat \n",
    "works better compared to the trial average methods (both Pearson and STTC).\n",
    "\n",
    "Steps:\n",
    "0. Calculate STTC and ACF on the full signal ()\n",
    "1. Take the full signal and randomly pick N trials\n",
    "2. Calculate Pearson trial-average\n",
    "3. Calculate STTC trial-average\n",
    "4. Calculate STTC on concatenated data\n",
    "5. Compare 2,3,4, values calculated on full signa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39be3909-302c-4ae0-ac5a-b8e950540326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "#from scipy.optimize import curve_fit, OptimizeWarning\n",
    "\n",
    "#import warnings\n",
    "\n",
    "# import from scripts\n",
    "import os\n",
    "current_wd = os.getcwd()\n",
    "os.chdir(os.path.abspath(\"..\\\\..\\\\..\\\\isttc\\\\scripts\"))\n",
    "#os.chdir(os.path.abspath(\"C:\\\\Users\\\\ipoch\\\\Documents\\\\repos\\\\isttc\\\\scripts\"))\n",
    "from calculate_tau import fit_single_exp\n",
    "from cfg_global import project_folder_path\n",
    "from calculate_acf import acf_sttc, acf_pearsonr_trial_avg, acf_sttc_trial_avg, acf_sttc_trial_concat\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fa8706-1b43-42d5-ab5a-bcad073eea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = project_folder_path + 'results\\\\allen_mice\\\\dataset\\\\'\n",
    "#fig_folder = project_folder_path + 'results\\\\allen_mice\\\\fig_draft_paper\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fc2dd-d44e-4264-95e8-5781648f0228",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b9b6f5-9174-4dc3-ab9b-6ca0e4d1d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded N units 5775\n"
     ]
    }
   ],
   "source": [
    "csv_data_file = dataset_folder + 'cut_30min\\\\sua_list_constrained.csv'\n",
    "with open(csv_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sua_list = list(reader)\n",
    "print(f'Loaded N units {len(sua_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7509af-1e56-406d-bc7d-d933eaf092b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded N units 5775\n"
     ]
    }
   ],
   "source": [
    "csv_binned_data_file = dataset_folder + 'cut_30min\\\\sua_list_constrained_binned_50ms.csv'\n",
    "with open(csv_binned_data_file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    binned_sua_list = list(reader)\n",
    "print(f'Loaded N units {len(binned_sua_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f8c826-a2bf-4a8f-a5ed-9204f150d982",
   "metadata": {},
   "source": [
    "### Calculate ACFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf95d9c-1608-4c8e-bd63-d443bbe165f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf_cols ['acf_0', 'acf_1', 'acf_2', 'acf_3', 'acf_4', 'acf_5', 'acf_6', 'acf_7', 'acf_8', 'acf_9', 'acf_10', 'acf_11', 'acf_12', 'acf_13', 'acf_14', 'acf_15', 'acf_16', 'acf_17', 'acf_18', 'acf_19', 'acf_20']\n"
     ]
    }
   ],
   "source": [
    "fs = 30000 # raw neuropixels\n",
    "n_lags = 20\n",
    "\n",
    "bin_size = 50 * (fs / 1000)\n",
    "sttc_dt = 49 * (fs / 1000)\n",
    "signal_len = 30 * 60 * fs\n",
    "\n",
    "acf_cols = ['acf_' + str(i) for i in range(n_lags+1)]\n",
    "print('acf_cols {}'.format(acf_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e171cb4e-5343-4df7-b006-26d880da9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_acf_full = True\n",
    "calc_isttc_full = True\n",
    "calc_pearsonr_trial_avg = False\n",
    "calc_sttc_trial_avg = False\n",
    "calc_sttc_trial_concat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2be2cfa-7bec-454c-8b41-a4002110466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unit 0\n",
      "Processing unit 100\n",
      "Processing unit 200\n",
      "Processing unit 300\n",
      "Processing unit 400\n",
      "Processing unit 500\n",
      "Processing unit 600\n",
      "Processing unit 700\n",
      "Processing unit 800\n",
      "Processing unit 900\n",
      "Processing unit 1000\n",
      "Processing unit 1100\n",
      "Processing unit 1200\n",
      "Processing unit 1300\n",
      "Processing unit 1400\n",
      "Processing unit 1500\n",
      "Processing unit 1600\n",
      "Processing unit 1700\n",
      "Processing unit 1800\n",
      "Processing unit 1900\n",
      "Processing unit 2000\n",
      "Processing unit 2100\n",
      "Processing unit 2200\n",
      "Processing unit 2300\n",
      "Processing unit 2400\n",
      "Processing unit 2500\n",
      "Processing unit 2600\n",
      "Processing unit 2700\n",
      "Processing unit 2800\n",
      "Processing unit 2900\n",
      "Processing unit 3000\n",
      "Processing unit 3100\n",
      "Processing unit 3200\n",
      "Processing unit 3300\n",
      "Processing unit 3400\n",
      "Processing unit 3500\n",
      "Processing unit 3600\n",
      "Processing unit 3700\n",
      "Processing unit 3800\n",
      "Processing unit 3900\n",
      "Processing unit 4000\n",
      "Processing unit 4100\n",
      "Processing unit 4200\n",
      "Processing unit 4300\n",
      "Processing unit 4400\n",
      "Processing unit 4500\n",
      "Processing unit 4600\n",
      "Processing unit 4700\n",
      "Processing unit 4800\n",
      "Processing unit 4900\n",
      "Processing unit 5000\n",
      "Processing unit 5100\n",
      "Processing unit 5200\n",
      "Processing unit 5300\n",
      "Processing unit 5400\n",
      "Processing unit 5500\n",
      "Processing unit 5600\n",
      "Processing unit 5700\n",
      "NaNs in acf False\n"
     ]
    }
   ],
   "source": [
    "if calc_acf_full:\n",
    "    acf_full_l = []\n",
    "    unit_metadata_l = []  # To store values 0-7\n",
    "    \n",
    "    for unit_idx, unit in enumerate(binned_sua_list):\n",
    "        if unit_idx % 100 == 0:\n",
    "            print(f'Processing unit {unit_idx}')\n",
    "        spike_train_binned_int = np.asarray([int(spike) for spike in unit[8:]])\n",
    "        spike_train_binned_acf = acf(spike_train_binned_int, nlags=n_lags)\n",
    "        acf_full_l.append(spike_train_binned_acf)\n",
    "        unit_metadata_l.append(unit[:8])\n",
    "    \n",
    "    acf_full_df = pd.DataFrame(np.array(acf_full_l), columns=acf_cols)\n",
    "    column_names = [\"specimen_id\", \"session_id\", \"unit_id\", \"ecephys_structure_acronym\", 'firing_rate', 'amplitude_cutoff', 'isi_violations', 'presence_ratio']\n",
    "    metadata_df = pd.DataFrame(unit_metadata_l, columns=column_names)\n",
    "    \n",
    "    acf_full_df = pd.concat([metadata_df, acf_full_df], axis=1)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_full_df.isnull().any().any()))\n",
    "    acf_full_df.head(3)\n",
    "    \n",
    "    acf_full_df.to_pickle(dataset_folder + 'cut_30min\\\\binned\\\\acf\\\\acf_full_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17451f91-7dea-4d57-8dc8-30723cb684a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unit 0\n"
     ]
    }
   ],
   "source": [
    "if calc_isttc_full:\n",
    "    acf_isttc_full_l = []\n",
    "    unit_metadata_l = []  # To store values 0-7\n",
    "    \n",
    "    for unit_idx, unit in enumerate(sua_list):\n",
    "        if unit_idx % 100 == 0:\n",
    "            print(f'Processing unit {unit_idx}')\n",
    "        spike_train_int = np.asarray([int(spike) for spike in unit[8:]])\n",
    "        spike_train_acf = acf_sttc(spike_train_int, n_lags, bin_size, sttc_dt, signal_len, verbose_=False)\n",
    "        acf_isttc_full_l.append(spike_train_acf)\n",
    "        unit_metadata_l.append(unit[:8])\n",
    "    \n",
    "    acf_isttc_full_df = pd.DataFrame(np.array(acf_isttc_full_l), columns=acf_cols)\n",
    "    column_names = [\"specimen_id\", \"session_id\", \"unit_id\", \"ecephys_structure_acronym\", 'firing_rate', 'amplitude_cutoff', 'isi_violations', 'presence_ratio']\n",
    "    metadata_df = pd.DataFrame(unit_metadata_l, columns=column_names)\n",
    "    \n",
    "    acf_isttc_full_df = pd.concat([metadata_df, acf_isttc_full_df], axis=1)\n",
    "    \n",
    "    print('NaNs in acf {}'.format(acf_isttc_full_df.isnull().any().any()))\n",
    "    acf_isttc_full_df.head(3)\n",
    "\n",
    "    acf_isttc_full_df.to_pickle(dataset_folder + 'cut_30min\\\\non_binned\\\\acf\\\\acf_isttc_full_50ms_20lags_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e39d1-e164-4326-b1b5-55536ffb006f",
   "metadata": {},
   "source": [
    "### Make trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a46a6-ccfb-424d-8411-da21ce86792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(spike_times_, signal_len_, n_trials_, trial_len_, verbose_=False):\n",
    "    # get random trail starts and ends\n",
    "    trials_start = [randrange(0, signal_len_-trial_len_+1) for i in range(n_trials_)]\n",
    "    trials_end = [trial_start + trial_len_ for trial_start in trials_start]\n",
    "    trial_intervals = np.vstack((trials_start, trials_end)).T\n",
    "    if verbose_:\n",
    "        print('N trials {}, trail len {}, n trial starts {}, \\ntrial starts {}, \\ntrial starts {}'.format(n_trials_, trial_len_, \n",
    "                                                                                                          len(trials_start), \n",
    "                                                                                                          trials_start, trials_end))\n",
    "    # get spikes\n",
    "    spikes_trials = []\n",
    "    for i in range(n_trials_):\n",
    "        spikes_trial = spike_times_[np.logical_and(spike_times_ >= trial_intervals[i,0], spike_times_ < trial_intervals[i,1])]\n",
    "        spikes_trials.append(spikes_trial)\n",
    "\n",
    "    # realign all trails to start with 0\n",
    "    spikes_trials_realigned_l = []\n",
    "    for idx, trial in enumerate(spikes_trials):\n",
    "        spikes_trial_realigned = trial - trial_intervals[idx,0] \n",
    "        spikes_trials_realigned_l.append(spikes_trial_realigned)\n",
    "\n",
    "    return spikes_trials_realigned_l\n",
    "\n",
    "def bin_trials(spikes_trials_l_, trial_len_, bin_size_):\n",
    "    binned_spikes_trials_l = []\n",
    "\n",
    "    n_bin_edges =  int(trial_len_/bin_size_)\n",
    "    bins_ = np.linspace(0, bin_size * n_bin_edges, n_bin_edges + 1).astype(int)\n",
    "    for trial in spikes_trials_l_:\n",
    "        binned_spike_train, _ = np.histogram(trial, bins_)\n",
    "        binned_spikes_trials_l.append(binned_spike_train)\n",
    "    binned_spikes_trials_2d = np.asarray(binned_spikes_trials_l)\n",
    "\n",
    "    return binned_spikes_trials_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0973fb6-c9db-40b2-8420-90529b46d0e1",
   "metadata": {},
   "source": [
    "### Run for one trial realization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
