{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420c63d-8785-498b-bca1-1e98fbf59bb5",
   "metadata": {},
   "source": [
    "Compares results from elephant sttc with my implementation of sttc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3729a815-3e02-443a-819c-6a059f90116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import quantities as pq\n",
    "from elephant.spike_train_correlation import spike_time_tiling_coefficient\n",
    "import neo\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be268e7-d3bc-4f32-894b-8705142615c2",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7f17b9a-3e50-43a6-8753-a917fee727c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acf_sttc(signal_, n_lags_, lag_shift_=50, sttc_dt_=25, signal_length_=1000, verbose_=True):\n",
    "    #def calculate_acf_sttc_t(spike_train, n_lags_, acf_lag_ms_, sttc_lag_ms_, rec_length_, verbose=True):\n",
    "    \n",
    "    shift_ms_l = np.linspace(lag_shift_, lag_shift_ * (n_lags_-1), n_lags_-1).astype(int)\n",
    "    if verbose_:\n",
    "        print('shift_ms_l {}'.format(shift_ms_l))\n",
    "\n",
    "    acf_l = []\n",
    "\n",
    "    sttc_no_shift = calc_sttc(signal_, signal_, t_start=0, t_stop=signal_length_, dt=sttc_dt_)\n",
    "    acf_l.append(sttc_no_shift)\n",
    "    # print(acf_l)\n",
    "\n",
    "    # correlated shifted signal\n",
    "    for shift_ms in shift_ms_l:\n",
    "        spike_1 = signal_[signal_ >= shift_ms]\n",
    "        spike_2 = signal_[signal_ < n_lags_*lag_shift_ - shift_ms]\n",
    "        # align, only 1st\n",
    "        spike_1_aligned = [spike - shift_ms for spike in spike_1]\n",
    "        if verbose_:\n",
    "            print(shift_ms)\n",
    "            print(spike_1)\n",
    "            print(spike_2)\n",
    "            print(spike_1_aligned)\n",
    "            print('spike_1 {}, spike_2 {}'.format(spike_1.shape, spike_2.shape))\n",
    "        \n",
    "        isttc = calc_sttc(spike_1_aligned, spike_2, t_start=0, t_stop=signal_length_-shift_ms, dt=sttc_dt_)\n",
    "       # print(isttc)\n",
    "        acf_l.append(isttc)\n",
    "\n",
    "    return acf_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c639bd1e-4f5d-4676-bb22-5aac03e1ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acf_sttc_t(spike_train, n_lags_, acf_lag_ms_, sttc_lag_ms_, rec_length_, verbose=True):\n",
    "    shift_ms_l = np.linspace(acf_lag_ms_, acf_lag_ms_ * (n_lags_-1), n_lags_-1).astype(int)\n",
    "    if verbose:\n",
    "        print('shift_ms_l {}'.format(shift_ms_l))\n",
    "\n",
    "    spike_train_bin = np.zeros(rec_length_)\n",
    "    spike_train_bin[spike_train] = 1\n",
    "    if verbose:\n",
    "        print(spike_train_bin.shape)\n",
    "\n",
    "    sttc_self_l = []\n",
    "    # correlate with itself\n",
    "    spike_train_neo = neo.SpikeTrain(spike_train, units='ms', t_start=0, t_stop=len(spike_train_bin))\n",
    "    sttc_no_shift = spike_time_tiling_coefficient(spike_train_neo, spike_train_neo, dt=sttc_lag_ms_ * pq.ms)\n",
    "    sttc_self_l.append(sttc_no_shift)\n",
    "\n",
    "    # correlated shifted signal\n",
    "    for shift_ms in shift_ms_l:\n",
    "\n",
    "        spike_train_bin1 = spike_train_bin[shift_ms:]\n",
    "        spike_train_bin2 = spike_train_bin[:- shift_ms]\n",
    "        if verbose:\n",
    "            print('spike_train_bin1 {}, spike_train_bin2 {}'.format(spike_train_bin1.shape, spike_train_bin2.shape))\n",
    "        \n",
    "        spike_train_bin1_idx = np.nonzero(spike_train_bin1)[0]\n",
    "        spike_train_bin2_idx = np.nonzero(spike_train_bin2)[0]\n",
    "        if verbose:\n",
    "            print('spike_train_bin1_idx {}'.format(spike_train_bin1_idx))\n",
    "            print('spike_train_bin2_idx {}'.format(spike_train_bin2_idx))\n",
    "        \n",
    "        spike_train_neo_1 = neo.SpikeTrain(spike_train_bin1_idx, units='ms', t_start=0, t_stop=len(spike_train_bin1))\n",
    "        spike_train_neo_2 = neo.SpikeTrain(spike_train_bin2_idx, units='ms', t_start=0, t_stop=len(spike_train_bin2))\n",
    "        if verbose:\n",
    "            print(spike_train_neo_1)\n",
    "            print(spike_train_neo_2)\n",
    "        \n",
    "        sttc_self = spike_time_tiling_coefficient(spike_train_neo_1, spike_train_neo_2, dt=sttc_lag_ms_ * pq.ms)\n",
    "        sttc_self_l.append(sttc_self)\n",
    "\n",
    "    return sttc_self_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8220093c-429c-4edb-ba76-49fe0e8e9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sttc_elephant(spike_train_1, spike_train_2, t_start_, t_stop_, dt_):\n",
    "    spike_train_neo_1 = neo.SpikeTrain(spike_train_1, units='ms', t_start=t_start_, t_stop=t_stop_)\n",
    "    spike_train_neo_2 = neo.SpikeTrain(spike_train_2, units='ms', t_start=t_start_, t_stop=t_stop_)\n",
    "    sttc_no_shift = spike_time_tiling_coefficient(spike_train_neo_1, spike_train_neo_2, dt=dt_ * pq.ms)\n",
    "    return sttc_no_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04234b3-b466-462e-beb4-3ebaac52ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_T(spiketrain, N, dt, t_start, t_stop):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of the total recording time 'tiled' by spikes.\n",
    "    N: number of spikes\n",
    "    \"\"\"\n",
    "    time_A = 2 * N * dt  # maxium possible time\n",
    "\n",
    "    if N == 1:  # for just one spike in train\n",
    "        if spiketrain[0] - t_start < dt:\n",
    "            time_A = time_A - dt + spiketrain[0] - t_start\n",
    "        elif spiketrain[0] + dt > t_stop:\n",
    "            time_A = time_A - dt - spiketrain[0] + t_stop\n",
    "\n",
    "    else:  # if more than one spike in train\n",
    "        '''\n",
    "            This part of code speeds up calculation with respect to the original version\n",
    "        '''\n",
    "        diff = np.diff(spiketrain)\n",
    "        idx = np.where(diff<(2*dt))[0]\n",
    "        Lidx = len(idx)\n",
    "        time_A = time_A - 2 * Lidx * dt + diff[idx].sum()\n",
    "\n",
    "        if (spiketrain[0] - t_start) < dt:\n",
    "            time_A = time_A + spiketrain[0] - dt - t_start\n",
    "\n",
    "        if (t_stop - spiketrain[N - 1]) < dt:\n",
    "            time_A = time_A - spiketrain[-1] - dt + t_stop\n",
    "\n",
    "    T = (time_A / (t_stop - t_start)) #.item()\n",
    "    \n",
    "    return time_A, T\n",
    "\n",
    "def run_P(spiketrain_1, spiketrain_2, N1, N2, dt):\n",
    "    \"\"\"\n",
    "    Check every spike in train 1 to see if there's a spike in train 2\n",
    "    within dt\n",
    "    \"\"\"\n",
    "    Nab = 0\n",
    "    j = 0\n",
    "    for i in range(N1):\n",
    "        L=0\n",
    "        while j < N2:  # don't need to search all j each iteration\n",
    "            if np.abs(spiketrain_1[i] - spiketrain_2[j]) <= dt:\n",
    "                Nab = Nab + 1\n",
    "                L+=1\n",
    "                break\n",
    "            elif spiketrain_2[j] > spiketrain_1[i]:\n",
    "                break\n",
    "            else:\n",
    "                j = j + 1\n",
    "    return Nab\n",
    "\n",
    "def calc_sttc(lag1_l, lag2_l, t_start, t_stop, dt):\n",
    "    n_a = len(lag1_l)\n",
    "    n_b = len(lag2_l)\n",
    "\n",
    "    if n_a == 0 or n_b == 0:\n",
    "        index = 0\n",
    "    else:\n",
    "        time_a, t_a = run_T(lag1_l, n_a, dt, t_start, t_stop)\n",
    "        # print('time_a {}, t_a {}'.format(time_a, t_a))\n",
    "        \n",
    "        time_b, t_b = run_T(lag2_l, n_b, dt, t_start, t_stop)\n",
    "        # print('time_b {}, t_b {}'.format(time_b, t_b))\n",
    "        \n",
    "        p_a_count = run_P(lag1_l, lag2_l, n_a, n_b, dt)\n",
    "        p_a = p_a_count / float(n_a)\n",
    "        # print('p_a_count {}, p_a {}'.format(p_a_count, p_a))\n",
    "        \n",
    "        p_b_count = run_P(lag2_l, lag1_l, n_b, n_a, dt)\n",
    "        p_b = p_b_count / float(n_b)\n",
    "        # print('p_b_count {}, p_b {}'.format(p_b_count, p_b))\n",
    "\n",
    "        if t_a * p_b == 1 and t_b * p_a == 1:\n",
    "            index = 1\n",
    "        elif t_a * p_b == 1:\n",
    "            index = 0.5 * (p_a - t_b) / (1 - p_a * t_b) + 0.5 \n",
    "        elif t_b * p_a == 1:\n",
    "            index = 0.5 + 0.5 * (p_b - t_a) / (1 - p_b * t_a) \n",
    "        else:\n",
    "            index = 0.5 * (p_a - t_b) / (1 - p_a * t_b) + 0.5 * (p_b - t_a) / (1 - p_b * t_a)\n",
    "    # print(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf5da7-cb1a-4864-b24f-26db4c579287",
   "metadata": {},
   "source": [
    "### Test on some random 0/1 arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f181eb-a298-4cad-9beb-da2fec602b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_trains_l = []\n",
    "n_trains = 10\n",
    "train_len = 1000\n",
    "\n",
    "for i in range(n_trains):\n",
    "    poisson = np.random.poisson(.05, train_len)\n",
    "    bounded_poisson = np.clip(poisson, a_min=0, a_max=1)\n",
    "    spike_trains_l.append(bounded_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2948a6ea-8d69-4517-94c6-2b021e703d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "i 0\n",
      "0.15850876611183662\n",
      "0.15850876611183662\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 1\n",
      "0.1646225264420118\n",
      "0.1646225264420118\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 2\n",
      "0.1656019296531637\n",
      "0.1656019296531637\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 3\n",
      "0.14053063991381132\n",
      "0.14053063991381132\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 4\n",
      "-0.07608761197138186\n",
      "-0.07608761197138186\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 5\n",
      "0.15432781378221572\n",
      "0.15432781378221572\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 6\n",
      "0.09194986338397529\n",
      "0.09194986338397529\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 7\n",
      "0.031008749835819954\n",
      "0.031008749835819954\n",
      "my_sttc - elephant_sttc: 0.0\n",
      "#############\n",
      "i 8\n",
      "0.007634156808932377\n",
      "0.007634156808932377\n",
      "my_sttc - elephant_sttc: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_trains-1):\n",
    "    print('#############')\n",
    "    print('i {}'.format(i))\n",
    "    spike_times_1 = np.where(spike_trains_l[i] == 1)[0]\n",
    "    spike_times_2 = np.where(spike_trains_l[i+1] == 1)[0]\n",
    "    \n",
    "    my_sttc = calc_sttc(spike_times_1, spike_times_2, t_start=0, t_stop=train_len, dt=10)\n",
    "    print(my_sttc)\n",
    "    \n",
    "    elephant_sttc = calc_sttc_elephant(spike_times_1, spike_times_2, t_start_=0, t_stop_=train_len, dt_=10)\n",
    "    print(elephant_sttc)\n",
    "\n",
    "    print('my_sttc - elephant_sttc: {}'.format(my_sttc - elephant_sttc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf0a05a-fe92-4fe7-a893-39cd404bfde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "i 0\n",
      "[1.0, 1.0, 0.3764829030006983, -0.2938758886255934, 1.0, 0.4200000000000004, 1.0, 1.0, 1.0, 1.0, 0.428819444444445, 0.4371827411167506, 1.0, 0.4368852459016391, 0.5753424657534247, 1, 1, 1, 1, 1.0]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 1\n",
      "[1.0, 1.0, 1.0, 0.24621549421193106, 0.36772908366533846, 0.23904179408766535, 0.1422413793103448, -0.4118969843949635, 1.0, 1.0, 1.0, 0.27750809061488657, 0.3416666666666666, 1, 1.0, 1.0, 1, 1, 1, 1]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 2\n",
      "[1.0, 1.0, 1.0, 0.1731707317073165, 0.36396761133603234, 1.0, 1.0, 0.1906249999999995, 1.0, 1.0, 0.5020345879959313, 1.0, 1.0, -0.5477376452293966, 1.0, 0.5782918149466193, 1, 1, 1, 1]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 3\n",
      "[1, 1, 1.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.0, 1, 1.0]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 4\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10359116022099463, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09585492227979203, 1.0, 1.0, 1.0, 1.0, 1.0, 0]\n",
      "my_acf_sttc - elephant_acf_sttc: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. nan]\n",
      "#############\n",
      "i 5\n",
      "[1, 1, 0.3041958041958045, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.0, 1, 1]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 6\n",
      "[1, 1, 1, 1, 0.2423954372623558, 1, 1, 1.0, 1, 1, 1, 1, 0.22549019607843146, 1, 1, 1.0, 1, 1, 1, 1.0]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 7\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 8\n",
      "[1.0, 1.0, -0.1202760616686162, 0.5307950727883534, 0.3603896103896104, -0.023459595103258568, 1.0, 1.0, 0.36363636363636376, 1.0, 0.5361216730038028, 0.5165562913907283, 1.0, 0.5341972642188626, 0.11160714285714313, 1, 1, 1, 1, 1.0]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "#############\n",
      "i 9\n",
      "[1, 1, 1, 1, 1.0, 1, 1, 1, 0.5909090909090909, 1, 1, 1.0, 1, 1, 1, 1.0, 1, 1, 1, 1.0]\n",
      "my_acf_sttc - elephant_acf_sttc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "n_lags_ = 20 \n",
    "for i in range(n_trains):\n",
    "    print('#############')\n",
    "    print('i {}'.format(i))\n",
    "    spike_times = np.where(spike_trains_l[i] == 1)[0]\n",
    "    \n",
    "    my_acf_sttc = acf_sttc(spike_times, n_lags_, lag_shift_=50, sttc_dt_=50, signal_length_=1000, verbose_=False) \n",
    "    print(my_acf_sttc)\n",
    "    \n",
    "    elephant_acf_sttc = calculate_acf_sttc_t(spike_times, n_lags_, acf_lag_ms_=50, sttc_lag_ms_=50, rec_length_=1000, verbose=False)\n",
    "    #print(elephant_acf_sttc)\n",
    "\n",
    "    print('my_acf_sttc - elephant_acf_sttc: {}'.format(np.asarray(my_acf_sttc) - np.asarray(elephant_acf_sttc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
