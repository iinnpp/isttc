{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4da220-01d6-4ce8-8db6-2956a92bce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# IP import warnings because of \"module 'numpy' has no attribute 'warnings'\"\n",
    "import warnings\n",
    "np.warnings = warnings\n",
    "from scipy import stats\n",
    "\n",
    "# add the path to the abcTau package\n",
    "import sys\n",
    "#sys.path.append('./abcTau')\n",
    "sys.path.append('C:\\\\Users\\\\ipochino\\\\.conda\\\\envs\\\\isttc\\\\Lib\\\\site-packages\\\\abcTau') # IP: replaced previous line with that; relative path was not working\n",
    "import abcTau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db934b15-e666-4c88-88d1-b75dfc50b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_tau_folder = 'D:\\\\intr_timescales\\\\abcTau-master\\\\'\n",
    "abc_tau_resuls = 'D:\\\\intr_timescales\\\\abcTau_results\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb413c94-2e03-4f39-b93e-f8353a7c644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for loading and saving data\n",
    "datasave_path = abc_tau_resuls + 'example_abc_results\\\\'\n",
    "dataload_path = abc_tau_folder + 'example_data\\\\'\n",
    "\n",
    "# path and filename to save the intermediate results after running each step\n",
    "inter_save_direc = abc_tau_resuls + 'example_abc_results\\\\'\n",
    "inter_filename = 'abc_intermediate_results'\n",
    "\n",
    "# define filename for loading and saving the results\n",
    "filename = 'OU_tau20_mean0_var1_rawData'\n",
    "filenameSave = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee358707-e1fd-49c3-a3dc-77b3a1feff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data time-series as a numpy array (numTrials * time-points)\n",
    "data_load = np.load(dataload_path + filename + '.npy')\n",
    "\n",
    "# select summary statistics metric\n",
    "summStat_metric = 'comp_ac_fft'\n",
    "ifNorm = True # if normalize the autocorrelation or PSD\n",
    "\n",
    "# extract statistics from real data\n",
    "deltaT = 1 # temporal resolution of data.\n",
    "binSize = 1 #  bin-size for binning data and computing the autocorrelation.\n",
    "disp = None # put the dispersion parameter if computed with grid-search\n",
    "maxTimeLag = 50 # only used when using autocorrelation for summary statistics\n",
    "data_sumStat, data_mean, data_var, T, numTrials =  abcTau.preprocessing.extract_stats(data_load, deltaT, binSize,\\\n",
    "                                                                                  summStat_metric, ifNorm, maxTimeLag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0c0a58-46d2-4f68-825a-a53d816803b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select generative model and distance function\n",
    "generativeModel = 'oneTauOU'\n",
    "distFunc = 'linear_distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a539472a-3622-4a00-a6e4-6709c7199c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a uniform prior distribution over the given range\n",
    "# for a uniform prior: stats.uniform(loc=x_min,scale=x_max-x_min)\n",
    "t_min = 0.0 # first timescale\n",
    "t_max = 100.0\n",
    "priorDist = [stats.uniform(loc= t_min, scale = t_max - t_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60671d07-5980-42f7-8715-b7b9f23f8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fitting params\n",
    "epsilon_0 = 1  # initial error threshold\n",
    "min_samples = 100 # min samples from the posterior\n",
    "steps = 60 # max number of iterations\n",
    "minAccRate = 0.01 # minimum acceptance rate to stop the iterations\n",
    "parallel = False # if parallel processing\n",
    "n_procs = 1 # number of processor for parallel processing (set to 1 if there is no parallel processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9209d67d-092c-418f-b2aa-41cc37f33513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model object\n",
    "class MyModel(abcTau.Model):\n",
    "\n",
    "    #This method initializes the model object.  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # draw samples from the prior. \n",
    "    def draw_theta(self):\n",
    "        theta = []\n",
    "        for p in self.prior:\n",
    "            theta.append(p.rvs())\n",
    "        return theta\n",
    "\n",
    "    # Choose the generative model (from generative_models)\n",
    "    # Choose autocorrelation computation method (from basic_functions)\n",
    "    def generate_data(self, theta):\n",
    "        # generate synthetic data\n",
    "        if disp == None:\n",
    "            syn_data, numBinData =  eval('abcTau.generative_models.' + generativeModel + \\\n",
    "                                         '(theta, deltaT, binSize, T, numTrials, data_mean, data_var)')\n",
    "        else:\n",
    "            syn_data, numBinData =  eval('abcTau.generative_models.' + generativeModel + \\\n",
    "                                         '(theta, deltaT, binSize, T, numTrials, data_mean, data_var, disp)')\n",
    "               \n",
    "        # compute the summary statistics\n",
    "        syn_sumStat = abcTau.summary_stats.comp_sumStat(syn_data, summStat_metric, ifNorm, deltaT, binSize, T,\\\n",
    "                                          numBinData, maxTimeLag)   \n",
    "        return syn_sumStat\n",
    "\n",
    "    # Computes the summary statistics\n",
    "    def summary_stats(self, data):\n",
    "        sum_stat = data\n",
    "        return sum_stat\n",
    "\n",
    "    # Choose the method for computing distance (from basic_functions)\n",
    "    def distance_function(self, data, synth_data):\n",
    "        if np.nansum(synth_data) <= 0: # in case of all nans return large d to reject the sample\n",
    "            d = 10**4\n",
    "        else:\n",
    "            d = eval('abcTau.distance_functions.' +distFunc + '(data, synth_data)')        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127e0589-c9fe-4acf-9ac7-0590897e346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting step 0\n",
      "epsilon = 1\n",
      "acceptence Rate = 1.0\n",
      "--------------------\n",
      "Starting step 1\n",
      "epsilon = 0.14620652469927575\n",
      "acceptence Rate = 0.704225352112676\n",
      "--------------------\n",
      "Starting step 2\n",
      "epsilon = 0.10360220593592875\n",
      "acceptence Rate = 0.684931506849315\n",
      "--------------------\n",
      "Starting step 3\n",
      "epsilon = 0.06932948991383497\n",
      "acceptence Rate = 0.6711409395973155\n",
      "--------------------\n",
      "Starting step 4\n",
      "epsilon = 0.030105962309847547\n",
      "acceptence Rate = 0.5208333333333334\n",
      "--------------------\n",
      "Starting step 5\n",
      "epsilon = 0.017353103164245667\n",
      "acceptence Rate = 0.5847953216374269\n",
      "--------------------\n",
      "Starting step 6\n",
      "epsilon = 0.008842130811325455\n",
      "acceptence Rate = 0.5076142131979695\n",
      "--------------------\n",
      "Starting step 7\n",
      "epsilon = 0.005118946344941341\n",
      "acceptence Rate = 0.4784688995215311\n",
      "--------------------\n",
      "Starting step 8\n",
      "epsilon = 0.0030495707354353512\n",
      "acceptence Rate = 0.5952380952380952\n",
      "--------------------\n",
      "Starting step 9\n",
      "epsilon = 0.0018993793660718739\n",
      "acceptence Rate = 0.5780346820809249\n",
      "--------------------\n",
      "Starting step 10\n",
      "epsilon = 0.000898616023153428\n",
      "acceptence Rate = 0.41841004184100417\n",
      "--------------------\n",
      "Starting step 11\n",
      "epsilon = 0.0004575984207095327\n",
      "acceptence Rate = 0.4830917874396135\n",
      "--------------------\n",
      "Starting step 12\n",
      "epsilon = 0.00022690245591353616\n",
      "acceptence Rate = 0.45662100456621\n",
      "--------------------\n",
      "Starting step 13\n",
      "epsilon = 0.00012635023860059797\n",
      "acceptence Rate = 0.49261083743842365\n",
      "--------------------\n",
      "Starting step 14\n",
      "epsilon = 6.923138762642139e-05\n",
      "acceptence Rate = 0.35714285714285715\n",
      "--------------------\n",
      "Starting step 15\n",
      "epsilon = 4.3338245073721676e-05\n",
      "acceptence Rate = 0.4065040650406504\n",
      "--------------------\n",
      "Starting step 16\n",
      "epsilon = 2.787506707850861e-05\n",
      "acceptence Rate = 0.2785515320334262\n",
      "--------------------\n",
      "Starting step 17\n",
      "epsilon = 1.7445170694616126e-05\n",
      "acceptence Rate = 0.25906735751295334\n",
      "--------------------\n",
      "Starting step 18\n",
      "epsilon = 1.2533464842778097e-05\n",
      "acceptence Rate = 0.2403846153846154\n",
      "--------------------\n",
      "Starting step 19\n",
      "epsilon = 8.946937982413509e-06\n",
      "acceptence Rate = 0.22026431718061673\n",
      "--------------------\n",
      "Starting step 20\n",
      "epsilon = 6.948663019374793e-06\n",
      "acceptence Rate = 0.13020833333333334\n",
      "--------------------\n",
      "Starting step 21\n",
      "epsilon = 5.645227375544065e-06\n",
      "acceptence Rate = 0.10989010989010989\n",
      "--------------------\n",
      "Starting step 22\n",
      "epsilon = 4.3975897821735795e-06\n",
      "acceptence Rate = 0.09066183136899365\n",
      "--------------------\n",
      "Starting step 23\n",
      "epsilon = 3.583310671270586e-06\n",
      "acceptence Rate = 0.06561679790026247\n",
      "--------------------\n",
      "Starting step 24\n",
      "epsilon = 2.9824925464645032e-06\n",
      "acceptence Rate = 0.06146281499692686\n",
      "--------------------\n",
      "Starting step 25\n",
      "epsilon = 2.6705863601021267e-06\n",
      "acceptence Rate = 0.044563279857397504\n",
      "--------------------\n",
      "Starting step 26\n",
      "epsilon = 2.2841804641972417e-06\n",
      "acceptence Rate = 0.032520325203252036\n",
      "--------------------\n",
      "Starting step 27\n",
      "epsilon = 1.8787126338880233e-06\n",
      "acceptence Rate = 0.018740629685157422\n",
      "--------------------\n",
      "Starting step 28\n",
      "epsilon = 1.6560116492485992e-06\n",
      "acceptence Rate = 0.018667164457718873\n",
      "--------------------\n",
      "Starting step 29\n",
      "epsilon = 1.3608116250272345e-06\n",
      "acceptence Rate = 0.010015022533800702\n",
      "--------------------\n",
      "Starting step 30\n",
      "epsilon = 1.167858851086162e-06\n",
      "acceptence Rate = 0.008848774444739404\n",
      "--------------------\n",
      "epsilon = 1.029880918084515e-06\n",
      "acceptence Rate = 0.008848774444739404\n",
      "END OF FITTING!!!\n",
      "***********************\n"
     ]
    }
   ],
   "source": [
    "# fit with aABC algorithm for any generative model\n",
    "abc_results, final_step = abcTau.fit.fit_withABC(MyModel, data_sumStat, priorDist, inter_save_direc, inter_filename,\\\n",
    "                                                 datasave_path,filenameSave, epsilon_0, min_samples, \\\n",
    "                                                 steps, minAccRate, parallel, n_procs, disp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
