{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7a34dc-2508-4032-a56b-b14cb7a82815",
   "metadata": {},
   "source": [
    "The notebooks shows how to calculate intrinsic timescales on the continious and epoched data. Four methods are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b3d74-805c-4cb6-90a4-c1238315a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import islice\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from isttc.acfunc import acf_pearsonr_trial_avg, acf_sttc_trial_concat, acf_sttc\n",
    "from isttc.tau import fit_single_exp, func_single_exp_monkey\n",
    "from isttc.spike_utils import bin_spike_train_fixed_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0e1e0-fe36-4e1c-9982-bd34d85a4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_every = 10\n",
    "\n",
    "fs = 1000 # sampling frequency \n",
    "bin_size = int(50 * (fs / 1000)) # 50 ms bin\n",
    "trial_len = int(1000 * (fs / 1000)) # 1000 ms trial\n",
    "\n",
    "sttc_dt = int(25 * (fs / 1000)) # dt for isttc \n",
    "n_lags = 20 # number of lags for acf calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94e6ab-06eb-4d17-a242-5982c402deff",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4154d7-160a-4b8f-8020-e87afb06cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike trains\n",
    "with open('spike_trains.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "spike_trains = data['spike_trains']\n",
    "signal_len = data['duration_ms']\n",
    "print(f'n spike trains {len(spike_trains)}, len {signal_len}')\n",
    "\n",
    "# trials\n",
    "with open('trials.pkl', 'rb') as f:\n",
    "    trials = pickle.load(f)\n",
    "\n",
    "with open('trials_binned.pkl', 'rb') as f:\n",
    "    trials_binned = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d845f23-b2e4-414f-942f-2d18f8cd939d",
   "metadata": {},
   "source": [
    "### Calculate intrinsic timescale using 4 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d1e7e-e9f8-4cd5-bfb4-f69f0c815d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_taus(acfs, exp_fun, log_every=2):\n",
    "    results = {}\n",
    "    for idx, unit_acf in enumerate(acfs):\n",
    "        if idx % log_every == 0:\n",
    "            print(f'#####\\nProcessing tau for unit {idx + 1}/{len(acfs)}, {datetime.now()}')\n",
    "        \n",
    "        fit_popt, fit_pcov, tau, tau_ci, fit_r_squared, explained_var, log_message = fit_single_exp(\n",
    "            unit_acf, start_idx_=1, exp_fun_=exp_fun)\n",
    "        \n",
    "        results[idx] = {\n",
    "            'taus': {\n",
    "                'tau': tau,\n",
    "                'tau_lower': tau_ci[0],\n",
    "                'tau_upper': tau_ci[1],\n",
    "                'fit_r_squared': fit_r_squared,\n",
    "                'popt': fit_popt,\n",
    "                'pcov': fit_pcov,\n",
    "                'log_message': log_message\n",
    "            },\n",
    "            'acf': unit_acf\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def build_acf_summary_df(acf_dict, method, fr_values, alphas, taus_ms, tau_ms_bin_size=50):\n",
    "    \"\"\"Construct summary df with tau and fit metrics.\"\"\"\n",
    "    data = []\n",
    "    for unit_id, unit_data in acf_dict.items():\n",
    "        taus = unit_data['taus']\n",
    "        data.append({\n",
    "            'unit_id': unit_id,\n",
    "            'tau': taus['tau'],\n",
    "            'fit_r_squared': taus['fit_r_squared']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['tau_ms'] = df['tau'] * tau_ms_bin_size    \n",
    "    df['method'] = method\n",
    "    df['fr'] = fr_values\n",
    "    df['alpha'] = alphas\n",
    "    df['tau_ms_true'] = taus_ms\n",
    "    df['tau_diff_abs'] = np.abs(df['tau_ms'] - df['tau_ms_true'])\n",
    "    df['tau_diff_rel'] = df['tau_diff_abs'] / df['tau_ms_true'] * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a028e-8e29-45f9-ae6c-0f858af83621",
   "metadata": {},
   "source": [
    "#### ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e278f73-697a-4242-9d70-70eeda9a5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin\n",
    "all_spike_trains_binned_l = [\n",
    "    bin_spike_train_fixed_len([int(spike) for spike in train], bin_size, fs, signal_len, verbose_=False)\n",
    "    for train in spike_trains\n",
    "]\n",
    "\n",
    "# get acf\n",
    "print(f'Calculating ACF...')\n",
    "acf_full_l = []\n",
    "for idx, unit in enumerate(all_spike_trains_binned_l):\n",
    "    if idx % log_every == 0:\n",
    "        print(f'#####\\nProcessing acf for unit {idx + 1}/{len(all_spike_trains_binned_l)}, {datetime.now()}')\n",
    "    acf_full_l.append(acf(unit, nlags=n_lags))\n",
    "\n",
    "# get tau\n",
    "print(f'\\nCalculating tau...')\n",
    "acf_full_dict = extract_all_taus(acf_full_l, func_single_exp_monkey, log_every)\n",
    "\n",
    "acf_full_df = build_acf_summary_df(acf_full_dict, 'acf', data['fr_values'], data['alphas'], data['tau_ms'], tau_ms_bin_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7337b2-b40a-43c8-8547-2d282e0f9ffc",
   "metadata": {},
   "source": [
    "#### iSTTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851cf77-784d-4359-adf0-7527d8c1182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get acf\n",
    "acf_isttc_full_l = []\n",
    "for idx, unit in enumerate(spike_trains):\n",
    "    if idx % log_every == 0:\n",
    "        print(f'#####\\nProcessing acf for unit {idx + 1}/{len(spike_trains)}, {datetime.now()}')\n",
    "    spike_train_int = np.asarray([int(spike) for spike in unit])\n",
    "    acf_isttc_full = acf_sttc(spike_train_int, n_lags, bin_size, sttc_dt, signal_len, verbose_=False)\n",
    "    acf_isttc_full_l.append(acf_isttc_full)\n",
    "\n",
    "# get tau\n",
    "print(f'\\nCalculating tau...')\n",
    "isttc_full_dict = extract_all_taus(acf_isttc_full_l, func_single_exp_monkey, log_every)\n",
    "\n",
    "isttc_full_df = build_acf_summary_df(isttc_full_dict, 'isttc', data['fr_values'], data['alphas'], data['tau_ms'], tau_ms_bin_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f97b3-9aa8-472a-86f9-010cf7089f6f",
   "metadata": {},
   "source": [
    "#### PearsonR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdcfee-7848-4997-8130-415238c19609",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_binned_dict = trials_binned['trial_dict']\n",
    "\n",
    "# get acf\n",
    "m_iterations = 1\n",
    "pearsonr_trial_avg_l = []\n",
    "for k, v in trial_binned_dict.items():\n",
    "    for m in range(m_iterations):\n",
    "        spikes_trials_binned = trial_binned_dict[k][m]\n",
    "        pearsonr_acf_matrix, pearsonr_acf_average = acf_pearsonr_trial_avg(spikes_trials_binned,\n",
    "                                                                           n_lags,\n",
    "                                                                           verbose_=False)\n",
    "        pearsonr_trial_avg_l.append(pearsonr_acf_average)\n",
    "   \n",
    "# get tau\n",
    "print(f'\\nCalculating tau...')\n",
    "pearsonr_full_dict = extract_all_taus(pearsonr_trial_avg_l, func_single_exp_monkey, log_every)\n",
    "\n",
    "pearsonr_full_df = build_acf_summary_df(pearsonr_full_dict, 'pearsonr', data['fr_values'], data['alphas'], data['tau_ms'], tau_ms_bin_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8e9ed-4f42-4cec-a03f-e5453aa07a34",
   "metadata": {},
   "source": [
    "#### iSTTC (trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1ff2e-880f-454e-8e5c-45a77c814806",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dict = trials['trial_dict']\n",
    "\n",
    "# get acf\n",
    "sttc_concat_acf_l= []\n",
    "for k, v in trial_dict.items():\n",
    "    for m in range(m_iterations):\n",
    "        spikes_trials = trial_dict[k][m]\n",
    "        acf_concat = acf_sttc_trial_concat(spikes_trials,\n",
    "                                           n_lags_=n_lags,\n",
    "                                           lag_shift_=bin_size,\n",
    "                                           sttc_dt_=sttc_dt,\n",
    "                                           trial_len_=trial_len,\n",
    "                                           zero_padding_len_=int(3*trial_len * (fs / 1000)),\n",
    "                                           verbose_=False)\n",
    "        sttc_concat_acf_l.append(acf_concat)\n",
    "\n",
    "# get tau\n",
    "print(f'\\nCalculating tau...')\n",
    "isttc_trials_dict = extract_all_taus(sttc_concat_acf_l, func_single_exp_monkey, log_every)\n",
    "\n",
    "isttc_trials_df = build_acf_summary_df(isttc_trials_dict, 'isttc_trials', data['fr_values'], data['alphas'], data['tau_ms'], tau_ms_bin_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4454be-471c-4b15-9d14-f6f56f3b5846",
   "metadata": {},
   "source": [
    "#### Combine all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fad8e6-0038-4c61-b0de-69ea892bfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df = pd.concat([acf_full_df, isttc_full_df, pearsonr_full_df, isttc_trials_df])\n",
    "tau_df.reset_index(inplace=True, drop=True)\n",
    "tau_df['tau_diff_rel_log10'] = np.log10(tau_df['tau_diff_rel'])\n",
    "tau_df['tau_ms_log10'] = np.log10(tau_df['tau_ms'])\n",
    "tau_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65deeb52-9e69-4e6c-a3db-71c106713b1b",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6423b38-6e38-4162-8bdc-ca6273233b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated taus and REE\n",
    "colors = ['#718190', '#1ba9e2', '#f4a91c' , '#955da2' ]\n",
    "method_order = ['acf', 'isttc', 'pearsonr', 'isttc_trials']\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(11, 4))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "sns.violinplot(y='method', x='tau_diff_rel_log10', hue='method', order=method_order, hue_order=method_order, \n",
    "               palette=colors, data=tau_df , cut=0, ax=axes[1])\n",
    "axes[1].set_xlabel('REE (%), log10')\n",
    "\n",
    "sns.violinplot(y='method', x='tau_ms_log10', hue='method', order=method_order, hue_order=method_order, \n",
    "               palette=colors, data=tau_df , cut=0, ax=axes[0])\n",
    "axes[0].set_xlabel('Intrinsic timescale (ms), log10')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.grid(True, which=\"both\", axis='x', linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "    ax.set_ylabel('Method')\n",
    "\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
